{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhJnJRunXCP5yXr38dgb1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaas-umputer/edge-cloud-workflow-scheduler/blob/main/uncertainty_aware_scheduler_review2_march13_with_scheduling_decisions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2oMvgmdldww",
        "outputId": "b815f86e-b048-4bd2-ec86-6369e014db6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd_MzCcCli_d",
        "outputId": "e276bfaf-a75f-4969-f022-8c467652f3a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZujlZYbrlloa",
        "outputId": "1274d139-0764-4bf9-cdab-7e3b38030aed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch_geometric networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3NlPxp3lob4",
        "outputId": "2ae53cec-a0b2-45df-f21c-0673a0cabd30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lerg0i9rlp6x",
        "outputId": "05389d7f-24af-4702-b660-dafa1759d363"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.2+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_cluster -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKh6rikAlr18",
        "outputId": "9f4fbcfe-e6c0-405b-c193-f5a7be3bc7a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_cluster) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_cluster) (1.26.4)\n",
            "Installing collected packages: torch_cluster\n",
            "Successfully installed torch_cluster-1.6.3+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2dNjfjkltHo",
        "outputId": "7c19ad60-1758-42fd-9780-4fa9ab809b90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_spline_conv\n",
            "Successfully installed torch_spline_conv-1.2.2+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a7U1wMNlx2w",
        "outputId": "c0c0ca01-dbdc-4f7d-dabb-c97e5f9122bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/920.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/920.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CTlRnIMlzUX",
        "outputId": "ceae8b06-4cc4-4e69-d16d-1a2b955dac01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43QRsHCwtlWi",
        "outputId": "d776c400-6de5-42ac-f52e-e0a98da1b2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.1.6)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/756.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, pyvis\n",
            "Successfully installed jedi-0.19.2 pyvis-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING AND VISUALIZING THE WORKFLOW"
      ],
      "metadata": {
        "id": "Dro_P-C6m5xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "def load_dag(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        dag_data = json.load(f)\n",
        "\n",
        "    cybershake_dag = nx.DiGraph()\n",
        "    for node, attributes in dag_data[\"nodes\"].items():\n",
        "        cybershake_dag.add_node(node, **attributes)\n",
        "    for parent, child, attributes in dag_data[\"edges\"]:\n",
        "        cybershake_dag.add_edge(parent, child, **attributes)\n",
        "    return cybershake_dag"
      ],
      "metadata": {
        "id": "W8Xj0JQLl0vO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gnwuTZyoUBzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow_dag = load_dag(\"cybershake_dag.json\")"
      ],
      "metadata": {
        "id": "BBPlvHESm3AS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_attributes = {node: workflow_dag.nodes[node] for node in workflow_dag.nodes()}\n",
        "print(\"Sample Node Attributes:\", list(node_attributes.items())[:5])  # Show first 5 nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqEx4hpEnlLT",
        "outputId": "00abe75b-f8a8-4043-e2ba-7033cf0f2223"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Node Attributes: [('ID00000', {'runtime': 3.81, 'execution_time': 4.0, 'cpu_usage': 1.26, 'memory_usage': 0.02247536844384094, 'disk_usage': 0.5, 'power_usage': 11.82, 'machine_type': 'cloud', 'network_latency': 4.40791560297728, 'migration_energy': 0.1576858346700459, 'data_size': 10, 'CCR': 0.005}), ('ID00001', {'runtime': 9.38, 'execution_time': 8.0, 'cpu_usage': 0.21, 'memory_usage': 0.0222659384464059, 'disk_usage': 0.5, 'power_usage': 4.47, 'machine_type': 'edge', 'network_latency': 30.57163749729113, 'migration_energy': 5.114316294420685, 'edge_queue_delay': 7.1, 'data_size': 10, 'CCR': 0.025}), ('ID00002', {'runtime': 99.15, 'execution_time': 100.50746268656717, 'cpu_usage': 0.16388059701492538, 'memory_usage': 0.02784441883456679, 'disk_usage': 0.5, 'power_usage': 4.147164179104478, 'machine_type': 'cloud', 'network_latency': 1.0169148405181474, 'migration_energy': 0.1621171199688822, 'data_size': 10, 'CCR': 0.00019899019899019898}), ('ID00003', {'runtime': 44.1, 'execution_time': 43.03001579778831, 'cpu_usage': 0.9952448657187993, 'memory_usage': 0.022653679285500296, 'disk_usage': 0.5, 'power_usage': 9.966714060031595, 'machine_type': 'cloud', 'network_latency': 3.2751709233900623, 'migration_energy': 0.19965715387778116, 'data_size': 10, 'CCR': 0.0004647918349364858}), ('ID00004', {'runtime': 1.47, 'execution_time': 1.3498495486459379, 'cpu_usage': 0.900370110330993, 'memory_usage': 0.022653679285500296, 'disk_usage': 0.5, 'power_usage': 9.30259077231695, 'machine_type': 'cloud', 'network_latency': 2.345371690597236, 'migration_energy': 0.2250751986368443, 'data_size': 10, 'CCR': 0.0148164660425026})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attributes = {edge: workflow_dag.edges[edge] for edge in workflow_dag.edges()}\n",
        "print(\"Sample Edge Attributes:\", list(edge_attributes.items())[:5])  # Show first 5 nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMMb_vSysiiJ",
        "outputId": "0f09973c-08ef-4ba3-efdf-ac763b18bdc2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Edge Attributes: [(('ID00002', 'ID00003'), {'CCR': 0.0004647918349364858, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00005'), {'CCR': 0.0007324573665082472, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00007'), {'CCR': 0.0005729166666666667, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00009'), {'CCR': 0.0006451612903225806, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00011'), {'CCR': 0.00036378783671202445, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list = list(workflow_dag.edges())\n",
        "print(\"Sample Edges (Task Dependencies):\", edge_list[:5])  # Show first 5 edges\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfAjlhY4sUvq",
        "outputId": "0003a4ea-1eb8-4896-d393-8ed3400c2ac9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Edges (Task Dependencies): [('ID00002', 'ID00003'), ('ID00002', 'ID00005'), ('ID00002', 'ID00007'), ('ID00002', 'ID00009'), ('ID00002', 'ID00011')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_workflow_dag(G):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    pos = nx.spring_layout(G)  # Positions for all nodes\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
        "    nx.draw(G, pos, node_color=\"lightblue\", edge_color=\"gray\", node_size=200)\n",
        "    plt.title(\"Workflow DAG (Task Dependencies)\")\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_workflow_dag(workflow_dag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "-elyHxmesfwX",
        "outputId": "d11f534e-70bb-468e-88a0-d2e77d8fbe24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "def plot_large_dag(G):\n",
        "    net = Network(notebook=True, height=\"750px\", width=\"100%\")\n",
        "    net.from_nx(G)\n",
        "    net.show(\"dag.html\")  # Opens in a browser\n",
        "\n",
        "plot_large_dag(workflow_dag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBW0p5XBsye5",
        "outputId": "323ab15d-e887-4731-b942-980a61d692f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "dag.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing, GATConv, global_mean_pool\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "import os\n",
        "\n",
        "\n",
        "# ---------------------- LOAD DAG & EXTRACT FEATURES ---------------------- #\n",
        "def load_dag(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        dag_data = json.load(f)\n",
        "\n",
        "    cybershake_dag = nx.DiGraph()\n",
        "    for node, attributes in dag_data[\"nodes\"].items():\n",
        "        cybershake_dag.add_node(node, **attributes)\n",
        "    for parent, child, attributes in dag_data[\"edges\"]:\n",
        "        cybershake_dag.add_edge(parent, child, **attributes)\n",
        "    return cybershake_dag\n",
        "\n",
        "\n",
        "def compute_feature_stats(workflow_dag):\n",
        "    execution_times, input_sizes, output_sizes, sla_deadlines, critical_paths = [], [], [], [], []\n",
        "\n",
        "    for node in workflow_dag.nodes():\n",
        "        node_data = workflow_dag.nodes[node]\n",
        "        execution_times.append(node_data.get(\"runtime\", 1.0))\n",
        "        input_sizes.append(sum(f.get(\"size\", 0) for f in node_data.get(\"input_files\", []) if f is not None))\n",
        "        output_sizes.append(sum(f.get(\"size\", 0) for f in node_data.get(\"output_files\", []) if f is not None))\n",
        "        sla_deadlines.append(node_data.get(\"sla_deadline\", execution_times[-1] * 1.5))\n",
        "        try:\n",
        "            critical_paths.append(\n",
        "                max(len(path) for path in nx.all_simple_paths(workflow_dag, list(workflow_dag.nodes())[0], node))\n",
        "                if nx.has_path(workflow_dag, list(workflow_dag.nodes())[0], node) else 0)\n",
        "        except nx.NetworkXNoPath:\n",
        "            critical_paths.append(0)\n",
        "\n",
        "    stats = lambda x: {\"min\": np.min(x), \"max\": np.max(x), \"mean\": np.mean(x), \"std\": np.std(x)}\n",
        "    return {\n",
        "        \"execution_time\": stats(execution_times),\n",
        "        \"input_size\": stats(input_sizes),\n",
        "        \"output_size\": stats(output_sizes),\n",
        "        \"sla_deadline\": stats(sla_deadlines),\n",
        "        \"critical_path\": stats(critical_paths)\n",
        "    }\n",
        "\n",
        "\n",
        "def normalize(value, stats, method=\"minmax\"):\n",
        "    if method == \"minmax\":\n",
        "        return (value - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"]) if stats[\"max\"] > stats[\"min\"] else 0\n",
        "    elif method == \"zscore\":\n",
        "        return (value - stats[\"mean\"]) / stats[\"std\"] if stats[\"std\"] > 0 else 0\n",
        "    else:\n",
        "        raise ValueError(\"Invalid normalization method.\")\n",
        "\n",
        "\n",
        "def prepare_workflow_dag(workflow_dag):\n",
        "    feature_stats = compute_feature_stats(workflow_dag)\n",
        "    node_id_to_idx = {node_id: idx for idx, node_id in enumerate(workflow_dag.nodes())}\n",
        "    edges = [(node_id_to_idx[u], node_id_to_idx[v]) for u, v in workflow_dag.edges()]\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Adjacency matrix for DAG\n",
        "    num_nodes = workflow_dag.number_of_nodes()\n",
        "    adjacency_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float)\n",
        "    for u, v in edges:\n",
        "        adjacency_matrix[u, v] = 1\n",
        "\n",
        "    # Topological order for positional encoding\n",
        "    topo_order = list(nx.topological_sort(workflow_dag))\n",
        "    node_features_list, edge_attr, execution_times, sla_adherences, task_priorities = [], [], [], [], []  # Corrected var name\n",
        "\n",
        "    # Compute shortest path to each node\n",
        "    shortest_path_lengths = {}\n",
        "    for node in workflow_dag.nodes():\n",
        "        try:\n",
        "            shortest_path_lengths[node] = nx.shortest_path_length(workflow_dag, source=topo_order[0], target=node)\n",
        "        except nx.NetworkXNoPath:\n",
        "            shortest_path_lengths[node] = 0\n",
        "\n",
        "    # Compute degree centrality\n",
        "    degree_centrality = nx.degree_centrality(workflow_dag)\n",
        "\n",
        "    for node in workflow_dag.nodes():\n",
        "        node_data = workflow_dag.nodes[node]\n",
        "        execution_time = node_data.get(\"runtime\", 1.0)\n",
        "        input_size = sum(f.get(\"size\", 0) for f in node_data.get(\"input_files\", []) if f is not None)\n",
        "        output_size = sum(f.get(\"size\", 0) for f in node_data.get(\"output_files\", []) if f is not None)\n",
        "        in_degree = workflow_dag.in_degree(node)\n",
        "        out_degree = workflow_dag.out_degree(node)\n",
        "        sla_deadline = node_data.get(\"sla_deadline\", execution_time * 1.5)\n",
        "        try:\n",
        "            critical_path = max(len(path) for path in\n",
        "                                nx.all_simple_paths(workflow_dag, topo_order[0], node)) if topo_order and nx.has_path(\n",
        "                workflow_dag, topo_order[0], node) else 0\n",
        "        except nx.NetworkXNoPath:\n",
        "            critical_path = 0\n",
        "\n",
        "        topo_rank = topo_order.index(node) / len(topo_order)\n",
        "\n",
        "        # Positional Encodings\n",
        "        shortest_path = shortest_path_lengths[node] / max(1, num_nodes)\n",
        "        node_degree = degree_centrality[node]\n",
        "\n",
        "        node_features = [  # Corrected local variable\n",
        "            normalize(execution_time, feature_stats[\"execution_time\"], \"zscore\"),\n",
        "            normalize(input_size, feature_stats[\"input_size\"], \"minmax\"),\n",
        "            normalize(output_size, feature_stats[\"output_size\"], \"minmax\"),\n",
        "            in_degree / max(1, workflow_dag.number_of_nodes()),\n",
        "            out_degree / max(1, workflow_dag.number_of_nodes()),\n",
        "            normalize(sla_deadline, feature_stats[\"sla_deadline\"], \"minmax\"),\n",
        "            normalize(critical_path, feature_stats[\"critical_path\"], \"minmax\"),\n",
        "            topo_rank,\n",
        "            shortest_path,  # Shortest Path\n",
        "            node_degree  # Degree\n",
        "        ]\n",
        "\n",
        "        node_features_list.append(node_features) # Corrected append\n",
        "\n",
        "        sla_adherence = 1 if execution_time <= sla_deadline else 0\n",
        "\n",
        "        task_priority = 1 / (execution_time + critical_path + 1e-6)\n",
        "        execution_times.append(normalize(execution_time, feature_stats[\"execution_time\"], \"zscore\"))\n",
        "        sla_adherences.append(sla_adherence)\n",
        "        task_priorities.append(task_priority)\n",
        "\n",
        "    sla_adherences = torch.tensor(sla_adherences, dtype=torch.float)\n",
        "    sla_adherences = torch.clamp(sla_adherences, min=1e-6, max=1.0)  # Ensure valid BCELoss input\n",
        "\n",
        "\n",
        "    for u, v in workflow_dag.edges():\n",
        "        u_idx, v_idx = node_id_to_idx[u], node_id_to_idx[v]\n",
        "        u_features, v_features = node_features_list[u_idx], node_features_list[v_idx]  # accessing features using new list\n",
        "        edge_attr.append([\n",
        "            abs(u_features[0] - v_features[0]),  # Execution time diff\n",
        "            abs(u_features[1] - v_features[1]),  # Input size diff\n",
        "            abs(u_features[2] - v_features[2]),  # Output size diff\n",
        "            abs(u_features[5] - v_features[5])  # SLA diff\n",
        "        ])\n",
        "\n",
        "    node_features_tensor = torch.tensor(node_features_list, dtype=torch.float) # Creating node features tensor\n",
        "    return (\n",
        "        node_features_tensor,\n",
        "        edge_index,\n",
        "        torch.tensor(edge_attr, dtype=torch.float),\n",
        "        adjacency_matrix,\n",
        "        torch.tensor(execution_times, dtype=torch.float).unsqueeze(1),\n",
        "        torch.tensor(sla_adherences, dtype=torch.float).unsqueeze(1),\n",
        "        torch.tensor(task_priorities, dtype=torch.float).unsqueeze(1),\n",
        "        node_features_list  # Passing the node feature list too for initial printing\n",
        "    )"
      ],
      "metadata": {
        "id": "RkXKeeZDtpJk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STATE REPRESENTATION MODULE"
      ],
      "metadata": {
        "id": "aBQ4c0L4LFA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trial cell\n",
        "# ---------------------- MODEL DEFINITION ---------------------- #\n",
        "class CustomGraphTransformerLayer(MessagePassing):\n",
        "    def __init__(self, in_features, out_features, heads=4, dropout=0.1, edge_dim=4):\n",
        "        super().__init__(aggr='add', node_dim=0)\n",
        "        self.heads = heads\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = out_features // heads\n",
        "\n",
        "        self.W_Q = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_K = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_V = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(edge_dim, heads * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(heads * 8, heads)\n",
        "        )\n",
        "        self.out_proj = nn.Linear(out_features, out_features)\n",
        "        self.gate = nn.Linear(out_features, out_features)\n",
        "        self.attn_weights = None\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        print(f\"GraphTransformerLayer input x shape: {x.shape}\")\n",
        "        Q = self.W_Q(x).view(-1, self.heads, self.head_dim)\n",
        "        print(f\"Q shape: {Q.shape}\")\n",
        "        K = self.W_K(x).view(-1, self.heads, self.head_dim)\n",
        "        V = self.W_V(x).view(-1, self.heads, self.head_dim)\n",
        "\n",
        "        alpha = self.compute_attention(Q, K, edge_index, edge_attr)\n",
        "        out = self.propagate(edge_index, x=V, alpha=alpha)\n",
        "        out = out.view(-1, self.heads * self.head_dim)\n",
        "        gate = torch.sigmoid(self.gate(out))\n",
        "        return self.out_proj(out * gate)\n",
        "\n",
        "    def compute_attention(self, Q, K, edge_index, edge_attr):\n",
        "        q_i, k_j = Q[edge_index[0]], K[edge_index[1]]\n",
        "        edge_weight = self.edge_mlp(edge_attr)\n",
        "        attn_scores = (q_i * k_j).sum(dim=-1) + edge_weight  # Compute raw attention scores\n",
        "        attn_scores = F.leaky_relu(attn_scores)\n",
        "        alpha = torch.softmax(attn_scores, dim=0)  # Apply softmax\n",
        "\n",
        "        self.attn_weights = alpha  # Store attention weights for visualization\n",
        "        return alpha\n",
        "\n",
        "    def message(self, x_j, alpha):\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "\n",
        "class TaskEmbeddingModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, heads=4, embedding_dim=32, lstm_hidden=32, lstm_layers=2,\n",
        "                 edge_dim=4, num_gnn_layers=2, num_transformer_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_transformer_layers = num_transformer_layers\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "\n",
        "        # ✅ Ensure Transformer layers output the same size as GNN input\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            CustomGraphTransformerLayer(input_dim if i == 0 else hidden_dim, hidden_dim, heads=heads,\n",
        "                                        edge_dim=edge_dim)\n",
        "            for i in range(num_transformer_layers)])\n",
        "\n",
        "        # ✅ Ensure GNN input matches the Transformer output\n",
        "        self.feature_projection = nn.Linear(hidden_dim, embedding_dim)  # Transform features\n",
        "\n",
        "        self.gnn_layers = nn.ModuleList([\n",
        "            GATConv(embedding_dim if i == 0 else embedding_dim, embedding_dim, heads=1)\n",
        "            for i in range(num_gnn_layers)])\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden, lstm_layers, batch_first=True)\n",
        "        self.fc_time = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_sla = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_priority = nn.Linear(lstm_hidden, 1)\n",
        "\n",
        "        # Learnable task weights for dynamic loss\n",
        "        self.log_sigma_time = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_sla = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_priority = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        # ✅ Fix Transformer-GNN Shape Mismatch\n",
        "        for i in range(max(self.num_transformer_layers, self.num_gnn_layers)):\n",
        "            if i < self.num_transformer_layers:\n",
        "                x = F.relu(self.transformer_layers[i](x, edge_index, edge_attr))\n",
        "\n",
        "        x = self.feature_projection(x)  # ✅ Ensures correct size before GNN\n",
        "\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x = F.relu(self.gnn_layers[i](x, edge_index))\n",
        "\n",
        "        # Graph-level read-out using global mean pooling\n",
        "        graph_embedding = global_mean_pool(x, batch)\n",
        "\n",
        "        lstm_input = x.unsqueeze(0)\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_out = lstm_out.squeeze(0)\n",
        "\n",
        "        exec_time_pred = self.fc_time(lstm_out)\n",
        "        sla_pred = torch.sigmoid(self.fc_sla(lstm_out))\n",
        "        priority_pred = torch.sigmoid(self.fc_priority(lstm_out))\n",
        "        return torch.cat([x, exec_time_pred, sla_pred, priority_pred], dim=1), graph_embedding\n"
      ],
      "metadata": {
        "id": "edAVCk1qvvQN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- TRAINING ---------------------- #\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def train_embeddings(node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities, node_features_list,\n",
        "                     epochs=500, save_path=\"./model_data\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Ensure save directory exists\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # ✅ Normalize execution times BEFORE passing to the model\n",
        "    scaler = MinMaxScaler()\n",
        "    execution_times = torch.tensor(scaler.fit_transform(execution_times.cpu().numpy()), dtype=torch.float).to(device)\n",
        "\n",
        "    model = TaskEmbeddingModel(node_features.size(1), num_gnn_layers=1, num_transformer_layers=1).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scaler = GradScaler() if device.type == \"cuda\" else None\n",
        "\n",
        "    data = [node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities]\n",
        "    data = [x.to(device) for x in data]\n",
        "    node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities = data\n",
        "\n",
        "    criterion_time = nn.L1Loss()\n",
        "    criterion_sla = nn.BCELoss()\n",
        "    criterion_priority = nn.L1Loss()\n",
        "\n",
        "    # ✅ Print SLA labels to check if they are all 0s\n",
        "    print(\"Unique SLA Adherence Values:\", torch.unique(sla_adherences))\n",
        "\n",
        "    # ✅ Scale SLA loss for better training\n",
        "    sla_adherences = torch.clamp(sla_adherences, min=1e-6, max=1.0)  # Ensure valid BCELoss input\n",
        "\n",
        "    # Create a batch vector for graph-level pooling (assuming single graph)\n",
        "    batch = torch.zeros(node_features.size(0), dtype=torch.long).to(device)\n",
        "\n",
        "    # ✅ Add loss tracking dictionary\n",
        "    loss_history = {\n",
        "        \"total_loss\": [],\n",
        "        \"loss_time\": [],\n",
        "        \"loss_sla\": [],\n",
        "        \"loss_priority\": [],\n",
        "        \"sigma_time\": [],\n",
        "        \"sigma_sla\": [],\n",
        "        \"sigma_priority\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=device.type == \"cuda\"):\n",
        "            embeddings, graph_embedding = model(node_features, edge_index, edge_attr, batch)  # Get graph embedding too\n",
        "            exec_time_pred = embeddings[:, -3].unsqueeze(1)\n",
        "            sla_pred = embeddings[:, -2].unsqueeze(1)\n",
        "            priority_pred = embeddings[:, -1].unsqueeze(1)\n",
        "\n",
        "            loss_time = criterion_time(exec_time_pred, execution_times)\n",
        "            loss_sla = criterion_sla(sla_pred, sla_adherences)\n",
        "            loss_priority = criterion_priority(priority_pred, task_priorities)\n",
        "\n",
        "            # ✅ Scale SLA Loss to prevent it from vanishing\n",
        "            loss_sla_scaled = loss_sla * 10  # Increase SLA loss impact\n",
        "\n",
        "            # Normalize loss values before dynamic weighting\n",
        "            loss_time_norm = loss_time / loss_time.detach().max()\n",
        "            loss_sla_norm = loss_sla_scaled / loss_sla_scaled.detach().max()\n",
        "            loss_priority_norm = loss_priority / loss_priority.detach().max()\n",
        "\n",
        "            # ✅ Prevent dynamic loss scaling from becoming too small\n",
        "            sigma_time = torch.exp(-model.log_sigma_time).clamp(min=0.1)\n",
        "            sigma_sla = torch.exp(-model.log_sigma_sla).clamp(min=0.1)\n",
        "            sigma_priority = torch.exp(-model.log_sigma_priority).clamp(min=0.1)\n",
        "\n",
        "            loss_time_weighted = 0.5 * sigma_time * loss_time_norm + 0.5 * model.log_sigma_time\n",
        "            loss_sla_weighted = 0.3 * sigma_sla * loss_sla_norm + 0.3 * model.log_sigma_sla\n",
        "            loss_priority_weighted = 0.2 * sigma_priority * loss_priority_norm + 0.2 * model.log_sigma_priority\n",
        "\n",
        "            loss = loss_time_weighted + loss_sla_weighted + loss_priority_weighted\n",
        "\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # ✅ Track loss values\n",
        "        loss_history[\"total_loss\"].append(loss.item())\n",
        "        loss_history[\"loss_time\"].append(loss_time.item())\n",
        "        loss_history[\"loss_sla\"].append(loss_sla.item())\n",
        "        loss_history[\"loss_priority\"].append(loss_priority.item())\n",
        "        loss_history[\"sigma_time\"].append(sigma_time.item())\n",
        "        loss_history[\"sigma_sla\"].append(sigma_sla.item())\n",
        "        loss_history[\"sigma_priority\"].append(sigma_priority.item())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch}, Loss: {loss.item():.4f}, Time Loss: {loss_time.item():.4f}, SLA Loss: {loss_sla.item():.4f}, Priority Loss: {loss_priority.item():.4f}\")\n",
        "\n",
        "    # ✅ Save loss history\n",
        "    np.save(os.path.join(save_path, \"loss_history.npy\"), loss_history)\n",
        "    print(f\"Loss history saved to {save_path}/loss_history.npy\")\n",
        "\n",
        "    # Save model, embeddings, and graph embedding after training\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, \"model.pth\"))\n",
        "\n",
        "    # Detach and move to CPU before saving as numpy arrays\n",
        "    node_embeddings_cpu = embeddings[:, :-3].detach().cpu().numpy()\n",
        "    graph_embedding_cpu = graph_embedding.detach().cpu().numpy()\n",
        "\n",
        "    np.save(os.path.join(save_path, \"task_embeddings.npy\"), node_embeddings_cpu)\n",
        "    np.save(os.path.join(save_path, \"graph_embedding.npy\"), graph_embedding_cpu)\n",
        "\n",
        "    print(f\"Model, task embeddings, and graph embedding saved to {save_path}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6vId4BNG07Gk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Load and prepare data\n",
        "workflow_dag = load_dag(\"cybershake_dag.json\")\n",
        "(node_features, edge_index, edge_attr, adjacency_matrix, execution_times, sla_adherences,\n",
        " task_priorities, node_features_list) = prepare_workflow_dag(workflow_dag)\n",
        "\n",
        "# Print initial node features\n",
        "print(\"Initial Node Features:\")\n",
        "for i, features in enumerate(node_features_list):\n",
        "    print(f\"Node {i}: {features}\")\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Train model\n",
        "embedding_model_save_path = \"./embedding_model_data\"\n",
        "model = train_embeddings(node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "                         task_priorities, node_features_list, save_path=embedding_model_save_path)\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), os.path.join(embedding_model_save_path, \"trained_model.pth\"))\n",
        "\n",
        "# Save node features, edge index, and edge attributes for later visualization\n",
        "np.save(os.path.join(embedding_model_save_path, \"node_features.npy\"), node_features.cpu().numpy())\n",
        "np.save(os.path.join(embedding_model_save_path, \"edge_index.npy\"), edge_index.cpu().numpy())\n",
        "np.save(os.path.join(embedding_model_save_path, \"edge_attr.npy\"), edge_attr.cpu().numpy())\n",
        "\n",
        "print(f\"Model training complete. Saved at {embedding_model_save_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmUj6md0970",
        "outputId": "a3aa461a-30c7-442f-a461-1ae2558ba0da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8ad5e4b2a293>:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(sla_adherences, dtype=torch.float).unsqueeze(1),\n",
            "<ipython-input-18-6ef5fed1a07e>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Node Features:\n",
            "Node 0: [-0.7908287615665436, 0, 0, 0.497, 0.0, 0.018099045081057072, 4.0, 0.999, 0.003, 0.4974974974974975]\n",
            "Node 1: [-0.5582804480397533, 0, 0, 0.497, 0.0, 0.0490228736397957, 3.0, 0.997, 0.002, 0.4974974974974975]\n",
            "Node 2: [3.1896301633246904, 0, 0, 0.0, 0.109, 0.5474128358871865, 1.0, 0.0, 0.0, 0.1091091091091091]\n",
            "Node 3: [0.8912846229925903, 0, 0, 0.001, 0.002, 0.24178325560737288, 2.0, 0.004, 0.001, 0.003003003003003003]\n",
            "Node 4: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.501, 0.002, 0.002002002002002002]\n",
            "Node 5: [0.14353950714612498, 0, 0, 0.001, 0.002, 0.1423495447479458, 2.0, 0.005, 0.001, 0.003003003003003003]\n",
            "Node 6: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.502, 0.002, 0.002002002002002002]\n",
            "Node 7: [0.4846382004161205, 0, 0, 0.001, 0.002, 0.18770819453697532, 2.0, 0.006, 0.001, 0.003003003003003003]\n",
            "Node 8: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 3.0, 0.503, 0.002, 0.002002002002002002]\n",
            "Node 9: [0.35354274180317236, 0, 0, 0.001, 0.002, 0.17027537197423936, 2.0, 0.007, 0.001, 0.003003003003003003]\n",
            "Node 10: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.504, 0.002, 0.002002002002002002]\n",
            "Node 11: [1.3893638654296827, 0, 0, 0.001, 0.002, 0.3080168776371308, 2.0, 0.008, 0.001, 0.003003003003003003]\n",
            "Node 12: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 3.0, 0.505, 0.002, 0.002002002002002002]\n",
            "Node 13: [0.15063703197548833, 0, 0, 0.001, 0.002, 0.14329335998223405, 2.0, 0.009, 0.001, 0.003003003003003003]\n",
            "Node 14: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.506, 0.002, 0.002002002002002002]\n",
            "Node 15: [1.0954428372019267, 0, 0, 0.001, 0.002, 0.2689318232289585, 2.0, 0.01, 0.001, 0.003003003003003003]\n",
            "Node 16: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.507, 0.002, 0.002002002002002002]\n",
            "Node 17: [1.1388629890992088, 0, 0, 0.001, 0.002, 0.2747057517210748, 2.0, 0.011, 0.001, 0.003003003003003003]\n",
            "Node 18: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.508, 0.002, 0.002002002002002002]\n",
            "Node 19: [0.049601678522197185, 0, 0, 0.001, 0.002, 0.12985787252942482, 2.0, 0.012, 0.001, 0.003003003003003003]\n",
            "Node 20: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.509, 0.002, 0.002002002002002002]\n",
            "Node 21: [1.7534251390299718, 0, 0, 0.001, 0.002, 0.3564290473017988, 2.0, 0.013, 0.001, 0.003003003003003003]\n",
            "Node 22: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 3.0, 0.51, 0.002, 0.002002002002002002]\n",
            "Node 23: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.014, 0.001, 0.003003003003003003]\n",
            "Node 24: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 3.0, 0.511, 0.002, 0.002002002002002002]\n",
            "Node 25: [1.3960438887984952, 0, 0, 0.001, 0.002, 0.3089051743282256, 2.0, 0.015, 0.001, 0.003003003003003003]\n",
            "Node 26: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 3.0, 0.512, 0.002, 0.002002002002002002]\n",
            "Node 27: [0.3218126308013124, 0, 0, 0.001, 0.002, 0.16605596269153894, 2.0, 0.016, 0.001, 0.003003003003003003]\n",
            "Node 28: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.513, 0.002, 0.002002002002002002]\n",
            "Node 29: [0.04459166099558766, 0, 0, 0.001, 0.002, 0.12919165001110372, 2.0, 0.017, 0.001, 0.003003003003003003]\n",
            "Node 30: [-0.9114866836657218, 0, 0, 0.001, 0.001, 0.0020541860981567843, 3.0, 0.514, 0.002, 0.002002002002002002]\n",
            "Node 31: [1.4048114194700623, 0, 0, 0.001, 0.002, 0.31007106373528753, 2.0, 0.018, 0.001, 0.003003003003003003]\n",
            "Node 32: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.515, 0.002, 0.002002002002002002]\n",
            "Node 33: [0.1147319063681204, 0, 0, 0.001, 0.002, 0.13851876526759938, 2.0, 0.019, 0.001, 0.003003003003003003]\n",
            "Node 34: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.516, 0.002, 0.002002002002002002]\n",
            "Node 35: [0.8019393104347211, 0, 0, 0.001, 0.002, 0.22990228736397955, 2.0, 0.02, 0.001, 0.003003003003003003]\n",
            "Node 36: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.517, 0.002, 0.002002002002002002]\n",
            "Node 37: [1.2231982841304683, 0, 0, 0.001, 0.002, 0.28592049744614695, 2.0, 0.021, 0.001, 0.003003003003003003]\n",
            "Node 38: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.518, 0.002, 0.002002002002002002]\n",
            "Node 39: [1.3689062938626941, 0, 0, 0.001, 0.002, 0.3052964690206529, 2.0, 0.022, 0.001, 0.003003003003003003]\n",
            "Node 40: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.519, 0.002, 0.002002002002002002]\n",
            "Node 41: [0.400302905384861, 0, 0, 0.001, 0.002, 0.17649344881190318, 2.0, 0.023, 0.001, 0.003003003003003003]\n",
            "Node 42: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.52, 0.002, 0.002002002002002002]\n",
            "Node 43: [0.08383679828736199, 0, 0, 0.001, 0.002, 0.1344103930712858, 2.0, 0.024, 0.001, 0.003003003003003003]\n",
            "Node 44: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.521, 0.002, 0.002002002002002002]\n",
            "Node 45: [0.125586944342441, 0, 0, 0.001, 0.002, 0.13996224739062846, 2.0, 0.025, 0.001, 0.003003003003003003]\n",
            "Node 46: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 3.0, 0.522, 0.002, 0.002002002002002002]\n",
            "Node 47: [0.9772899238660527, 0, 0, 0.001, 0.002, 0.2532200755052187, 2.0, 0.026, 0.001, 0.003003003003003003]\n",
            "Node 48: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.523, 0.002, 0.002002002002002002]\n",
            "Node 49: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 2.0, 0.027, 0.001, 0.003003003003003003]\n",
            "Node 50: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.524, 0.002, 0.002002002002002002]\n",
            "Node 51: [0.5209608274840392, 0, 0, 0.001, 0.002, 0.19253830779480344, 2.0, 0.028, 0.001, 0.003003003003003003]\n",
            "Node 52: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 3.0, 0.525, 0.002, 0.002002002002002002]\n",
            "Node 53: [1.0136125509339717, 0, 0, 0.001, 0.002, 0.25805018876304686, 2.0, 0.029, 0.001, 0.003003003003003003]\n",
            "Node 54: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.526, 0.002, 0.002002002002002002]\n",
            "Node 55: [0.155229548041547, 0, 0, 0.001, 0.002, 0.14390406395736174, 2.0, 0.03, 0.001, 0.003003003003003003]\n",
            "Node 56: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.527, 0.002, 0.002002002002002002]\n",
            "Node 57: [0.8908671215320395, 0, 0, 0.001, 0.002, 0.24172773706417944, 2.0, 0.031, 0.001, 0.003003003003003003]\n",
            "Node 58: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.528, 0.002, 0.002002002002002002]\n",
            "Node 59: [0.6219961809373304, 0, 0, 0.001, 0.002, 0.20597379524761267, 2.0, 0.032, 0.001, 0.003003003003003003]\n",
            "Node 60: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 3.0, 0.529, 0.002, 0.002002002002002002]\n",
            "Node 61: [1.7550951448721752, 0, 0, 0.001, 0.002, 0.3566511214745725, 2.0, 0.033, 0.001, 0.003003003003003003]\n",
            "Node 62: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.53, 0.002, 0.002002002002002002]\n",
            "Node 63: [0.6499687787942334, 0, 0, 0.001, 0.002, 0.20969353764157228, 2.0, 0.034, 0.001, 0.003003003003003003]\n",
            "Node 64: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 3.0, 0.531, 0.002, 0.002002002002002002]\n",
            "Node 65: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.035, 0.001, 0.003003003003003003]\n",
            "Node 66: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.532, 0.002, 0.002002002002002002]\n",
            "Node 67: [1.1150654058478138, 0, 0, 0.001, 0.002, 0.2715411947590495, 2.0, 0.036, 0.001, 0.003003003003003003]\n",
            "Node 68: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.533, 0.002, 0.002002002002002002]\n",
            "Node 69: [1.2227807826699175, 0, 0, 0.001, 0.002, 0.2858649789029536, 2.0, 0.037, 0.001, 0.003003003003003003]\n",
            "Node 70: [-0.8981266369280967, 0, 0, 0.001, 0.001, 0.0038307794803464344, 3.0, 0.534, 0.002, 0.002002002002002002]\n",
            "Node 71: [1.4110739413783238, 0, 0, 0.001, 0.002, 0.3109038418831889, 2.0, 0.038, 0.001, 0.003003003003003003]\n",
            "Node 72: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.535, 0.002, 0.002002002002002002]\n",
            "Node 73: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 2.0, 0.039, 0.001, 0.003003003003003003]\n",
            "Node 74: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.536, 0.002, 0.002002002002002002]\n",
            "Node 75: [0.3255701439462695, 0, 0, 0.001, 0.002, 0.1665556295802798, 2.0, 0.04, 0.001, 0.003003003003003003]\n",
            "Node 76: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.537, 0.002, 0.002002002002002002]\n",
            "Node 77: [1.4778741750664504, 0, 0, 0.001, 0.002, 0.3197868087941372, 2.0, 0.041, 0.001, 0.003003003003003003]\n",
            "Node 78: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.538, 0.002, 0.002002002002002002]\n",
            "Node 79: [1.4507365801306489, 0, 0, 0.001, 0.002, 0.3161781034865645, 2.0, 0.042, 0.001, 0.003003003003003003]\n",
            "Node 80: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.539, 0.002, 0.002002002002002002]\n",
            "Node 81: [0.342270202368301, 0, 0, 0.001, 0.002, 0.16877637130801684, 2.0, 0.043, 0.001, 0.003003003003003003]\n",
            "Node 82: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.54, 0.002, 0.002002002002002002]\n",
            "Node 83: [1.2732984593965633, 0, 0, 0.001, 0.002, 0.2925827226293582, 2.0, 0.044, 0.001, 0.003003003003003003]\n",
            "Node 84: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.541, 0.002, 0.002002002002002002]\n",
            "Node 85: [0.27630497160127626, 0, 0, 0.001, 0.002, 0.16000444148345547, 2.0, 0.045, 0.001, 0.003003003003003003]\n",
            "Node 86: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.542, 0.002, 0.002002002002002002]\n",
            "Node 87: [0.9877274603798225, 0, 0, 0.001, 0.002, 0.25460803908505436, 2.0, 0.046, 0.001, 0.003003003003003003]\n",
            "Node 88: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.543, 0.002, 0.002002002002002002]\n",
            "Node 89: [1.1271729482037867, 0, 0, 0.001, 0.002, 0.2731512325116589, 2.0, 0.047, 0.001, 0.003003003003003003]\n",
            "Node 90: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 3.0, 0.544, 0.002, 0.002002002002002002]\n",
            "Node 91: [0.6140636531868655, 0, 0, 0.001, 0.002, 0.20491894292693758, 2.0, 0.048, 0.001, 0.003003003003003003]\n",
            "Node 92: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 3.0, 0.545, 0.002, 0.002002002002002002]\n",
            "Node 93: [0.03164911571851322, 0, 0, 0.001, 0.002, 0.12747057517210747, 2.0, 0.049, 0.001, 0.003003003003003003]\n",
            "Node 94: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 3.0, 0.546, 0.002, 0.002002002002002002]\n",
            "Node 95: [1.1547280446001387, 0, 0, 0.001, 0.002, 0.276815456362425, 2.0, 0.05, 0.001, 0.003003003003003003]\n",
            "Node 96: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 3.0, 0.547, 0.002, 0.002002002002002002]\n",
            "Node 97: [1.0754027670954884, 0, 0, 0.001, 0.002, 0.26626693315567396, 2.0, 0.051, 0.001, 0.003003003003003003]\n",
            "Node 98: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.548, 0.002, 0.002002002002002002]\n",
            "Node 99: [1.3167186112938454, 0, 0, 0.001, 0.002, 0.2983566511214746, 2.0, 0.052, 0.001, 0.003003003003003003]\n",
            "Node 100: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 3.0, 0.549, 0.002, 0.002002002002002002]\n",
            "Node 101: [1.3125435966883374, 0, 0, 0.001, 0.002, 0.2978014656895403, 2.0, 0.053, 0.001, 0.003003003003003003]\n",
            "Node 102: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 3.0, 0.55, 0.002, 0.002002002002002002]\n",
            "Node 103: [1.3405161945452402, 0, 0, 0.001, 0.002, 0.30152120808349986, 2.0, 0.054, 0.001, 0.003003003003003003]\n",
            "Node 104: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.551, 0.002, 0.002002002002002002]\n",
            "Node 105: [1.1605730650478496, 0, 0, 0.001, 0.002, 0.277592715967133, 2.0, 0.055, 0.001, 0.003003003003003003]\n",
            "Node 106: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.552, 0.002, 0.002002002002002002]\n",
            "Node 107: [0.2696249482324636, 0, 0, 0.001, 0.002, 0.15911614479236064, 2.0, 0.056, 0.001, 0.003003003003003003]\n",
            "Node 108: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.553, 0.002, 0.002002002002002002]\n",
            "Node 109: [0.6424537525043192, 0, 0, 0.001, 0.002, 0.2086942038640906, 2.0, 0.057, 0.001, 0.003003003003003003]\n",
            "Node 110: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.554, 0.002, 0.002002002002002002]\n",
            "Node 111: [1.7258700426336198, 0, 0, 0.001, 0.002, 0.35276482345103266, 2.0, 0.058, 0.001, 0.003003003003003003]\n",
            "Node 112: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 3.0, 0.555, 0.002, 0.002002002002002002]\n",
            "Node 113: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.059, 0.001, 0.003003003003003003]\n",
            "Node 114: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 3.0, 0.556, 0.002, 0.002002002002002002]\n",
            "Node 115: [1.7112574915143424, 0, 0, 0.001, 0.002, 0.3508216744392627, 2.0, 0.06, 0.001, 0.003003003003003003]\n",
            "Node 116: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.557, 0.002, 0.002002002002002002]\n",
            "Node 117: [0.4144979550435877, 0, 0, 0.001, 0.002, 0.17838107928047964, 2.0, 0.061, 0.001, 0.003003003003003003]\n",
            "Node 118: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.558, 0.002, 0.002002002002002002]\n",
            "Node 119: [1.3743338128498543, 0, 0, 0.001, 0.002, 0.3060182100821674, 2.0, 0.062, 0.001, 0.003003003003003003]\n",
            "Node 120: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 3.0, 0.559, 0.002, 0.002002002002002002]\n",
            "Node 121: [0.06630173694422874, 0, 0, 0.001, 0.002, 0.13207861425716186, 2.0, 0.063, 0.001, 0.003003003003003003]\n",
            "Node 122: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.56, 0.002, 0.002002002002002002]\n",
            "Node 123: [1.6966449403950643, 0, 0, 0.001, 0.002, 0.3488785254274928, 2.0, 0.064, 0.001, 0.003003003003003003]\n",
            "Node 124: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 3.0, 0.561, 0.002, 0.002002002002002002]\n",
            "Node 125: [1.3831013435214212, 0, 0, 0.001, 0.002, 0.3071840994892294, 2.0, 0.065, 0.001, 0.003003003003003003]\n",
            "Node 126: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 3.0, 0.562, 0.002, 0.002002002002002002]\n",
            "Node 127: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 2.0, 0.066, 0.001, 0.003003003003003003]\n",
            "Node 128: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 3.0, 0.563, 0.002, 0.002002002002002002]\n",
            "Node 129: [0.1869596590434071, 0, 0, 0.001, 0.002, 0.14812347324006217, 2.0, 0.067, 0.001, 0.003003003003003003]\n",
            "Node 130: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.564, 0.002, 0.002002002002002002]\n",
            "Node 131: [1.1133954000056105, 0, 0, 0.001, 0.002, 0.2713191205862758, 2.0, 0.068, 0.001, 0.003003003003003003]\n",
            "Node 132: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.565, 0.002, 0.002002002002002002]\n",
            "Node 133: [0.9468123172458452, 0, 0, 0.001, 0.002, 0.24916722185209858, 2.0, 0.069, 0.001, 0.003003003003003003]\n",
            "Node 134: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.566, 0.002, 0.002002002002002002]\n",
            "Node 135: [0.8507869813191636, 0, 0, 0.001, 0.002, 0.23639795691761048, 2.0, 0.07, 0.001, 0.003003003003003003]\n",
            "Node 136: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.567, 0.002, 0.002002002002002002]\n",
            "Node 137: [0.32306513518296465, 0, 0, 0.001, 0.002, 0.16622251832111923, 2.0, 0.071, 0.001, 0.003003003003003003]\n",
            "Node 138: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.568, 0.002, 0.002002002002002002]\n",
            "Node 139: [0.704243968665836, 0, 0, 0.001, 0.002, 0.2169109482567177, 2.0, 0.072, 0.001, 0.003003003003003003]\n",
            "Node 140: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 3.0, 0.569, 0.002, 0.002002002002002002]\n",
            "Node 141: [0.7660341848273532, 0, 0, 0.001, 0.002, 0.22512769264934487, 2.0, 0.073, 0.001, 0.003003003003003003]\n",
            "Node 142: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.57, 0.002, 0.002002002002002002]\n",
            "Node 143: [1.299601051411263, 0, 0, 0.001, 0.002, 0.2960803908505441, 2.0, 0.074, 0.001, 0.003003003003003003]\n",
            "Node 144: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.571, 0.002, 0.002002002002002002]\n",
            "Node 145: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 2.0, 0.075, 0.001, 0.003003003003003003]\n",
            "Node 146: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.572, 0.002, 0.002002002002002002]\n",
            "Node 147: [0.40907043605642734, 0, 0, 0.001, 0.002, 0.1776593382189651, 2.0, 0.076, 0.001, 0.003003003003003003]\n",
            "Node 148: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.573, 0.002, 0.002002002002002002]\n",
            "Node 149: [0.9910674720642291, 0, 0, 0.001, 0.002, 0.2550521874306018, 2.0, 0.077, 0.001, 0.003003003003003003]\n",
            "Node 150: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 3.0, 0.574, 0.002, 0.002002002002002002]\n",
            "Node 151: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 2.0, 0.078, 0.001, 0.003003003003003003]\n",
            "Node 152: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.575, 0.002, 0.002002002002002002]\n",
            "Node 153: [1.6640798264721026, 0, 0, 0.001, 0.002, 0.34454807905840545, 2.0, 0.079, 0.001, 0.003003003003003003]\n",
            "Node 154: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 3.0, 0.576, 0.002, 0.002002002002002002]\n",
            "Node 155: [1.2975135441085088, 0, 0, 0.001, 0.002, 0.29580279813457694, 2.0, 0.08, 0.001, 0.003003003003003003]\n",
            "Node 156: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.577, 0.002, 0.002002002002002002]\n",
            "Node 157: [0.9960774895908384, 0, 0, 0.001, 0.002, 0.2557184099489229, 2.0, 0.081, 0.001, 0.003003003003003003]\n",
            "Node 158: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.578, 0.002, 0.002002002002002002]\n",
            "Node 159: [0.14938452759383591, 0, 0, 0.001, 0.002, 0.14312680435265376, 2.0, 0.082, 0.001, 0.003003003003003003]\n",
            "Node 160: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.579, 0.002, 0.002002002002002002]\n",
            "Node 161: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.083, 0.001, 0.003003003003003003]\n",
            "Node 162: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.58, 0.002, 0.002002002002002002]\n",
            "Node 163: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 2.0, 0.084, 0.001, 0.003003003003003003]\n",
            "Node 164: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.581, 0.002, 0.002002002002002002]\n",
            "Node 165: [-0.012606039099870637, 0, 0, 0.001, 0.002, 0.12158560959360425, 2.0, 0.085, 0.001, 0.003003003003003003]\n",
            "Node 166: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.582, 0.002, 0.002002002002002002]\n",
            "Node 167: [0.5714785042106848, 0, 0, 0.001, 0.002, 0.19925605152120807, 2.0, 0.086, 0.001, 0.003003003003003003]\n",
            "Node 168: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 3.0, 0.583, 0.002, 0.002002002002002002]\n",
            "Node 169: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 2.0, 0.087, 0.001, 0.003003003003003003]\n",
            "Node 170: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.584, 0.002, 0.002002002002002002]\n",
            "Node 171: [0.020794077744192608, 0, 0, 0.001, 0.002, 0.1260270930490784, 2.0, 0.088, 0.001, 0.003003003003003003]\n",
            "Node 172: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.585, 0.002, 0.002002002002002002]\n",
            "Node 173: [0.6971464438364728, 0, 0, 0.001, 0.002, 0.21596713302242948, 2.0, 0.089, 0.001, 0.003003003003003003]\n",
            "Node 174: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.586, 0.002, 0.002002002002002002]\n",
            "Node 175: [1.3810138362186668, 0, 0, 0.001, 0.002, 0.30690650677326226, 2.0, 0.09, 0.001, 0.003003003003003003]\n",
            "Node 176: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 3.0, 0.587, 0.002, 0.002002002002002002]\n",
            "Node 177: [0.5840035480272087, 0, 0, 0.001, 0.002, 0.20092160781701088, 2.0, 0.091, 0.001, 0.003003003003003003]\n",
            "Node 178: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.588, 0.002, 0.002002002002002002]\n",
            "Node 179: [1.1935556804313623, 0, 0, 0.001, 0.002, 0.28197868087941375, 2.0, 0.092, 0.001, 0.003003003003003003]\n",
            "Node 180: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 3.0, 0.589, 0.002, 0.002002002002002002]\n",
            "Node 181: [0.2550123971131859, 0, 0, 0.001, 0.002, 0.1571729957805907, 2.0, 0.093, 0.001, 0.003003003003003003]\n",
            "Node 182: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.59, 0.002, 0.002002002002002002]\n",
            "Node 183: [1.3956263873379449, 0, 0, 0.001, 0.002, 0.30884965578503215, 2.0, 0.094, 0.001, 0.003003003003003003]\n",
            "Node 184: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 3.0, 0.591, 0.002, 0.002002002002002002]\n",
            "Node 185: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 2.0, 0.095, 0.001, 0.003003003003003003]\n",
            "Node 186: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 3.0, 0.592, 0.002, 0.002002002002002002]\n",
            "Node 187: [1.7145975031987486, 0, 0, 0.001, 0.002, 0.3512658227848101, 2.0, 0.096, 0.001, 0.003003003003003003]\n",
            "Node 188: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 3.0, 0.593, 0.002, 0.002002002002002002]\n",
            "Node 189: [1.6198246716537188, 0, 0, 0.001, 0.002, 0.33866311347990224, 2.0, 0.097, 0.001, 0.003003003003003003]\n",
            "Node 190: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.594, 0.002, 0.002002002002002002]\n",
            "Node 191: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 2.0, 0.098, 0.001, 0.003003003003003003]\n",
            "Node 192: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.595, 0.002, 0.002002002002002002]\n",
            "Node 193: [1.4916517232646265, 0, 0, 0.001, 0.002, 0.3216189207195203, 2.0, 0.099, 0.001, 0.003003003003003003]\n",
            "Node 194: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 3.0, 0.596, 0.002, 0.002002002002002002]\n",
            "Node 195: [0.8850221010843284, 0, 0, 0.001, 0.002, 0.24095047745947148, 2.0, 0.1, 0.001, 0.003003003003003003]\n",
            "Node 196: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.597, 0.002, 0.002002002002002002]\n",
            "Node 197: [0.24707986936272097, 0, 0, 0.001, 0.002, 0.15611814345991562, 2.0, 0.101, 0.001, 0.003003003003003003]\n",
            "Node 198: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.598, 0.002, 0.002002002002002002]\n",
            "Node 199: [0.2917525256416554, 0, 0, 0.001, 0.002, 0.16205862758161224, 2.0, 0.102, 0.001, 0.003003003003003003]\n",
            "Node 200: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 3.0, 0.599, 0.002, 0.002002002002002002]\n",
            "Node 201: [0.557283454551958, 0, 0, 0.001, 0.002, 0.19736842105263158, 2.0, 0.103, 0.001, 0.003003003003003003]\n",
            "Node 202: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 3.0, 0.6, 0.002, 0.002002002002002002]\n",
            "Node 203: [0.6925539277704141, 0, 0, 0.001, 0.002, 0.2153564290473018, 2.0, 0.104, 0.001, 0.003003003003003003]\n",
            "Node 204: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.601, 0.002, 0.002002002002002002]\n",
            "Node 205: [0.8637295265962379, 0, 0, 0.001, 0.002, 0.23811903175660667, 2.0, 0.105, 0.001, 0.003003003003003003]\n",
            "Node 206: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.602, 0.002, 0.002002002002002002]\n",
            "Node 207: [0.02496909234970057, 0, 0, 0.001, 0.002, 0.12658227848101267, 2.0, 0.106, 0.001, 0.003003003003003003]\n",
            "Node 208: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.603, 0.002, 0.002002002002002002]\n",
            "Node 209: [0.5510209326436962, 0, 0, 0.001, 0.002, 0.1965356429047302, 2.0, 0.107, 0.001, 0.003003003003003003]\n",
            "Node 210: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 3.0, 0.604, 0.002, 0.002002002002002002]\n",
            "Node 211: [0.6837863970988476, 0, 0, 0.001, 0.002, 0.21419053964023985, 2.0, 0.108, 0.001, 0.003003003003003003]\n",
            "Node 212: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 3.0, 0.605, 0.002, 0.002002002002002002]\n",
            "Node 213: [0.3456102140527074, 0, 0, 0.001, 0.002, 0.16922051965356427, 2.0, 0.109, 0.001, 0.003003003003003003]\n",
            "Node 214: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.606, 0.002, 0.002002002002002002]\n",
            "Node 215: [0.8424369521081477, 0, 0, 0.001, 0.002, 0.23528758605374192, 2.0, 0.11, 0.001, 0.003003003003003003]\n",
            "Node 216: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.607, 0.002, 0.002002002002002002]\n",
            "Node 217: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 2.0, 0.111, 0.001, 0.003003003003003003]\n",
            "Node 218: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.608, 0.002, 0.002002002002002002]\n",
            "Node 219: [1.673682360064771, 0, 0, 0.001, 0.002, 0.3458250055518543, 2.0, 0.112, 0.001, 0.003003003003003003]\n",
            "Node 220: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 3.0, 0.609, 0.002, 0.002002002002002002]\n",
            "Node 221: [6.593102069734732, 0, 0, 0.0, 0.125, 1.0, 0.0, 0.001, 0.0, 0.12512512512512514]\n",
            "Node 222: [0.9217622296127977, 0, 0, 0.001, 0.002, 0.245836109260493, 0.0, 0.113, 0.0, 0.003003003003003003]\n",
            "Node 223: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.61, 0.0, 0.002002002002002002]\n",
            "Node 224: [1.682032389275787, 0, 0, 0.001, 0.002, 0.34693537641572286, 0.0, 0.114, 0.0, 0.003003003003003003]\n",
            "Node 225: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.611, 0.0, 0.002002002002002002]\n",
            "Node 226: [0.6533087904786397, 0, 0, 0.001, 0.002, 0.21013768598711965, 0.0, 0.115, 0.0, 0.003003003003003003]\n",
            "Node 227: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.612, 0.0, 0.002002002002002002]\n",
            "Node 228: [1.2344708235653397, 0, 0, 0.001, 0.002, 0.28741949811236955, 0.0, 0.116, 0.0, 0.003003003003003003]\n",
            "Node 229: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.613, 0.0, 0.002002002002002002]\n",
            "Node 230: [0.8023568118952717, 0, 0, 0.001, 0.002, 0.22995780590717296, 0.0, 0.117, 0.0, 0.003003003003003003]\n",
            "Node 231: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.614, 0.0, 0.002002002002002002]\n",
            "Node 232: [1.7672026872281477, 0, 0, 0.001, 0.002, 0.3582611592271819, 0.0, 0.118, 0.0, 0.003003003003003003]\n",
            "Node 233: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.615, 0.0, 0.002002002002002002]\n",
            "Node 234: [0.9305297602843644, 0, 0, 0.001, 0.002, 0.24700199866755496, 0.0, 0.119, 0.0, 0.003003003003003003]\n",
            "Node 235: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.616, 0.0, 0.002002002002002002]\n",
            "Node 236: [0.6683388430584681, 0, 0, 0.001, 0.002, 0.21213635354208304, 0.0, 0.12, 0.0, 0.003003003003003003]\n",
            "Node 237: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.617, 0.0, 0.002002002002002002]\n",
            "Node 238: [1.5830845431252494, 0, 0, 0.001, 0.002, 0.3337774816788807, 0.0, 0.121, 0.0, 0.003003003003003003]\n",
            "Node 239: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.618, 0.0, 0.002002002002002002]\n",
            "Node 240: [0.9209272266916964, 0, 0, 0.001, 0.002, 0.24572507217410614, 0.0, 0.122, 0.0, 0.003003003003003003]\n",
            "Node 241: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.619, 0.0, 0.002002002002002002]\n",
            "Node 242: [1.1584855577450959, 0, 0, 0.001, 0.002, 0.27731512325116586, 0.0, 0.123, 0.0, 0.003003003003003003]\n",
            "Node 243: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.62, 0.0, 0.002002002002002002]\n",
            "Node 244: [0.3431052052894026, 0, 0, 0.001, 0.002, 0.16888740839440372, 0.0, 0.124, 0.0, 0.003003003003003003]\n",
            "Node 245: [-0.8851840916510221, 0, 0, 0.001, 0.001, 0.00555185431934266, 0.0, 0.621, 0.0, 0.002002002002002002]\n",
            "Node 246: [1.0006700056568971, 0, 0, 0.001, 0.002, 0.2563291139240506, 0.0, 0.125, 0.0, 0.003003003003003003]\n",
            "Node 247: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.622, 0.0, 0.002002002002002002]\n",
            "Node 248: [0.9923199764458815, 0, 0, 0.001, 0.002, 0.2552187430601821, 0.0, 0.126, 0.0, 0.003003003003003003]\n",
            "Node 249: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.623, 0.0, 0.002002002002002002]\n",
            "Node 250: [0.5393308917482741, 0, 0, 0.001, 0.002, 0.19498112369531423, 0.0, 0.127, 0.0, 0.003003003003003003]\n",
            "Node 251: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.624, 0.0, 0.002002002002002002]\n",
            "Node 252: [0.157317055344301, 0, 0, 0.001, 0.002, 0.14418165667332888, 0.0, 0.128, 0.0, 0.003003003003003003]\n",
            "Node 253: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.625, 0.0, 0.002002002002002002]\n",
            "Node 254: [0.8679045412017459, 0, 0, 0.001, 0.002, 0.23867421718854095, 0.0, 0.129, 0.0, 0.003003003003003003]\n",
            "Node 255: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.626, 0.0, 0.002002002002002002]\n",
            "Node 256: [0.781899240328283, 0, 0, 0.001, 0.002, 0.22723739729069506, 0.0, 0.13, 0.0, 0.003003003003003003]\n",
            "Node 257: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.627, 0.0, 0.002002002002002002]\n",
            "Node 258: [0.3940403834765989, 0, 0, 0.001, 0.002, 0.17566067066400176, 0.0, 0.131, 0.0, 0.003003003003003003]\n",
            "Node 259: [-0.9110691822051711, 0, 0, 0.001, 0.001, 0.002109704641350211, 0.0, 0.628, 0.0, 0.002002002002002002]\n",
            "Node 260: [1.2553458965928792, 0, 0, 0.001, 0.002, 0.29019542527204084, 0.0, 0.132, 0.0, 0.003003003003003003]\n",
            "Node 261: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.629, 0.0, 0.002002002002002002]\n",
            "Node 262: [0.10972188884151088, 0, 0, 0.001, 0.002, 0.13785254274927825, 0.0, 0.133, 0.0, 0.003003003003003003]\n",
            "Node 263: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.63, 0.0, 0.002002002002002002]\n",
            "Node 264: [0.08007928514240488, 0, 0, 0.001, 0.002, 0.13391072618254496, 0.0, 0.134, 0.0, 0.003003003003003003]\n",
            "Node 265: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.631, 0.0, 0.002002002002002002]\n",
            "Node 266: [-0.041413639877875066, 0, 0, 0.001, 0.002, 0.11775483011325782, 0.0, 0.135, 0.0, 0.003003003003003003]\n",
            "Node 267: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.632, 0.0, 0.002002002002002002]\n",
            "Node 268: [1.4795441809086534, 0, 0, 0.001, 0.002, 0.32000888296691093, 0.0, 0.136, 0.0, 0.003003003003003003]\n",
            "Node 269: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.633, 0.0, 0.002002002002002002]\n",
            "Node 270: [1.0716452539505317, 0, 0, 0.001, 0.002, 0.26576726626693314, 0.0, 0.137, 0.0, 0.003003003003003003]\n",
            "Node 271: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.634, 0.0, 0.002002002002002002]\n",
            "Node 272: [0.06170922087817007, 0, 0, 0.001, 0.002, 0.1314679102820342, 0.0, 0.138, 0.0, 0.003003003003003003]\n",
            "Node 273: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.635, 0.0, 0.002002002002002002]\n",
            "Node 274: [1.15013552853408, 0, 0, 0.001, 0.002, 0.2762047523872973, 0.0, 0.139, 0.0, 0.003003003003003003]\n",
            "Node 275: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.636, 0.0, 0.002002002002002002]\n",
            "Node 276: [1.637777234457403, 0, 0, 0.001, 0.002, 0.3410504108372196, 0.0, 0.14, 0.0, 0.003003003003003003]\n",
            "Node 277: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.637, 0.0, 0.002002002002002002]\n",
            "Node 278: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.141, 0.0, 0.003003003003003003]\n",
            "Node 279: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.638, 0.0, 0.002002002002002002]\n",
            "Node 280: [1.2524233863690237, 0, 0, 0.001, 0.002, 0.28980679546968685, 0.0, 0.142, 0.0, 0.003003003003003003]\n",
            "Node 281: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.639, 0.0, 0.002002002002002002]\n",
            "Node 282: [0.7906667709998496, 0, 0, 0.001, 0.002, 0.22840328669775703, 0.0, 0.143, 0.0, 0.003003003003003003]\n",
            "Node 283: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.64, 0.0, 0.002002002002002002]\n",
            "Node 284: [0.9013046580458093, 0, 0, 0.001, 0.002, 0.2431157006440151, 0.0, 0.144, 0.0, 0.003003003003003003]\n",
            "Node 285: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.641, 0.0, 0.002002002002002002]\n",
            "Node 286: [0.30761758114258553, 0, 0, 0.001, 0.002, 0.16416833222296245, 0.0, 0.145, 0.0, 0.003003003003003003]\n",
            "Node 287: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.642, 0.0, 0.002002002002002002]\n",
            "Node 288: [0.1685895947791723, 0, 0, 0.001, 0.002, 0.1456806573395514, 0.0, 0.146, 0.0, 0.003003003003003003]\n",
            "Node 289: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.643, 0.0, 0.002002002002002002]\n",
            "Node 290: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.147, 0.0, 0.003003003003003003]\n",
            "Node 291: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.644, 0.0, 0.002002002002002002]\n",
            "Node 292: [1.3501187281379086, 0, 0, 0.001, 0.002, 0.3027981345769487, 0.0, 0.148, 0.0, 0.003003003003003003]\n",
            "Node 293: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.645, 0.0, 0.002002002002002002]\n",
            "Node 294: [0.5172033143390822, 0, 0, 0.001, 0.002, 0.19203864090606262, 0.0, 0.149, 0.0, 0.003003003003003003]\n",
            "Node 295: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.646, 0.0, 0.002002002002002002]\n",
            "Node 296: [1.3325836667947755, 0, 0, 0.001, 0.002, 0.30046635576282477, 0.0, 0.15, 0.0, 0.003003003003003003]\n",
            "Node 297: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.647, 0.0, 0.002002002002002002]\n",
            "Node 298: [1.6720123542225676, 0, 0, 0.001, 0.002, 0.34560293137908055, 0.0, 0.151, 0.0, 0.003003003003003003]\n",
            "Node 299: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.648, 0.0, 0.002002002002002002]\n",
            "Node 300: [0.9326172675871185, 0, 0, 0.001, 0.002, 0.2472795913835221, 0.0, 0.152, 0.0, 0.003003003003003003]\n",
            "Node 301: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.649, 0.0, 0.002002002002002002]\n",
            "Node 302: [0.4128279492013846, 0, 0, 0.001, 0.002, 0.17815900510770596, 0.0, 0.153, 0.0, 0.003003003003003003]\n",
            "Node 303: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.65, 0.0, 0.002002002002002002]\n",
            "Node 304: [0.953492340614658, 0, 0, 0.001, 0.002, 0.2500555185431934, 0.0, 0.154, 0.0, 0.003003003003003003]\n",
            "Node 305: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.651, 0.0, 0.002002002002002002]\n",
            "Node 306: [0.3209776278802108, 0, 0, 0.001, 0.002, 0.16594492560515212, 0.0, 0.155, 0.0, 0.003003003003003003]\n",
            "Node 307: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.652, 0.0, 0.002002002002002002]\n",
            "Node 308: [1.1831181439175926, 0, 0, 0.001, 0.002, 0.2805907172995781, 0.0, 0.156, 0.0, 0.003003003003003003]\n",
            "Node 309: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.653, 0.0, 0.002002002002002002]\n",
            "Node 310: [0.3201426249591092, 0, 0, 0.001, 0.002, 0.16583388851876527, 0.0, 0.157, 0.0, 0.003003003003003003]\n",
            "Node 311: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.654, 0.0, 0.002002002002002002]\n",
            "Node 312: [1.0374101341853668, 0, 0, 0.001, 0.002, 0.2612147457250722, 0.0, 0.158, 0.0, 0.003003003003003003]\n",
            "Node 313: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.655, 0.0, 0.002002002002002002]\n",
            "Node 314: [1.7388125879106944, 0, 0, 0.001, 0.002, 0.35448589829002886, 0.0, 0.159, 0.0, 0.003003003003003003]\n",
            "Node 315: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.656, 0.0, 0.002002002002002002]\n",
            "Node 316: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 0.0, 0.16, 0.0, 0.003003003003003003]\n",
            "Node 317: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.657, 0.0, 0.002002002002002002]\n",
            "Node 318: [0.7514216337080755, 0, 0, 0.001, 0.002, 0.22318454363757492, 0.0, 0.161, 0.0, 0.003003003003003003]\n",
            "Node 319: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.658, 0.0, 0.002002002002002002]\n",
            "Node 320: [0.5915185743171228, 0, 0, 0.001, 0.002, 0.20192094159449256, 0.0, 0.162, 0.0, 0.003003003003003003]\n",
            "Node 321: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.659, 0.0, 0.002002002002002002]\n",
            "Node 322: [0.8942071332164457, 0, 0, 0.001, 0.002, 0.2421718854097268, 0.0, 0.163, 0.0, 0.003003003003003003]\n",
            "Node 323: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.66, 0.0, 0.002002002002002002]\n",
            "Node 324: [0.4032254156087163, 0, 0, 0.001, 0.002, 0.17688207861425712, 0.0, 0.164, 0.0, 0.003003003003003003]\n",
            "Node 325: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.661, 0.0, 0.002002002002002002]\n",
            "Node 326: [1.1438730066258183, 0, 0, 0.001, 0.002, 0.2753719742393959, 0.0, 0.165, 0.0, 0.003003003003003003]\n",
            "Node 327: [-0.8960391296253427, 0, 0, 0.001, 0.001, 0.004108372196313569, 0.0, 0.662, 0.0, 0.002002002002002002]\n",
            "Node 328: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.166, 0.0, 0.003003003003003003]\n",
            "Node 329: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.663, 0.0, 0.002002002002002002]\n",
            "Node 330: [1.4720291546187394, 0, 0, 0.001, 0.002, 0.31900954918942925, 0.0, 0.167, 0.0, 0.003003003003003003]\n",
            "Node 331: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.664, 0.0, 0.002002002002002002]\n",
            "Node 332: [1.5192068196609785, 0, 0, 0.001, 0.002, 0.3252831445702865, 0.0, 0.168, 0.0, 0.003003003003003003]\n",
            "Node 333: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.665, 0.0, 0.002002002002002002]\n",
            "Node 334: [0.0608742179570685, 0, 0, 0.001, 0.002, 0.13135687319564732, 0.0, 0.169, 0.0, 0.003003003003003003]\n",
            "Node 335: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.666, 0.0, 0.002002002002002002]\n",
            "Node 336: [0.34185270090775033, 0, 0, 0.001, 0.002, 0.16872085276482346, 0.0, 0.17, 0.0, 0.003003003003003003]\n",
            "Node 337: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.667, 0.0, 0.002002002002002002]\n",
            "Node 338: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.171, 0.0, 0.003003003003003003]\n",
            "Node 339: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.668, 0.0, 0.002002002002002002]\n",
            "Node 340: [0.5280583523134026, 0, 0, 0.001, 0.002, 0.19348212302909168, 0.0, 0.172, 0.0, 0.003003003003003003]\n",
            "Node 341: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.669, 0.0, 0.002002002002002002]\n",
            "Node 342: [0.4332855207683734, 0, 0, 0.001, 0.002, 0.1808794137241839, 0.0, 0.173, 0.0, 0.003003003003003003]\n",
            "Node 343: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.67, 0.0, 0.002002002002002002]\n",
            "Node 344: [1.698732447697818, 0, 0, 0.001, 0.002, 0.34915611814345987, 0.0, 0.174, 0.0, 0.003003003003003003]\n",
            "Node 345: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.671, 0.0, 0.002002002002002002]\n",
            "Node 346: [0.5577009560125088, 0, 0, 0.001, 0.002, 0.197423939595825, 0.0, 0.175, 0.0, 0.003003003003003003]\n",
            "Node 347: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.672, 0.0, 0.002002002002002002]\n",
            "Node 348: [1.54634441459678, 0, 0, 0.001, 0.002, 0.3288918498778592, 0.0, 0.176, 0.0, 0.003003003003003003]\n",
            "Node 349: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.673, 0.0, 0.002002002002002002]\n",
            "Node 350: [1.6256696921014298, 0, 0, 0.001, 0.002, 0.3394403730846102, 0.0, 0.177, 0.0, 0.003003003003003003]\n",
            "Node 351: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.674, 0.0, 0.002002002002002002]\n",
            "Node 352: [0.883352095242125, 0, 0, 0.001, 0.002, 0.24072840328669773, 0.0, 0.178, 0.0, 0.003003003003003003]\n",
            "Node 353: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.675, 0.0, 0.002002002002002002]\n",
            "Node 354: [1.5212943269637322, 0, 0, 0.001, 0.002, 0.32556073728625357, 0.0, 0.179, 0.0, 0.003003003003003003]\n",
            "Node 355: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.676, 0.0, 0.002002002002002002]\n",
            "Node 356: [0.8040268177374749, 0, 0, 0.001, 0.002, 0.2301798800799467, 0.0, 0.18, 0.0, 0.003003003003003003]\n",
            "Node 357: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.677, 0.0, 0.002002002002002002]\n",
            "Node 358: [-0.025131082916394373, 0, 0, 0.001, 0.002, 0.11992005329780143, 0.0, 0.181, 0.0, 0.003003003003003003]\n",
            "Node 359: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.678, 0.0, 0.002002002002002002]\n",
            "Node 360: [1.122580432137728, 0, 0, 0.001, 0.002, 0.2725405285365312, 0.0, 0.182, 0.0, 0.003003003003003003]\n",
            "Node 361: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.679, 0.0, 0.002002002002002002]\n",
            "Node 362: [1.7617751682409877, 0, 0, 0.001, 0.002, 0.35753941816566737, 0.0, 0.183, 0.0, 0.003003003003003003]\n",
            "Node 363: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.68, 0.0, 0.002002002002002002]\n",
            "Node 364: [0.5606234662363643, 0, 0, 0.001, 0.002, 0.19781256939817896, 0.0, 0.184, 0.0, 0.003003003003003003]\n",
            "Node 365: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.681, 0.0, 0.002002002002002002]\n",
            "Node 366: [0.2516723854287796, 0, 0, 0.001, 0.002, 0.15672884743504328, 0.0, 0.185, 0.0, 0.003003003003003003]\n",
            "Node 367: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.682, 0.0, 0.002002002002002002]\n",
            "Node 368: [0.3977978966215562, 0, 0, 0.001, 0.002, 0.1761603375527426, 0.0, 0.186, 0.0, 0.003003003003003003]\n",
            "Node 369: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.683, 0.0, 0.002002002002002002]\n",
            "Node 370: [1.7162675090409514, 0, 0, 0.001, 0.002, 0.35148789695758376, 0.0, 0.187, 0.0, 0.003003003003003003]\n",
            "Node 371: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.684, 0.0, 0.002002002002002002]\n",
            "Node 372: [0.16733709039752004, 0, 0, 0.001, 0.002, 0.14551410170997112, 0.0, 0.188, 0.0, 0.003003003003003003]\n",
            "Node 373: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.685, 0.0, 0.002002002002002002]\n",
            "Node 374: [0.5873435597116149, 0, 0, 0.001, 0.002, 0.2013657561625583, 0.0, 0.189, 0.0, 0.003003003003003003]\n",
            "Node 375: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.686, 0.0, 0.002002002002002002]\n",
            "Node 376: [0.44288805436104145, 0, 0, 0.001, 0.002, 0.18215634021763266, 0.0, 0.19, 0.0, 0.003003003003003003]\n",
            "Node 377: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.687, 0.0, 0.002002002002002002]\n",
            "Node 378: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.191, 0.0, 0.003003003003003003]\n",
            "Node 379: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.688, 0.0, 0.002002002002002002]\n",
            "Node 380: [0.5426709034326803, 0, 0, 0.001, 0.002, 0.19542527204086163, 0.0, 0.192, 0.0, 0.003003003003003003]\n",
            "Node 381: [-0.9227592231005933, 0, 0, 0.001, 0.001, 0.0005551854319342662, 0.0, 0.689, 0.0, 0.002002002002002002]\n",
            "Node 382: [0.016201561678133938, 0, 0, 0.001, 0.002, 0.1254163890739507, 0.0, 0.193, 0.0, 0.003003003003003003]\n",
            "Node 383: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.69, 0.0, 0.002002002002002002]\n",
            "Node 384: [0.3973803951610055, 0, 0, 0.001, 0.002, 0.1761048190095492, 0.0, 0.194, 0.0, 0.003003003003003003]\n",
            "Node 385: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.691, 0.0, 0.002002002002002002]\n",
            "Node 386: [1.6945574330923105, 0, 0, 0.001, 0.002, 0.34860093271152565, 0.0, 0.195, 0.0, 0.003003003003003003]\n",
            "Node 387: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.692, 0.0, 0.002002002002002002]\n",
            "Node 388: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 0.0, 0.196, 0.0, 0.003003003003003003]\n",
            "Node 389: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.693, 0.0, 0.002002002002002002]\n",
            "Node 390: [0.5506034311831453, 0, 0, 0.001, 0.002, 0.19648012436153672, 0.0, 0.197, 0.0, 0.003003003003003003]\n",
            "Node 391: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.694, 0.0, 0.002002002002002002]\n",
            "Node 392: [0.13143196479015196, 0, 0, 0.001, 0.002, 0.1407395069953364, 0.0, 0.198, 0.0, 0.003003003003003003]\n",
            "Node 393: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.695, 0.0, 0.002002002002002002]\n",
            "Node 394: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.199, 0.0, 0.003003003003003003]\n",
            "Node 395: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.696, 0.0, 0.002002002002002002]\n",
            "Node 396: [1.6766048702886263, 0, 0, 0.001, 0.002, 0.3462136353542083, 0.0, 0.2, 0.0, 0.003003003003003003]\n",
            "Node 397: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.697, 0.0, 0.002002002002002002]\n",
            "Node 398: [0.8453594623320032, 0, 0, 0.001, 0.002, 0.2356762158560959, 0.0, 0.201, 0.0, 0.003003003003003003]\n",
            "Node 399: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.698, 0.0, 0.002002002002002002]\n",
            "Node 400: [1.5835020445858004, 0, 0, 0.001, 0.002, 0.3338330002220741, 0.0, 0.202, 0.0, 0.003003003003003003]\n",
            "Node 401: [-0.8826790828877173, 0, 0, 0.001, 0.001, 0.005884965578503219, 0.0, 0.699, 0.0, 0.002002002002002002]\n",
            "Node 402: [0.8603895149118317, 0, 0, 0.001, 0.002, 0.23767488341105925, 0.0, 0.203, 0.0, 0.003003003003003003]\n",
            "Node 403: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.7, 0.0, 0.002002002002002002]\n",
            "Node 404: [1.540499394149069, 0, 0, 0.001, 0.002, 0.3281145902731512, 0.0, 0.204, 0.0, 0.003003003003003003]\n",
            "Node 405: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.701, 0.0, 0.002002002002002002]\n",
            "Node 406: [1.7229475324097638, 0, 0, 0.001, 0.002, 0.35237619364867867, 0.0, 0.205, 0.0, 0.003003003003003003]\n",
            "Node 407: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.702, 0.0, 0.002002002002002002]\n",
            "Node 408: [0.5188733201812853, 0, 0, 0.001, 0.002, 0.1922607150788363, 0.0, 0.206, 0.0, 0.003003003003003003]\n",
            "Node 409: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.703, 0.0, 0.002002002002002002]\n",
            "Node 410: [0.4245179900968068, 0, 0, 0.001, 0.002, 0.17971352431712193, 0.0, 0.207, 0.0, 0.003003003003003003]\n",
            "Node 411: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.704, 0.0, 0.002002002002002002]\n",
            "Node 412: [-0.015111047863175325, 0, 0, 0.001, 0.002, 0.1212524983344437, 0.0, 0.208, 0.0, 0.003003003003003003]\n",
            "Node 413: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.705, 0.0, 0.002002002002002002]\n",
            "Node 414: [-0.007178520112710406, 0, 0, 0.001, 0.002, 0.12230735065511879, 0.0, 0.209, 0.0, 0.003003003003003003]\n",
            "Node 415: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.706, 0.0, 0.002002002002002002]\n",
            "Node 416: [0.38777786156833716, 0, 0, 0.001, 0.002, 0.17482789251610037, 0.0, 0.21, 0.0, 0.003003003003003003]\n",
            "Node 417: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.707, 0.0, 0.002002002002002002]\n",
            "Node 418: [-0.03556861943016413, 0, 0, 0.001, 0.002, 0.11853208971796576, 0.0, 0.211, 0.0, 0.003003003003003003]\n",
            "Node 419: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.708, 0.0, 0.002002002002002002]\n",
            "Node 420: [1.7279575499363735, 0, 0, 0.001, 0.002, 0.3530424161669998, 0.0, 0.212, 0.0, 0.003003003003003003]\n",
            "Node 421: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.709, 0.0, 0.002002002002002002]\n",
            "Node 422: [0.2600224146397954, 0, 0, 0.001, 0.002, 0.15783921829891182, 0.0, 0.213, 0.0, 0.003003003003003003]\n",
            "Node 423: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.71, 0.0, 0.002002002002002002]\n",
            "Node 424: [0.7764717213411229, 0, 0, 0.001, 0.002, 0.22651565622918055, 0.0, 0.214, 0.0, 0.003003003003003003]\n",
            "Node 425: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.711, 0.0, 0.002002002002002002]\n",
            "Node 426: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 0.0, 0.215, 0.0, 0.003003003003003003]\n",
            "Node 427: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.712, 0.0, 0.002002002002002002]\n",
            "Node 428: [0.2537598927315335, 0, 0, 0.001, 0.002, 0.15700644015101042, 0.0, 0.216, 0.0, 0.003003003003003003]\n",
            "Node 429: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.713, 0.0, 0.002002002002002002]\n",
            "Node 430: [0.6144811546474163, 0, 0, 0.001, 0.002, 0.20497446147013101, 0.0, 0.217, 0.0, 0.003003003003003003]\n",
            "Node 431: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.714, 0.0, 0.002002002002002002]\n",
            "Node 432: [1.386858856666378, 0, 0, 0.001, 0.002, 0.30768376637797024, 0.0, 0.218, 0.0, 0.003003003003003003]\n",
            "Node 433: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.715, 0.0, 0.002002002002002002]\n",
            "Node 434: [0.9196747223100439, 0, 0, 0.001, 0.002, 0.24555851654452587, 0.0, 0.219, 0.0, 0.003003003003003003]\n",
            "Node 435: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.716, 0.0, 0.002002002002002002]\n",
            "Node 436: [0.45833560840142057, 0, 0, 0.001, 0.002, 0.18421052631578946, 0.0, 0.22, 0.0, 0.003003003003003003]\n",
            "Node 437: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.717, 0.0, 0.002002002002002002]\n",
            "Node 438: [1.4695241458554344, 0, 0, 0.001, 0.002, 0.31867643793026873, 0.0, 0.221, 0.0, 0.003003003003003003]\n",
            "Node 439: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.718, 0.0, 0.002002002002002002]\n",
            "Node 440: [0.8829345937815742, 0, 0, 0.001, 0.002, 0.2406728847435043, 0.0, 0.222, 0.0, 0.003003003003003003]\n",
            "Node 441: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.719, 0.0, 0.002002002002002002]\n",
            "Node 442: [0.21910727150581794, 0, 0, 0.001, 0.002, 0.152398401065956, 0.0, 0.223, 0.0, 0.003003003003003003]\n",
            "Node 443: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.72, 0.0, 0.002002002002002002]\n",
            "Node 444: [0.9701923990366895, 0, 0, 0.001, 0.002, 0.2522762602709305, 0.0, 0.224, 0.0, 0.003003003003003003]\n",
            "Node 445: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.721, 0.0, 0.002002002002002002]\n",
            "Node 446: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.225, 0.0, 0.003003003003003003]\n",
            "Node 447: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.722, 0.0, 0.002002002002002002]\n",
            "Node 448: [0.7672866892090056, 0, 0, 0.001, 0.002, 0.22529424827892516, 0.0, 0.226, 0.0, 0.003003003003003003]\n",
            "Node 449: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.723, 0.0, 0.002002002002002002]\n",
            "Node 450: [1.6386122373785044, 0, 0, 0.001, 0.002, 0.3411614479236065, 0.0, 0.227, 0.0, 0.003003003003003003]\n",
            "Node 451: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.724, 0.0, 0.002002002002002002]\n",
            "Node 452: [1.4937392305673802, 0, 0, 0.001, 0.002, 0.3218965134354874, 0.0, 0.228, 0.0, 0.003003003003003003]\n",
            "Node 453: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.725, 0.0, 0.002002002002002002]\n",
            "Node 454: [1.09210282551752, 0, 0, 0.001, 0.002, 0.268487674883411, 0.0, 0.229, 0.0, 0.003003003003003003]\n",
            "Node 455: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.726, 0.0, 0.002002002002002002]\n",
            "Node 456: [0.4165854623463416, 0, 0, 0.001, 0.002, 0.1786586719964468, 0.0, 0.23, 0.0, 0.003003003003003003]\n",
            "Node 457: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.727, 0.0, 0.002002002002002002]\n",
            "Node 458: [0.43412052368947485, 0, 0, 0.001, 0.002, 0.1809904508105707, 0.0, 0.231, 0.0, 0.003003003003003003]\n",
            "Node 459: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.728, 0.0, 0.002002002002002002]\n",
            "Node 460: [0.9518223347724546, 0, 0, 0.001, 0.002, 0.24983344437041966, 0.0, 0.232, 0.0, 0.003003003003003003]\n",
            "Node 461: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.729, 0.0, 0.002002002002002002]\n",
            "Node 462: [0.44622806604544774, 0, 0, 0.001, 0.002, 0.18260048856318006, 0.0, 0.233, 0.0, 0.003003003003003003]\n",
            "Node 463: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.73, 0.0, 0.002002002002002002]\n",
            "Node 464: [1.6949749345528615, 0, 0, 0.001, 0.002, 0.34865645125471906, 0.0, 0.234, 0.0, 0.003003003003003003]\n",
            "Node 465: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.731, 0.0, 0.002002002002002002]\n",
            "Node 466: [1.610222138061051, 0, 0, 0.001, 0.002, 0.33738618698645345, 0.0, 0.235, 0.0, 0.003003003003003003]\n",
            "Node 467: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.732, 0.0, 0.002002002002002002]\n",
            "Node 468: [1.0040100173413034, 0, 0, 0.001, 0.002, 0.256773262269598, 0.0, 0.236, 0.0, 0.003003003003003003]\n",
            "Node 469: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.733, 0.0, 0.002002002002002002]\n",
            "Node 470: [0.3080350826031362, 0, 0, 0.001, 0.002, 0.1642238507661559, 0.0, 0.237, 0.0, 0.003003003003003003]\n",
            "Node 471: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.734, 0.0, 0.002002002002002002]\n",
            "Node 472: [3.5207088215414664, 0, 0, 0.0, 0.131, 0.5914390406395736, 0.0, 0.002, 0.0, 0.13113113113113112]\n",
            "Node 473: [0.3898653688710913, 0, 0, 0.001, 0.002, 0.1751054852320675, 0.0, 0.238, 0.0, 0.003003003003003003]\n",
            "Node 474: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.735, 0.0, 0.002002002002002002]\n",
            "Node 475: [1.5317318634775021, 0, 0, 0.001, 0.002, 0.32694870086608924, 0.0, 0.239, 0.0, 0.003003003003003003]\n",
            "Node 476: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.736, 0.0, 0.002002002002002002]\n",
            "Node 477: [0.7397315928126532, 0, 0, 0.001, 0.002, 0.221630024428159, 0.0, 0.24, 0.0, 0.003003003003003003]\n",
            "Node 478: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.737, 0.0, 0.002002002002002002]\n",
            "Node 479: [0.17025960062137543, 0, 0, 0.001, 0.002, 0.1459027315123251, 0.0, 0.241, 0.0, 0.003003003003003003]\n",
            "Node 480: [-0.9035541559152569, 0, 0, 0.001, 0.001, 0.0031090384188318895, 0.0, 0.738, 0.0, 0.002002002002002002]\n",
            "Node 481: [0.5627109735391181, 0, 0, 0.001, 0.002, 0.1980901621141461, 0.0, 0.242, 0.0, 0.003003003003003003]\n",
            "Node 482: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.739, 0.0, 0.002002002002002002]\n",
            "Node 483: [-0.008848525954913531, 0, 0, 0.001, 0.002, 0.1220852764823451, 0.0, 0.243, 0.0, 0.003003003003003003]\n",
            "Node 484: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.74, 0.0, 0.002002002002002002]\n",
            "Node 485: [0.8061143250402291, 0, 0, 0.001, 0.002, 0.23045747279591383, 0.0, 0.244, 0.0, 0.003003003003003003]\n",
            "Node 486: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.741, 0.0, 0.002002002002002002]\n",
            "Node 487: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.245, 0.0, 0.003003003003003003]\n",
            "Node 488: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.742, 0.0, 0.002002002002002002]\n",
            "Node 489: [1.615649657048211, 0, 0, 0.001, 0.002, 0.338107928047968, 0.0, 0.246, 0.0, 0.003003003003003003]\n",
            "Node 490: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.743, 0.0, 0.002002002002002002]\n",
            "Node 491: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.247, 0.0, 0.003003003003003003]\n",
            "Node 492: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.744, 0.0, 0.002002002002002002]\n",
            "Node 493: [0.36940779730410245, 0, 0, 0.001, 0.002, 0.1723850766155896, 0.0, 0.248, 0.0, 0.003003003003003003]\n",
            "Node 494: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.745, 0.0, 0.002002002002002002]\n",
            "Node 495: [0.22536979341407973, 0, 0, 0.001, 0.002, 0.1532311792138574, 0.0, 0.249, 0.0, 0.003003003003003003]\n",
            "Node 496: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.746, 0.0, 0.002002002002002002]\n",
            "Node 497: [1.5713945022298272, 0, 0, 0.001, 0.002, 0.3322229624694648, 0.0, 0.25, 0.0, 0.003003003003003003]\n",
            "Node 498: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.747, 0.0, 0.002002002002002002]\n",
            "Node 499: [1.1434555051652675, 0, 0, 0.001, 0.002, 0.27531645569620256, 0.0, 0.251, 0.0, 0.003003003003003003]\n",
            "Node 500: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.748, 0.0, 0.002002002002002002]\n",
            "Node 501: [1.659487310406044, 0, 0, 0.001, 0.002, 0.3439373750832778, 0.0, 0.252, 0.0, 0.003003003003003003]\n",
            "Node 502: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.749, 0.0, 0.002002002002002002]\n",
            "Node 503: [0.8211443776200574, 0, 0, 0.001, 0.002, 0.2324561403508772, 0.0, 0.253, 0.0, 0.003003003003003003]\n",
            "Node 504: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.75, 0.0, 0.002002002002002002]\n",
            "Node 505: [1.7358900776868385, 0, 0, 0.001, 0.002, 0.35409726848767487, 0.0, 0.254, 0.0, 0.003003003003003003]\n",
            "Node 506: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.751, 0.0, 0.002002002002002002]\n",
            "Node 507: [1.161825569429502, 0, 0, 0.001, 0.002, 0.2777592715967133, 0.0, 0.255, 0.0, 0.003003003003003003]\n",
            "Node 508: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.752, 0.0, 0.002002002002002002]\n",
            "Node 509: [1.6290097037858366, 0, 0, 0.001, 0.002, 0.3398845214301577, 0.0, 0.256, 0.0, 0.003003003003003003]\n",
            "Node 510: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.753, 0.0, 0.002002002002002002]\n",
            "Node 511: [1.7642801770042924, 0, 0, 0.001, 0.002, 0.35787252942482795, 0.0, 0.257, 0.0, 0.003003003003003003]\n",
            "Node 512: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.754, 0.0, 0.002002002002002002]\n",
            "Node 513: [0.13226696771125365, 0, 0, 0.001, 0.002, 0.1408505440817233, 0.0, 0.258, 0.0, 0.003003003003003003]\n",
            "Node 514: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.755, 0.0, 0.002002002002002002]\n",
            "Node 515: [0.32056012641966, 0, 0, 0.001, 0.002, 0.16588940706195868, 0.0, 0.259, 0.0, 0.003003003003003003]\n",
            "Node 516: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.756, 0.0, 0.002002002002002002]\n",
            "Node 517: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.26, 0.0, 0.003003003003003003]\n",
            "Node 518: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.757, 0.0, 0.002002002002002002]\n",
            "Node 519: [0.028726605494657675, 0, 0, 0.001, 0.002, 0.1270819453697535, 0.0, 0.261, 0.0, 0.003003003003003003]\n",
            "Node 520: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.758, 0.0, 0.002002002002002002]\n",
            "Node 521: [1.3363411799397324, 0, 0, 0.001, 0.002, 0.30096602265156563, 0.0, 0.262, 0.0, 0.003003003003003003]\n",
            "Node 522: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.759, 0.0, 0.002002002002002002]\n",
            "Node 523: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.263, 0.0, 0.003003003003003003]\n",
            "Node 524: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.76, 0.0, 0.002002002002002002]\n",
            "Node 525: [1.0683052422661252, 0, 0, 0.001, 0.002, 0.26532311792138574, 0.0, 0.264, 0.0, 0.003003003003003003]\n",
            "Node 526: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.761, 0.0, 0.002002002002002002]\n",
            "Node 527: [1.5388293883068656, 0, 0, 0.001, 0.002, 0.32789251610037745, 0.0, 0.265, 0.0, 0.003003003003003003]\n",
            "Node 528: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.762, 0.0, 0.002002002002002002]\n",
            "Node 529: [0.547263419498739, 0, 0, 0.001, 0.002, 0.19603597601598932, 0.0, 0.266, 0.0, 0.003003003003003003]\n",
            "Node 530: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.763, 0.0, 0.002002002002002002]\n",
            "Node 531: [0.7756367184200212, 0, 0, 0.001, 0.002, 0.22640461914279367, 0.0, 0.267, 0.0, 0.003003003003003003]\n",
            "Node 532: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.764, 0.0, 0.002002002002002002]\n",
            "Node 533: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.268, 0.0, 0.003003003003003003]\n",
            "Node 534: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.765, 0.0, 0.002002002002002002]\n",
            "Node 535: [1.378926328915913, 0, 0, 0.001, 0.002, 0.30662891405729514, 0.0, 0.269, 0.0, 0.003003003003003003]\n",
            "Node 536: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.766, 0.0, 0.002002002002002002]\n",
            "Node 537: [0.8219793805411589, 0, 0, 0.001, 0.002, 0.23256717743726402, 0.0, 0.27, 0.0, 0.003003003003003003]\n",
            "Node 538: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.767, 0.0, 0.002002002002002002]\n",
            "Node 539: [0.578993530500599, 0, 0, 0.001, 0.002, 0.20025538529868972, 0.0, 0.271, 0.0, 0.003003003003003003]\n",
            "Node 540: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.768, 0.0, 0.002002002002002002]\n",
            "Node 541: [1.0916853240569693, 0, 0, 0.001, 0.002, 0.2684321563402176, 0.0, 0.272, 0.0, 0.003003003003003003]\n",
            "Node 542: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.769, 0.0, 0.002002002002002002]\n",
            "Node 543: [0.684621400019949, 0, 0, 0.001, 0.002, 0.21430157672662667, 0.0, 0.273, 0.0, 0.003003003003003003]\n",
            "Node 544: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.77, 0.0, 0.002002002002002002]\n",
            "Node 545: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.274, 0.0, 0.003003003003003003]\n",
            "Node 546: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.771, 0.0, 0.002002002002002002]\n",
            "Node 547: [0.5067657778253124, 0, 0, 0.001, 0.002, 0.19065067732622695, 0.0, 0.275, 0.0, 0.003003003003003003]\n",
            "Node 548: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.772, 0.0, 0.002002002002002002]\n",
            "Node 549: [0.3088700855242378, 0, 0, 0.001, 0.002, 0.16433488785254272, 0.0, 0.276, 0.0, 0.003003003003003003]\n",
            "Node 550: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.773, 0.0, 0.002002002002002002]\n",
            "Node 551: [0.9125771974806804, 0, 0, 0.001, 0.002, 0.24461470131023758, 0.0, 0.277, 0.0, 0.003003003003003003]\n",
            "Node 552: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.774, 0.0, 0.002002002002002002]\n",
            "Node 553: [0.599033600607037, 0, 0, 0.001, 0.002, 0.20292027537197424, 0.0, 0.278, 0.0, 0.003003003003003003]\n",
            "Node 554: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.775, 0.0, 0.002002002002002002]\n",
            "Node 555: [1.0340701225009605, 0, 0, 0.001, 0.002, 0.26077059737952474, 0.0, 0.279, 0.0, 0.003003003003003003]\n",
            "Node 556: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.776, 0.0, 0.002002002002002002]\n",
            "Node 557: [0.8662345353595428, 0, 0, 0.001, 0.002, 0.23845214301576725, 0.0, 0.28, 0.0, 0.003003003003003003]\n",
            "Node 558: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.777, 0.0, 0.002002002002002002]\n",
            "Node 559: [1.6912174214079043, 0, 0, 0.001, 0.002, 0.34815678436597824, 0.0, 0.281, 0.0, 0.003003003003003003]\n",
            "Node 560: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.778, 0.0, 0.002002002002002002]\n",
            "Node 561: [0.4516555850326081, 0, 0, 0.001, 0.002, 0.18332222962469466, 0.0, 0.282, 0.0, 0.003003003003003003]\n",
            "Node 562: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.779, 0.0, 0.002002002002002002]\n",
            "Node 563: [1.512109294831615, 0, 0, 0.001, 0.002, 0.3243393293359982, 0.0, 0.283, 0.0, 0.003003003003003003]\n",
            "Node 564: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.78, 0.0, 0.002002002002002002]\n",
            "Node 565: [0.9902324691431273, 0, 0, 0.001, 0.002, 0.25494115034421494, 0.0, 0.284, 0.0, 0.003003003003003003]\n",
            "Node 566: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.781, 0.0, 0.002002002002002002]\n",
            "Node 567: [-0.036821123811816396, 0, 0, 0.001, 0.002, 0.11836553408838552, 0.0, 0.285, 0.0, 0.003003003003003003]\n",
            "Node 568: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.782, 0.0, 0.002002002002002002]\n",
            "Node 569: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.286, 0.0, 0.003003003003003003]\n",
            "Node 570: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.783, 0.0, 0.002002002002002002]\n",
            "Node 571: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.287, 0.0, 0.003003003003003003]\n",
            "Node 572: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.784, 0.0, 0.002002002002002002]\n",
            "Node 573: [1.164330578192807, 0, 0, 0.001, 0.002, 0.2780923828558739, 0.0, 0.288, 0.0, 0.003003003003003003]\n",
            "Node 574: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.785, 0.0, 0.002002002002002002]\n",
            "Node 575: [0.07256425885249053, 0, 0, 0.001, 0.002, 0.13291139240506328, 0.0, 0.289, 0.0, 0.003003003003003003]\n",
            "Node 576: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.786, 0.0, 0.002002002002002002]\n",
            "Node 577: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.29, 0.0, 0.003003003003003003]\n",
            "Node 578: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.787, 0.0, 0.002002002002002002]\n",
            "Node 579: [1.6469622665895203, 0, 0, 0.001, 0.002, 0.34227181878747504, 0.0, 0.291, 0.0, 0.003003003003003003]\n",
            "Node 580: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.788, 0.0, 0.002002002002002002]\n",
            "Node 581: [1.3083685820828297, 0, 0, 0.001, 0.002, 0.297246280257606, 0.0, 0.292, 0.0, 0.003003003003003003]\n",
            "Node 582: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.789, 0.0, 0.002002002002002002]\n",
            "Node 583: [0.989397466222026, 0, 0, 0.001, 0.002, 0.2548301132578281, 0.0, 0.293, 0.0, 0.003003003003003003]\n",
            "Node 584: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.79, 0.0, 0.002002002002002002]\n",
            "Node 585: [0.12266443411858546, 0, 0, 0.001, 0.002, 0.1395736175882745, 0.0, 0.294, 0.0, 0.003003003003003003]\n",
            "Node 586: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.791, 0.0, 0.002002002002002002]\n",
            "Node 587: [1.1776906249304322, 0, 0, 0.001, 0.002, 0.2798689762380635, 0.0, 0.295, 0.0, 0.003003003003003003]\n",
            "Node 588: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.792, 0.0, 0.002002002002002002]\n",
            "Node 589: [-0.020121065389784847, 0, 0, 0.001, 0.002, 0.12058627581612258, 0.0, 0.296, 0.0, 0.003003003003003003]\n",
            "Node 590: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.793, 0.0, 0.002002002002002002]\n",
            "Node 591: [1.0503526794624412, 0, 0, 0.001, 0.002, 0.2629358205640684, 0.0, 0.297, 0.0, 0.003003003003003003]\n",
            "Node 592: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.794, 0.0, 0.002002002002002002]\n",
            "Node 593: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.298, 0.0, 0.003003003003003003]\n",
            "Node 594: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.795, 0.0, 0.002002002002002002]\n",
            "Node 595: [0.3113750942875426, 0, 0, 0.001, 0.002, 0.1646679991117033, 0.0, 0.299, 0.0, 0.003003003003003003]\n",
            "Node 596: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.796, 0.0, 0.002002002002002002]\n",
            "Node 597: [0.9831349443137639, 0, 0, 0.001, 0.002, 0.25399733510992667, 0.0, 0.3, 0.0, 0.003003003003003003]\n",
            "Node 598: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.797, 0.0, 0.002002002002002002]\n",
            "Node 599: [0.8591370105301792, 0, 0, 0.001, 0.002, 0.237508327781479, 0.0, 0.301, 0.0, 0.003003003003003003]\n",
            "Node 600: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.798, 0.0, 0.002002002002002002]\n",
            "Node 601: [0.6645813299135112, 0, 0, 0.001, 0.002, 0.2116366866533422, 0.0, 0.302, 0.0, 0.003003003003003003]\n",
            "Node 602: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.799, 0.0, 0.002002002002002002]\n",
            "Node 603: [1.3204761244388026, 0, 0, 0.001, 0.002, 0.2988563180102154, 0.0, 0.303, 0.0, 0.003003003003003003]\n",
            "Node 604: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.8, 0.0, 0.002002002002002002]\n",
            "Node 605: [0.8996346522036058, 0, 0, 0.001, 0.002, 0.24289362647124133, 0.0, 0.304, 0.0, 0.003003003003003003]\n",
            "Node 606: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.801, 0.0, 0.002002002002002002]\n",
            "Node 607: [1.1108903912423058, 0, 0, 0.001, 0.002, 0.2709860093271152, 0.0, 0.305, 0.0, 0.003003003003003003]\n",
            "Node 608: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.802, 0.0, 0.002002002002002002]\n",
            "Node 609: [0.47670567266565556, 0, 0, 0.001, 0.002, 0.18665334221630023, 0.0, 0.306, 0.0, 0.003003003003003003]\n",
            "Node 610: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.803, 0.0, 0.002002002002002002]\n",
            "Node 611: [0.5698084983684817, 0, 0, 0.001, 0.002, 0.19903397734843434, 0.0, 0.307, 0.0, 0.003003003003003003]\n",
            "Node 612: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.804, 0.0, 0.002002002002002002]\n",
            "Node 613: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.308, 0.0, 0.003003003003003003]\n",
            "Node 614: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.805, 0.0, 0.002002002002002002]\n",
            "Node 615: [0.740149094273204, 0, 0, 0.001, 0.002, 0.2216855429713524, 0.0, 0.309, 0.0, 0.003003003003003003]\n",
            "Node 616: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.806, 0.0, 0.002002002002002002]\n",
            "Node 617: [0.8077843308824322, 0, 0, 0.001, 0.002, 0.23067954696868756, 0.0, 0.31, 0.0, 0.003003003003003003]\n",
            "Node 618: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.807, 0.0, 0.002002002002002002]\n",
            "Node 619: [0.3886128644894389, 0, 0, 0.001, 0.002, 0.17493892960248722, 0.0, 0.311, 0.0, 0.003003003003003003]\n",
            "Node 620: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.808, 0.0, 0.002002002002002002]\n",
            "Node 621: [0.5664684866840753, 0, 0, 0.001, 0.002, 0.19858982900288696, 0.0, 0.312, 0.0, 0.003003003003003003]\n",
            "Node 622: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.809, 0.0, 0.002002002002002002]\n",
            "Node 623: [0.5718960056712358, 0, 0, 0.001, 0.002, 0.1993115700644015, 0.0, 0.313, 0.0, 0.003003003003003003]\n",
            "Node 624: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.81, 0.0, 0.002002002002002002]\n",
            "Node 625: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.314, 0.0, 0.003003003003003003]\n",
            "Node 626: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.811, 0.0, 0.002002002002002002]\n",
            "Node 627: [1.100452854728536, 0, 0, 0.001, 0.002, 0.2695980457472795, 0.0, 0.315, 0.0, 0.003003003003003003]\n",
            "Node 628: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 0.0, 0.812, 0.0, 0.002002002002002002]\n",
            "Node 629: [1.0336526210404096, 0, 0, 0.001, 0.002, 0.2607150788363313, 0.0, 0.316, 0.0, 0.003003003003003003]\n",
            "Node 630: [-0.915244196810679, 0, 0, 0.001, 0.001, 0.0015545192094159443, 0.0, 0.813, 0.0, 0.002002002002002002]\n",
            "Node 631: [1.573899510993132, 0, 0, 0.001, 0.002, 0.3325560737286254, 0.0, 0.317, 0.0, 0.003003003003003003]\n",
            "Node 632: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.814, 0.0, 0.002002002002002002]\n",
            "Node 633: [0.3652327826985945, 0, 0, 0.001, 0.002, 0.17182989118365533, 0.0, 0.318, 0.0, 0.003003003003003003]\n",
            "Node 634: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.815, 0.0, 0.002002002002002002]\n",
            "Node 635: [1.5872595577307578, 0, 0, 0.001, 0.002, 0.334332667110815, 0.0, 0.319, 0.0, 0.003003003003003003]\n",
            "Node 636: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.816, 0.0, 0.002002002002002002]\n",
            "Node 637: [0.34394020821050414, 0, 0, 0.001, 0.002, 0.16899844548079057, 0.0, 0.32, 0.0, 0.003003003003003003]\n",
            "Node 638: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.817, 0.0, 0.002002002002002002]\n",
            "Node 639: [0.4925707281665854, 0, 0, 0.001, 0.002, 0.1887630468576504, 0.0, 0.321, 0.0, 0.003003003003003003]\n",
            "Node 640: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.818, 0.0, 0.002002002002002002]\n",
            "Node 641: [1.1029578634918409, 0, 0, 0.001, 0.002, 0.2699311570064401, 0.0, 0.322, 0.0, 0.003003003003003003]\n",
            "Node 642: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.819, 0.0, 0.002002002002002002]\n",
            "Node 643: [0.5050957719831093, 0, 0, 0.001, 0.002, 0.19042860315345325, 0.0, 0.323, 0.0, 0.003003003003003003]\n",
            "Node 644: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.82, 0.0, 0.002002002002002002]\n",
            "Node 645: [0.039581643468978134, 0, 0, 0.001, 0.002, 0.12852542749278256, 0.0, 0.324, 0.0, 0.003003003003003003]\n",
            "Node 646: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.821, 0.0, 0.002002002002002002]\n",
            "Node 647: [1.221945779748816, 0, 0, 0.001, 0.002, 0.2857539418165667, 0.0, 0.325, 0.0, 0.003003003003003003]\n",
            "Node 648: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.822, 0.0, 0.002002002002002002]\n",
            "Node 649: [0.12391693850023773, 0, 0, 0.001, 0.002, 0.13974017321785473, 0.0, 0.326, 0.0, 0.003003003003003003]\n",
            "Node 650: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.823, 0.0, 0.002002002002002002]\n",
            "Node 651: [1.0111075421706668, 0, 0, 0.001, 0.002, 0.2577170775038863, 0.0, 0.327, 0.0, 0.003003003003003003]\n",
            "Node 652: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.824, 0.0, 0.002002002002002002]\n",
            "Node 653: [0.11974192389472993, 0, 0, 0.001, 0.002, 0.13918498778592048, 0.0, 0.328, 0.0, 0.003003003003003003]\n",
            "Node 654: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.825, 0.0, 0.002002002002002002]\n",
            "Node 655: [1.357633754427823, 0, 0, 0.001, 0.002, 0.3037974683544304, 0.0, 0.329, 0.0, 0.003003003003003003]\n",
            "Node 656: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.826, 0.0, 0.002002002002002002]\n",
            "Node 657: [0.35521274764537564, 0, 0, 0.001, 0.002, 0.1704974461470131, 0.0, 0.33, 0.0, 0.003003003003003003]\n",
            "Node 658: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.827, 0.0, 0.002002002002002002]\n",
            "Node 659: [0.9785424282477052, 0, 0, 0.001, 0.002, 0.253386631134799, 0.0, 0.331, 0.0, 0.003003003003003003]\n",
            "Node 660: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.828, 0.0, 0.002002002002002002]\n",
            "Node 661: [1.219858272446062, 0, 0, 0.001, 0.002, 0.2854763491005996, 0.0, 0.332, 0.0, 0.003003003003003003]\n",
            "Node 662: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.829, 0.0, 0.002002002002002002]\n",
            "Node 663: [0.9372097836531772, 0, 0, 0.001, 0.002, 0.24789029535864981, 0.0, 0.333, 0.0, 0.003003003003003003]\n",
            "Node 664: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.83, 0.0, 0.002002002002002002]\n",
            "Node 665: [0.45499559671701434, 0, 0, 0.001, 0.002, 0.18376637797024203, 0.0, 0.334, 0.0, 0.003003003003003003]\n",
            "Node 666: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.831, 0.0, 0.002002002002002002]\n",
            "Node 667: [0.23789483723060348, 0, 0, 0.001, 0.002, 0.1548967355096602, 0.0, 0.335, 0.0, 0.003003003003003003]\n",
            "Node 668: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.832, 0.0, 0.002002002002002002]\n",
            "Node 669: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.336, 0.0, 0.003003003003003003]\n",
            "Node 670: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.833, 0.0, 0.002002002002002002]\n",
            "Node 671: [0.6245011897006353, 0, 0, 0.001, 0.002, 0.20630690650677325, 0.0, 0.337, 0.0, 0.003003003003003003]\n",
            "Node 672: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.834, 0.0, 0.002002002002002002]\n",
            "Node 673: [-0.03264610920630858, 0, 0, 0.001, 0.002, 0.11892071952031977, 0.0, 0.338, 0.0, 0.003003003003003003]\n",
            "Node 674: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.835, 0.0, 0.002002002002002002]\n",
            "Node 675: [1.0098550377890145, 0, 0, 0.001, 0.002, 0.257550521874306, 0.0, 0.339, 0.0, 0.003003003003003003]\n",
            "Node 676: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.836, 0.0, 0.002002002002002002]\n",
            "Node 677: [1.6528072870372315, 0, 0, 0.001, 0.002, 0.343049078392183, 0.0, 0.34, 0.0, 0.003003003003003003]\n",
            "Node 678: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.837, 0.0, 0.002002002002002002]\n",
            "Node 679: [1.5000017524756424, 0, 0, 0.001, 0.002, 0.3227292915833888, 0.0, 0.341, 0.0, 0.003003003003003003]\n",
            "Node 680: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.838, 0.0, 0.002002002002002002]\n",
            "Node 681: [0.44163554997938903, 0, 0, 0.001, 0.002, 0.18198978458805237, 0.0, 0.342, 0.0, 0.003003003003003003]\n",
            "Node 682: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.839, 0.0, 0.002002002002002002]\n",
            "Node 683: [0.4733656609812493, 0, 0, 0.001, 0.002, 0.18620919387075283, 0.0, 0.343, 0.0, 0.003003003003003003]\n",
            "Node 684: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.84, 0.0, 0.002002002002002002]\n",
            "Node 685: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.344, 0.0, 0.003003003003003003]\n",
            "Node 686: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.841, 0.0, 0.002002002002002002]\n",
            "Node 687: [0.39612789077935306, 0, 0, 0.001, 0.002, 0.1759382633799689, 0.0, 0.345, 0.0, 0.003003003003003003]\n",
            "Node 688: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.842, 0.0, 0.002002002002002002]\n",
            "Node 689: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.346, 0.0, 0.003003003003003003]\n",
            "Node 690: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.843, 0.0, 0.002002002002002002]\n",
            "Node 691: [0.9029746638880124, 0, 0, 0.001, 0.002, 0.2433377748167888, 0.0, 0.347, 0.0, 0.003003003003003003]\n",
            "Node 692: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.844, 0.0, 0.002002002002002002]\n",
            "Node 693: [0.36565028415914536, 0, 0, 0.001, 0.002, 0.17188540972684876, 0.0, 0.348, 0.0, 0.003003003003003003]\n",
            "Node 694: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.845, 0.0, 0.002002002002002002]\n",
            "Node 695: [1.5396643912279675, 0, 0, 0.001, 0.002, 0.3280035531867644, 0.0, 0.349, 0.0, 0.003003003003003003]\n",
            "Node 696: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.846, 0.0, 0.002002002002002002]\n",
            "Node 697: [0.8745845645705587, 0, 0, 0.001, 0.002, 0.2395625138796358, 0.0, 0.35, 0.0, 0.003003003003003003]\n",
            "Node 698: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.847, 0.0, 0.002002002002002002]\n",
            "Node 699: [0.7209440270878679, 0, 0, 0.001, 0.002, 0.21913168998445479, 0.0, 0.351, 0.0, 0.003003003003003003]\n",
            "Node 700: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.848, 0.0, 0.002002002002002002]\n",
            "Node 701: [0.007851532467118165, 0, 0, 0.001, 0.002, 0.12430601821008216, 0.0, 0.352, 0.0, 0.003003003003003003]\n",
            "Node 702: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.849, 0.0, 0.002002002002002002]\n",
            "Node 703: [1.3755863172315068, 0, 0, 0.001, 0.002, 0.30618476571174774, 0.0, 0.353, 0.0, 0.003003003003003003]\n",
            "Node 704: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.85, 0.0, 0.002002002002002002]\n",
            "Node 705: [0.45290808941426053, 0, 0, 0.001, 0.002, 0.18348878525427492, 0.0, 0.354, 0.0, 0.003003003003003003]\n",
            "Node 706: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.851, 0.0, 0.002002002002002002]\n",
            "Node 707: [0.7518391351686261, 0, 0, 0.001, 0.002, 0.22324006218076836, 0.0, 0.355, 0.0, 0.003003003003003003]\n",
            "Node 708: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.852, 0.0, 0.002002002002002002]\n",
            "Node 709: [1.6369422315363016, 0, 0, 0.001, 0.002, 0.3409393737508328, 0.0, 0.356, 0.0, 0.003003003003003003]\n",
            "Node 710: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.853, 0.0, 0.002002002002002002]\n",
            "Node 711: [0.36189277101418826, 0, 0, 0.001, 0.002, 0.17138574283810792, 0.0, 0.357, 0.0, 0.003003003003003003]\n",
            "Node 712: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.854, 0.0, 0.002002002002002002]\n",
            "Node 713: [1.6056296219949924, 0, 0, 0.001, 0.002, 0.33677548301132576, 0.0, 0.358, 0.0, 0.003003003003003003]\n",
            "Node 714: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 0.0, 0.855, 0.0, 0.002002002002002002]\n",
            "Node 715: [0.9935724808275336, 0, 0, 0.001, 0.002, 0.25538529868976234, 0.0, 0.359, 0.0, 0.003003003003003003]\n",
            "Node 716: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.856, 0.0, 0.002002002002002002]\n",
            "Node 717: [1.4027239121673083, 0, 0, 0.001, 0.002, 0.3097934710193205, 0.0, 0.36, 0.0, 0.003003003003003003]\n",
            "Node 718: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.857, 0.0, 0.002002002002002002]\n",
            "Node 719: [1.4603391137233173, 0, 0, 0.001, 0.002, 0.3174550299800133, 0.0, 0.361, 0.0, 0.003003003003003003]\n",
            "Node 720: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.858, 0.0, 0.002002002002002002]\n",
            "Node 721: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 0.0, 0.362, 0.0, 0.003003003003003003]\n",
            "Node 722: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.859, 0.0, 0.002002002002002002]\n",
            "Node 723: [0.2282923036379353, 0, 0, 0.001, 0.002, 0.1536198090162114, 0.0, 0.363, 0.0, 0.003003003003003003]\n",
            "Node 724: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 0.0, 0.86, 0.0, 0.002002002002002002]\n",
            "Node 725: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 0.0, 0.364, 0.0, 0.003003003003003003]\n",
            "Node 726: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.861, 0.0, 0.002002002002002002]\n",
            "Node 727: [0.9777074253266038, 0, 0, 0.001, 0.002, 0.25327559404841216, 0.0, 0.365, 0.0, 0.003003003003003003]\n",
            "Node 728: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.862, 0.0, 0.002002002002002002]\n",
            "Node 729: [0.5046782705225585, 0, 0, 0.001, 0.002, 0.19037308461025984, 0.0, 0.366, 0.0, 0.003003003003003003]\n",
            "Node 730: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 0.0, 0.863, 0.0, 0.002002002002002002]\n",
            "Node 731: [0.925102241297204, 0, 0, 0.001, 0.002, 0.2462802576060404, 0.0, 0.367, 0.0, 0.003003003003003003]\n",
            "Node 732: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.864, 0.0, 0.002002002002002002]\n",
            "Node 733: [1.5751520153747844, 0, 0, 0.001, 0.002, 0.3327226293582056, 0.0, 0.368, 0.0, 0.003003003003003003]\n",
            "Node 734: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.865, 0.0, 0.002002002002002002]\n",
            "Node 735: [3.959085355119796, 0, 0, 0.0, 0.132, 0.6497335109926716, 0.0, 0.003, 0.0, 0.13213213213213212]\n",
            "Node 736: [1.0428376531725267, 0, 0, 0.001, 0.002, 0.2619364867865867, 0.0, 0.369, 0.0, 0.003003003003003003]\n",
            "Node 737: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.866, 0.0, 0.002002002002002002]\n",
            "Node 738: [0.6457937641887255, 0, 0, 0.001, 0.002, 0.209138352209638, 0.0, 0.37, 0.0, 0.003003003003003003]\n",
            "Node 739: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.867, 0.0, 0.002002002002002002]\n",
            "Node 740: [1.0361576298037143, 0, 0, 0.001, 0.002, 0.2610481900954919, 0.0, 0.371, 0.0, 0.003003003003003003]\n",
            "Node 741: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.868, 0.0, 0.002002002002002002]\n",
            "Node 742: [0.32682264832792174, 0, 0, 0.001, 0.002, 0.16672218520986007, 0.0, 0.372, 0.0, 0.003003003003003003]\n",
            "Node 743: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.869, 0.0, 0.002002002002002002]\n",
            "Node 744: [0.6182386677923735, 0, 0, 0.001, 0.002, 0.20547412835887185, 0.0, 0.373, 0.0, 0.003003003003003003]\n",
            "Node 745: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.87, 0.0, 0.002002002002002002]\n",
            "Node 746: [0.24791487228382253, 0, 0, 0.001, 0.002, 0.15622918054630247, 0.0, 0.374, 0.0, 0.003003003003003003]\n",
            "Node 747: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.871, 0.0, 0.002002002002002002]\n",
            "Node 748: [1.7116749929748927, 0, 0, 0.001, 0.002, 0.3508771929824561, 0.0, 0.375, 0.0, 0.003003003003003003]\n",
            "Node 749: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.872, 0.0, 0.002002002002002002]\n",
            "Node 750: [0.10888688592040931, 0, 0, 0.001, 0.002, 0.1377415056628914, 0.0, 0.376, 0.0, 0.003003003003003003]\n",
            "Node 751: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.873, 0.0, 0.002002002002002002]\n",
            "Node 752: [-0.012188537639319782, 0, 0, 0.001, 0.002, 0.12164112813679767, 0.0, 0.377, 0.0, 0.003003003003003003]\n",
            "Node 753: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.874, 0.0, 0.002002002002002002]\n",
            "Node 754: [0.49507573692989026, 0, 0, 0.001, 0.002, 0.189096158116811, 0.0, 0.378, 0.0, 0.003003003003003003]\n",
            "Node 755: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.875, 0.0, 0.002002002002002002]\n",
            "Node 756: [1.5250518401086897, 0, 0, 0.001, 0.002, 0.32606040417499443, 0.0, 0.379, 0.0, 0.003003003003003003]\n",
            "Node 757: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.876, 0.0, 0.002002002002002002]\n",
            "Node 758: [1.0378276356459175, 0, 0, 0.001, 0.002, 0.26127026426826555, 0.0, 0.38, 0.0, 0.003003003003003003]\n",
            "Node 759: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.877, 0.0, 0.002002002002002002]\n",
            "Node 760: [0.22453479049297817, 0, 0, 0.001, 0.002, 0.15312014212747055, 0.0, 0.381, 0.0, 0.003003003003003003]\n",
            "Node 761: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.878, 0.0, 0.002002002002002002]\n",
            "Node 762: [0.30260756361597596, 0, 0, 0.001, 0.002, 0.16350210970464132, 0.0, 0.382, 0.0, 0.003003003003003003]\n",
            "Node 763: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.879, 0.0, 0.002002002002002002]\n",
            "Node 764: [0.7985992987503149, 0, 0, 0.001, 0.002, 0.22945813901843218, 0.0, 0.383, 0.0, 0.003003003003003003]\n",
            "Node 765: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.88, 0.0, 0.002002002002002002]\n",
            "Node 766: [1.576822021216988, 0, 0, 0.001, 0.002, 0.3329447035309793, 0.0, 0.384, 0.0, 0.003003003003003003]\n",
            "Node 767: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.881, 0.0, 0.002002002002002002]\n",
            "Node 768: [1.7254525411730688, 0, 0, 0.001, 0.002, 0.3527093049078392, 0.0, 0.385, 0.0, 0.003003003003003003]\n",
            "Node 769: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.882, 0.0, 0.002002002002002002]\n",
            "Node 770: [0.8541269930035699, 0, 0, 0.001, 0.002, 0.23684210526315788, 0.0, 0.386, 0.0, 0.003003003003003003]\n",
            "Node 771: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.883, 0.0, 0.002002002002002002]\n",
            "Node 772: [0.6675038401373667, 0, 0, 0.001, 0.002, 0.2120253164556962, 0.0, 0.387, 0.0, 0.003003003003003003]\n",
            "Node 773: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.884, 0.0, 0.002002002002002002]\n",
            "Node 774: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.388, 0.0, 0.003003003003003003]\n",
            "Node 775: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.885, 0.0, 0.002002002002002002]\n",
            "Node 776: [1.281230987147028, 0, 0, 0.001, 0.002, 0.2936375749500333, 0.0, 0.389, 0.0, 0.003003003003003003]\n",
            "Node 777: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.886, 0.0, 0.002002002002002002]\n",
            "Node 778: [0.7334690709043915, 0, 0, 0.001, 0.002, 0.2207972462802576, 0.0, 0.39, 0.0, 0.003003003003003003]\n",
            "Node 779: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.887, 0.0, 0.002002002002002002]\n",
            "Node 780: [0.8816820893999219, 0, 0, 0.001, 0.002, 0.240506329113924, 0.0, 0.391, 0.0, 0.003003003003003003]\n",
            "Node 781: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.888, 0.0, 0.002002002002002002]\n",
            "Node 782: [1.0812477875431996, 0, 0, 0.001, 0.002, 0.26704419276038194, 0.0, 0.392, 0.0, 0.003003003003003003]\n",
            "Node 783: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.889, 0.0, 0.002002002002002002]\n",
            "Node 784: [0.6829513941777459, 0, 0, 0.001, 0.002, 0.21407950255385297, 0.0, 0.393, 0.0, 0.003003003003003003]\n",
            "Node 785: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.89, 0.0, 0.002002002002002002]\n",
            "Node 786: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 0.0, 0.394, 0.0, 0.003003003003003003]\n",
            "Node 787: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.891, 0.0, 0.002002002002002002]\n",
            "Node 788: [1.3709938011654481, 0, 0, 0.001, 0.002, 0.30557406173662005, 0.0, 0.395, 0.0, 0.003003003003003003]\n",
            "Node 789: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.892, 0.0, 0.002002002002002002]\n",
            "Node 790: [1.60437711761334, 0, 0, 0.001, 0.002, 0.33660892738174547, 0.0, 0.396, 0.0, 0.003003003003003003]\n",
            "Node 791: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.893, 0.0, 0.002002002002002002]\n",
            "Node 792: [0.23079731240124013, 0, 0, 0.001, 0.002, 0.15395292027537197, 0.0, 0.397, 0.0, 0.003003003003003003]\n",
            "Node 793: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.894, 0.0, 0.002002002002002002]\n",
            "Node 794: [0.3639802783169421, 0, 0, 0.001, 0.002, 0.17166333555407504, 0.0, 0.398, 0.0, 0.003003003003003003]\n",
            "Node 795: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.895, 0.0, 0.002002002002002002]\n",
            "Node 796: [1.6857899024207441, 0, 0, 0.001, 0.002, 0.3474350433044637, 0.0, 0.399, 0.0, 0.003003003003003003]\n",
            "Node 797: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.896, 0.0, 0.002002002002002002]\n",
            "Node 798: [0.6487162744125811, 0, 0, 0.001, 0.002, 0.209526982011992, 0.0, 0.4, 0.0, 0.003003003003003003]\n",
            "Node 799: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.897, 0.0, 0.002002002002002002]\n",
            "Node 800: [0.015784060217583083, 0, 0, 0.001, 0.002, 0.12536087053075726, 0.0, 0.401, 0.0, 0.003003003003003003]\n",
            "Node 801: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.898, 0.0, 0.002002002002002002]\n",
            "Node 802: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.402, 0.0, 0.003003003003003003]\n",
            "Node 803: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.899, 0.0, 0.002002002002002002]\n",
            "Node 804: [0.2792274818251318, 0, 0, 0.001, 0.002, 0.16039307128580946, 0.0, 0.403, 0.0, 0.003003003003003003]\n",
            "Node 805: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.9, 0.0, 0.002002002002002002]\n",
            "Node 806: [0.31930762203800755, 0, 0, 0.001, 0.002, 0.1657228514323784, 0.0, 0.404, 0.0, 0.003003003003003003]\n",
            "Node 807: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.901, 0.0, 0.002002002002002002]\n",
            "Node 808: [1.6123096453638048, 0, 0, 0.001, 0.002, 0.33766377970242056, 0.0, 0.405, 0.0, 0.003003003003003003]\n",
            "Node 809: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.902, 0.0, 0.002002002002002002]\n",
            "Node 810: [0.621161178016229, 0, 0, 0.001, 0.002, 0.20586275816122587, 0.0, 0.406, 0.0, 0.003003003003003003]\n",
            "Node 811: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.903, 0.0, 0.002002002002002002]\n",
            "Node 812: [0.9280247515210596, 0, 0, 0.001, 0.002, 0.24666888740839438, 0.0, 0.407, 0.0, 0.003003003003003003]\n",
            "Node 813: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.904, 0.0, 0.002002002002002002]\n",
            "Node 814: [0.9397147924164817, 0, 0, 0.001, 0.002, 0.24822340661781034, 0.0, 0.408, 0.0, 0.003003003003003003]\n",
            "Node 815: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.905, 0.0, 0.002002002002002002]\n",
            "Node 816: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.409, 0.0, 0.003003003003003003]\n",
            "Node 817: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.906, 0.0, 0.002002002002002002]\n",
            "Node 818: [1.570977000769277, 0, 0, 0.001, 0.002, 0.3321674439262714, 0.0, 0.41, 0.0, 0.003003003003003003]\n",
            "Node 819: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.907, 0.0, 0.002002002002002002]\n",
            "Node 820: [1.1989831994185225, 0, 0, 0.001, 0.002, 0.28270042194092826, 0.0, 0.411, 0.0, 0.003003003003003003]\n",
            "Node 821: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.908, 0.0, 0.002002002002002002]\n",
            "Node 822: [1.1117253941634075, 0, 0, 0.001, 0.002, 0.27109704641350213, 0.0, 0.412, 0.0, 0.003003003003003003]\n",
            "Node 823: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.909, 0.0, 0.002002002002002002]\n",
            "Node 824: [0.9121596960201297, 0, 0, 0.001, 0.002, 0.2445591827670442, 0.0, 0.413, 0.0, 0.003003003003003003]\n",
            "Node 825: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.91, 0.0, 0.002002002002002002]\n",
            "Node 826: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 0.0, 0.414, 0.0, 0.003003003003003003]\n",
            "Node 827: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.911, 0.0, 0.002002002002002002]\n",
            "Node 828: [1.1985656979579717, 0, 0, 0.001, 0.002, 0.2826449033977348, 0.0, 0.415, 0.0, 0.003003003003003003]\n",
            "Node 829: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.912, 0.0, 0.002002002002002002]\n",
            "Node 830: [0.4929882296271364, 0, 0, 0.001, 0.002, 0.18881856540084388, 0.0, 0.416, 0.0, 0.003003003003003003]\n",
            "Node 831: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.913, 0.0, 0.002002002002002002]\n",
            "Node 832: [0.9626773727467753, 0, 0, 0.001, 0.002, 0.2512769264934488, 0.0, 0.417, 0.0, 0.003003003003003003]\n",
            "Node 833: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.914, 0.0, 0.002002002002002002]\n",
            "Node 834: [0.6203261750951273, 0, 0, 0.001, 0.002, 0.20575172107483897, 0.0, 0.418, 0.0, 0.003003003003003003]\n",
            "Node 835: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.915, 0.0, 0.002002002002002002]\n",
            "Node 836: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 0.0, 0.419, 0.0, 0.003003003003003003]\n",
            "Node 837: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.916, 0.0, 0.002002002002002002]\n",
            "Node 838: [0.09552683918278401, 0, 0, 0.001, 0.002, 0.13596491228070176, 0.0, 0.42, 0.0, 0.003003003003003003]\n",
            "Node 839: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.917, 0.0, 0.002002002002002002]\n",
            "Node 840: [1.2315483133414842, 0, 0, 0.001, 0.002, 0.2870308683100155, 0.0, 0.421, 0.0, 0.003003003003003003]\n",
            "Node 841: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.918, 0.0, 0.002002002002002002]\n",
            "Node 842: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.422, 0.0, 0.003003003003003003]\n",
            "Node 843: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.919, 0.0, 0.002002002002002002]\n",
            "Node 844: [0.7272065489961297, 0, 0, 0.001, 0.002, 0.2199644681323562, 0.0, 0.423, 0.0, 0.003003003003003003]\n",
            "Node 845: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.92, 0.0, 0.002002002002002002]\n",
            "Node 846: [1.1209104262955247, 0, 0, 0.001, 0.002, 0.2723184543637575, 0.0, 0.424, 0.0, 0.003003003003003003]\n",
            "Node 847: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.921, 0.0, 0.002002002002002002]\n",
            "Node 848: [1.6895474155657009, 0, 0, 0.001, 0.002, 0.3479347101932045, 0.0, 0.425, 0.0, 0.003003003003003003]\n",
            "Node 849: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.922, 0.0, 0.002002002002002002]\n",
            "Node 850: [0.5134458011941249, 0, 0, 0.001, 0.002, 0.19153897401732176, 0.0, 0.426, 0.0, 0.003003003003003003]\n",
            "Node 851: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.923, 0.0, 0.002002002002002002]\n",
            "Node 852: [0.20741723061039577, 0, 0, 0.001, 0.002, 0.15084388185654007, 0.0, 0.427, 0.0, 0.003003003003003003]\n",
            "Node 853: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.924, 0.0, 0.002002002002002002]\n",
            "Node 854: [1.2833184944497822, 0, 0, 0.001, 0.002, 0.2939151676660004, 0.0, 0.428, 0.0, 0.003003003003003003]\n",
            "Node 855: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.925, 0.0, 0.002002002002002002]\n",
            "Node 856: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 0.0, 0.429, 0.0, 0.003003003003003003]\n",
            "Node 857: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.926, 0.0, 0.002002002002002002]\n",
            "Node 858: [0.7990168002108655, 0, 0, 0.001, 0.002, 0.22951365756162556, 0.0, 0.43, 0.0, 0.003003003003003003]\n",
            "Node 859: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.927, 0.0, 0.002002002002002002]\n",
            "Node 860: [1.4941567320279312, 0, 0, 0.001, 0.002, 0.3219520319786809, 0.0, 0.431, 0.0, 0.003003003003003003]\n",
            "Node 861: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.928, 0.0, 0.002002002002002002]\n",
            "Node 862: [1.3914513727324365, 0, 0, 0.001, 0.002, 0.3082944703530979, 0.0, 0.432, 0.0, 0.003003003003003003]\n",
            "Node 863: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.929, 0.0, 0.002002002002002002]\n",
            "Node 864: [1.1676705898772133, 0, 0, 0.001, 0.002, 0.27853653120142124, 0.0, 0.433, 0.0, 0.003003003003003003]\n",
            "Node 865: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.93, 0.0, 0.002002002002002002]\n",
            "Node 866: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.434, 0.0, 0.003003003003003003]\n",
            "Node 867: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.931, 0.0, 0.002002002002002002]\n",
            "Node 868: [0.04876667560109562, 0, 0, 0.001, 0.002, 0.12974683544303797, 0.0, 0.435, 0.0, 0.003003003003003003]\n",
            "Node 869: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.932, 0.0, 0.002002002002002002]\n",
            "Node 870: [1.5041767670811501, 0, 0, 0.001, 0.002, 0.3232844770153231, 0.0, 0.436, 0.0, 0.003003003003003003]\n",
            "Node 871: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.933, 0.0, 0.002002002002002002]\n",
            "Node 872: [1.6248346891803285, 0, 0, 0.001, 0.002, 0.33932933599822335, 0.0, 0.437, 0.0, 0.003003003003003003]\n",
            "Node 873: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.934, 0.0, 0.002002002002002002]\n",
            "Node 874: [0.8537094915430191, 0, 0, 0.001, 0.002, 0.2367865867199645, 0.0, 0.438, 0.0, 0.003003003003003003]\n",
            "Node 875: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.935, 0.0, 0.002002002002002002]\n",
            "Node 876: [0.8729145587283552, 0, 0, 0.001, 0.002, 0.23934043970686206, 0.0, 0.439, 0.0, 0.003003003003003003]\n",
            "Node 877: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.936, 0.0, 0.002002002002002002]\n",
            "Node 878: [1.5772395226775384, 0, 0, 0.001, 0.002, 0.33300022207417274, 0.0, 0.44, 0.0, 0.003003003003003003]\n",
            "Node 879: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.937, 0.0, 0.002002002002002002]\n",
            "Node 880: [1.1626605723506038, 0, 0, 0.001, 0.002, 0.27787030868310014, 0.0, 0.441, 0.0, 0.003003003003003003]\n",
            "Node 881: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.938, 0.0, 0.002002002002002002]\n",
            "Node 882: [0.5443409092748834, 0, 0, 0.001, 0.002, 0.19564734621363536, 0.0, 0.442, 0.0, 0.003003003003003003]\n",
            "Node 883: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.939, 0.0, 0.002002002002002002]\n",
            "Node 884: [1.5567819511105498, 0, 0, 0.001, 0.002, 0.33027981345769486, 0.0, 0.443, 0.0, 0.003003003003003003]\n",
            "Node 885: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.94, 0.0, 0.002002002002002002]\n",
            "Node 886: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.444, 0.0, 0.003003003003003003]\n",
            "Node 887: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.941, 0.0, 0.002002002002002002]\n",
            "Node 888: [0.17693962399018806, 0, 0, 0.001, 0.002, 0.14679102820341994, 0.0, 0.445, 0.0, 0.003003003003003003]\n",
            "Node 889: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.942, 0.0, 0.002002002002002002]\n",
            "Node 890: [0.555195947249204, 0, 0, 0.001, 0.002, 0.19709082833666441, 0.0, 0.446, 0.0, 0.003003003003003003]\n",
            "Node 891: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.943, 0.0, 0.002002002002002002]\n",
            "Node 892: [0.8169693630145495, 0, 0, 0.001, 0.002, 0.23190095491894291, 0.0, 0.447, 0.0, 0.003003003003003003]\n",
            "Node 893: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.944, 0.0, 0.002002002002002002]\n",
            "Node 894: [0.15564704950209785, 0, 0, 0.001, 0.002, 0.14395958250055516, 0.0, 0.448, 0.0, 0.003003003003003003]\n",
            "Node 895: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.945, 0.0, 0.002002002002002002]\n",
            "Node 896: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.449, 0.0, 0.003003003003003003]\n",
            "Node 897: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.946, 0.0, 0.002002002002002002]\n",
            "Node 898: [0.8921196259136916, 0, 0, 0.001, 0.002, 0.24189429269375967, 0.0, 0.45, 0.0, 0.003003003003003003]\n",
            "Node 899: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.947, 0.0, 0.002002002002002002]\n",
            "Node 900: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.451, 0.0, 0.003003003003003003]\n",
            "Node 901: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.948, 0.0, 0.002002002002002002]\n",
            "Node 902: [0.05795170773321296, 0, 0, 0.001, 0.002, 0.13096824339329335, 0.0, 0.452, 0.0, 0.003003003003003003]\n",
            "Node 903: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.949, 0.0, 0.002002002002002002]\n",
            "Node 904: [1.1835356453781434, 0, 0, 0.001, 0.002, 0.2806462358427715, 0.0, 0.453, 0.0, 0.003003003003003003]\n",
            "Node 905: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.95, 0.0, 0.002002002002002002]\n",
            "Node 906: [1.3530412383617638, 0, 0, 0.001, 0.002, 0.30318676437930264, 0.0, 0.454, 0.0, 0.003003003003003003]\n",
            "Node 907: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.951, 0.0, 0.002002002002002002]\n",
            "Node 908: [-0.03306361066685929, 0, 0, 0.001, 0.002, 0.11886520097712634, 0.0, 0.455, 0.0, 0.003003003003003003]\n",
            "Node 909: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.952, 0.0, 0.002002002002002002]\n",
            "Node 910: [0.9188397193889423, 0, 0, 0.001, 0.002, 0.245447479458139, 0.0, 0.456, 0.0, 0.003003003003003003]\n",
            "Node 911: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.953, 0.0, 0.002002002002002002]\n",
            "Node 912: [1.5087692831472088, 0, 0, 0.001, 0.002, 0.32389518099045084, 0.0, 0.457, 0.0, 0.003003003003003003]\n",
            "Node 913: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.954, 0.0, 0.002002002002002002]\n",
            "Node 914: [1.7605226638593352, 0, 0, 0.001, 0.002, 0.357372862536087, 0.0, 0.458, 0.0, 0.003003003003003003]\n",
            "Node 915: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.955, 0.0, 0.002002002002002002]\n",
            "Node 916: [0.11514940782867125, 0, 0, 0.001, 0.002, 0.1385742838107928, 0.0, 0.459, 0.0, 0.003003003003003003]\n",
            "Node 917: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.956, 0.0, 0.002002002002002002]\n",
            "Node 918: [0.9726974077999941, 0, 0, 0.001, 0.002, 0.252609371530091, 0.0, 0.46, 0.0, 0.003003003003003003]\n",
            "Node 919: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.957, 0.0, 0.002002002002002002]\n",
            "Node 920: [0.3869428586472357, 0, 0, 0.001, 0.002, 0.17471685542971352, 0.0, 0.461, 0.0, 0.003003003003003003]\n",
            "Node 921: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.958, 0.0, 0.002002002002002002]\n",
            "Node 922: [0.7915017739209513, 0, 0, 0.001, 0.002, 0.22851432378414388, 0.0, 0.462, 0.0, 0.003003003003003003]\n",
            "Node 923: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.959, 0.0, 0.002002002002002002]\n",
            "Node 924: [1.0065150261046083, 0, 0, 0.001, 0.002, 0.25710637352875854, 0.0, 0.463, 0.0, 0.003003003003003003]\n",
            "Node 925: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.96, 0.0, 0.002002002002002002]\n",
            "Node 926: [1.4586691078811138, 0, 0, 0.001, 0.002, 0.3172329558072396, 0.0, 0.464, 0.0, 0.003003003003003003]\n",
            "Node 927: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.961, 0.0, 0.002002002002002002]\n",
            "Node 928: [1.7546776434116242, 0, 0, 0.001, 0.002, 0.35659560293137904, 0.0, 0.465, 0.0, 0.003003003003003003]\n",
            "Node 929: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.962, 0.0, 0.002002002002002002]\n",
            "Node 930: [0.750169129326423, 0, 0, 0.001, 0.002, 0.22301798800799466, 0.0, 0.466, 0.0, 0.003003003003003003]\n",
            "Node 931: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.963, 0.0, 0.002002002002002002]\n",
            "Node 932: [0.4842206989555698, 0, 0, 0.001, 0.002, 0.18765267599378194, 0.0, 0.467, 0.0, 0.003003003003003003]\n",
            "Node 933: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.964, 0.0, 0.002002002002002002]\n",
            "Node 934: [0.1548120465809963, 0, 0, 0.001, 0.002, 0.1438485454141683, 0.0, 0.468, 0.0, 0.003003003003003003]\n",
            "Node 935: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.965, 0.0, 0.002002002002002002]\n",
            "Node 936: [0.8854396025448791, 0, 0, 0.001, 0.002, 0.24100599600266487, 0.0, 0.469, 0.0, 0.003003003003003003]\n",
            "Node 937: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.966, 0.0, 0.002002002002002002]\n",
            "Node 938: [0.7180215168640124, 0, 0, 0.001, 0.002, 0.21874306018210082, 0.0, 0.47, 0.0, 0.003003003003003003]\n",
            "Node 939: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.967, 0.0, 0.002002002002002002]\n",
            "Node 940: [0.24165235037556057, 0, 0, 0.001, 0.002, 0.15539640239840105, 0.0, 0.471, 0.0, 0.003003003003003003]\n",
            "Node 941: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.968, 0.0, 0.002002002002002002]\n",
            "Node 942: [1.173933111785475, 0, 0, 0.001, 0.002, 0.27936930934932264, 0.0, 0.472, 0.0, 0.003003003003003003]\n",
            "Node 943: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.969, 0.0, 0.002002002002002002]\n",
            "Node 944: [0.9488998245485991, 0, 0, 0.001, 0.002, 0.24944481456806572, 0.0, 0.473, 0.0, 0.003003003003003003]\n",
            "Node 945: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.97, 0.0, 0.002002002002002002]\n",
            "Node 946: [0.8190568703173033, 0, 0, 0.001, 0.002, 0.23217854763491003, 0.0, 0.474, 0.0, 0.003003003003003003]\n",
            "Node 947: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.971, 0.0, 0.002002002002002002]\n",
            "Node 948: [0.7898317680787482, 0, 0, 0.001, 0.002, 0.22829224961137018, 0.0, 0.475, 0.0, 0.003003003003003003]\n",
            "Node 949: [-0.8910291120987331, 0, 0, 0.001, 0.001, 0.0047745947146346866, 0.0, 0.972, 0.0, 0.002002002002002002]\n",
            "Node 950: [0.8649820309778903, 0, 0, 0.001, 0.002, 0.23828558738618696, 0.0, 0.476, 0.0, 0.003003003003003003]\n",
            "Node 951: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.973, 0.0, 0.002002002002002002]\n",
            "Node 952: [0.2879950124966983, 0, 0, 0.001, 0.002, 0.16155896069287137, 0.0, 0.477, 0.0, 0.003003003003003003]\n",
            "Node 953: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.974, 0.0, 0.002002002002002002]\n",
            "Node 954: [1.6394472402996065, 0, 0, 0.001, 0.002, 0.3412724850099933, 0.0, 0.478, 0.0, 0.003003003003003003]\n",
            "Node 955: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.975, 0.0, 0.002002002002002002]\n",
            "Node 956: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.479, 0.0, 0.003003003003003003]\n",
            "Node 957: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.976, 0.0, 0.002002002002002002]\n",
            "Node 958: [0.7305465606805359, 0, 0, 0.001, 0.002, 0.2204086164779036, 0.0, 0.48, 0.0, 0.003003003003003003]\n",
            "Node 959: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.977, 0.0, 0.002002002002002002]\n",
            "Node 960: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.481, 0.0, 0.003003003003003003]\n",
            "Node 961: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.978, 0.0, 0.002002002002002002]\n",
            "Node 962: [1.4261039939581521, 0, 0, 0.001, 0.002, 0.3129025094381523, 0.0, 0.482, 0.0, 0.003003003003003003]\n",
            "Node 963: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.979, 0.0, 0.002002002002002002]\n",
            "Node 964: [1.0420026502514255, 0, 0, 0.001, 0.002, 0.26182544970019983, 0.0, 0.483, 0.0, 0.003003003003003003]\n",
            "Node 965: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.98, 0.0, 0.002002002002002002]\n",
            "Node 966: [1.4945742334884817, 0, 0, 0.001, 0.002, 0.32200755052187424, 0.0, 0.484, 0.0, 0.003003003003003003]\n",
            "Node 967: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.981, 0.0, 0.002002002002002002]\n",
            "Node 968: [1.1968956921157687, 0, 0, 0.001, 0.002, 0.2824228292249611, 0.0, 0.485, 0.0, 0.003003003003003003]\n",
            "Node 969: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.982, 0.0, 0.002002002002002002]\n",
            "Node 970: [0.6420362510437685, 0, 0, 0.001, 0.002, 0.2086386853208972, 0.0, 0.486, 0.0, 0.003003003003003003]\n",
            "Node 971: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.983, 0.0, 0.002002002002002002]\n",
            "Node 972: [1.0929378284386218, 0, 0, 0.001, 0.002, 0.2685987119697979, 0.0, 0.487, 0.0, 0.003003003003003003]\n",
            "Node 973: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.984, 0.0, 0.002002002002002002]\n",
            "Node 974: [0.5777410261189468, 0, 0, 0.001, 0.002, 0.20008882966910949, 0.0, 0.488, 0.0, 0.003003003003003003]\n",
            "Node 975: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.985, 0.0, 0.002002002002002002]\n",
            "Node 976: [0.9096546872568249, 0, 0, 0.001, 0.002, 0.2442260715078836, 0.0, 0.489, 0.0, 0.003003003003003003]\n",
            "Node 977: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.986, 0.0, 0.002002002002002002]\n",
            "Node 978: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.49, 0.0, 0.003003003003003003]\n",
            "Node 979: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.987, 0.0, 0.002002002002002002]\n",
            "Node 980: [1.5501019277417374, 0, 0, 0.001, 0.002, 0.32939151676660006, 0.0, 0.491, 0.0, 0.003003003003003003]\n",
            "Node 981: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.988, 0.0, 0.002002002002002002]\n",
            "Node 982: [1.3730813084682019, 0, 0, 0.001, 0.002, 0.30585165445258716, 0.0, 0.492, 0.0, 0.003003003003003003]\n",
            "Node 983: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.989, 0.0, 0.002002002002002002]\n",
            "Node 984: [1.1672530884166625, 0, 0, 0.001, 0.002, 0.27848101265822783, 0.0, 0.493, 0.0, 0.003003003003003003]\n",
            "Node 985: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.99, 0.0, 0.002002002002002002]\n",
            "Node 986: [0.7238665373117235, 0, 0, 0.001, 0.002, 0.2195203197868088, 0.0, 0.494, 0.0, 0.003003003003003003]\n",
            "Node 987: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.991, 0.0, 0.002002002002002002]\n",
            "Node 988: [0.6583188080052493, 0, 0, 0.001, 0.002, 0.2108039085054408, 0.0, 0.495, 0.0, 0.003003003003003003]\n",
            "Node 989: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.992, 0.0, 0.002002002002002002]\n",
            "Node 990: [1.5033417641600486, 0, 0, 0.001, 0.002, 0.32317343992893627, 0.0, 0.496, 0.0, 0.003003003003003003]\n",
            "Node 991: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.993, 0.0, 0.002002002002002002]\n",
            "Node 992: [0.7493341264053216, 0, 0, 0.001, 0.002, 0.2229069509216078, 0.0, 0.497, 0.0, 0.003003003003003003]\n",
            "Node 993: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.994, 0.0, 0.002002002002002002]\n",
            "Node 994: [0.30427756945817913, 0, 0, 0.001, 0.002, 0.16372418387741505, 0.0, 0.498, 0.0, 0.003003003003003003]\n",
            "Node 995: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.995, 0.0, 0.002002002002002002]\n",
            "Node 996: [0.9313647632054661, 0, 0, 0.001, 0.002, 0.2471130357539418, 0.0, 0.499, 0.0, 0.003003003003003003]\n",
            "Node 997: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.996, 0.0, 0.002002002002002002]\n",
            "Node 998: [1.2887460134369424, 0, 0, 0.001, 0.002, 0.29463690872751497, 0.0, 0.5, 0.0, 0.003003003003003003]\n",
            "Node 999: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.998, 0.0, 0.002002002002002002]\n",
            "Using device: cpu\n",
            "Using device: cpu\n",
            "Unique SLA Adherence Values: tensor([1.])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 0, Loss: 1.0000, Time Loss: 0.2008, SLA Loss: 0.6467, Priority Loss: 0.4730\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 10, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.6240, Priority Loss: 0.4706\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 20, Loss: 1.0000, Time Loss: 0.1214, SLA Loss: 0.5832, Priority Loss: 0.4673\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 30, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.5401, Priority Loss: 0.4644\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 40, Loss: 1.0000, Time Loss: 0.1203, SLA Loss: 0.4688, Priority Loss: 0.4589\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 50, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.3312, Priority Loss: 0.4463\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 60, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.1365, Priority Loss: 0.4142\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 70, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0524, Priority Loss: 0.4073\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 80, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0229, Priority Loss: 0.4069\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 90, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0108, Priority Loss: 0.4067\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 100, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0056, Priority Loss: 0.4066\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 110, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0030, Priority Loss: 0.4064\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 120, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0018, Priority Loss: 0.4063\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 130, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0011, Priority Loss: 0.4063\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 140, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0006, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 150, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0004, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 160, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0003, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 170, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0002, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 180, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0001, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 190, Loss: 1.0000, Time Loss: 0.1198, SLA Loss: 0.0001, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 200, Loss: 1.0000, Time Loss: 0.1198, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 210, Loss: 1.0000, Time Loss: 0.1198, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 220, Loss: 1.0000, Time Loss: 0.1198, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 230, Loss: 1.0000, Time Loss: 0.1198, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 240, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 250, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 260, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 270, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 280, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 290, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 300, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 310, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 320, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 330, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 340, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 350, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 360, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 370, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 380, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 390, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 400, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 410, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 420, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 430, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 440, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 450, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 460, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 470, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 480, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 490, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Loss history saved to ./embedding_model_data/loss_history.npy\n",
            "Model, task embeddings, and graph embedding saved to ./embedding_model_data\n",
            "Model training complete. Saved at ./embedding_model_data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trained model\n",
        "embedding_model_save_path = \"./embedding_model_data\"\n",
        "model = TaskEmbeddingModel(input_dim=10, num_gnn_layers=1, num_transformer_layers=1).to(device)  # Adjust input_dim if needed\n",
        "model.load_state_dict(torch.load(os.path.join(embedding_model_save_path, \"trained_model.pth\"), map_location=device))\n",
        "model.eval()\n",
        "print(\"Trained model loaded successfully.\")\n",
        "\n",
        "# Load saved data\n",
        "node_features = torch.tensor(np.load(os.path.join(embedding_model_save_path, \"node_features.npy\")), dtype=torch.float).to(device)\n",
        "edge_index = torch.tensor(np.load(os.path.join(embedding_model_save_path, \"edge_index.npy\")), dtype=torch.long).to(device)\n",
        "edge_attr = torch.tensor(np.load(os.path.join(embedding_model_save_path, \"edge_attr.npy\")), dtype=torch.float).to(device)\n",
        "# Load saved task embeddings and graph embedding\n",
        "task_embeddings = np.load(os.path.join(embedding_model_save_path, \"task_embeddings.npy\"))\n",
        "graph_embedding = np.load(os.path.join(embedding_model_save_path, \"graph_embedding.npy\"))\n",
        "\n",
        "print(\"Loaded saved other data successfully.\")\n",
        "\n",
        "# -------------------------------- #\n",
        "# 🔍 Visualization Functions #\n",
        "# -------------------------------- #\n",
        "\n",
        "## **Graph Attention Visualization**\n",
        "def plot_attention_scores(attn_weights):\n",
        "    attn_values = attn_weights.mean(dim=1).cpu().numpy()  # Take the mean over heads\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(len(attn_values)), np.sort(attn_values), marker='o', linestyle='-', color='b')\n",
        "\n",
        "    plt.xlabel(\"Edge Index (Sorted)\")\n",
        "    plt.ylabel(\"Attention Score\")\n",
        "    plt.title(\"Attention Scores Across Edges\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Ensure attn_weights is updated before calling plot_attention_scores()\n",
        "# Generate predictions using the trained model\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    embeddings, _ = model(node_features.to(device), edge_index.to(device), edge_attr.to(device),\n",
        "                          torch.zeros(node_features.size(0), dtype=torch.long).to(device))\n",
        "\n",
        "    exec_time_pred = embeddings[:, -3].cpu().numpy()  # Extract predicted execution times\n",
        "\n",
        "\n",
        "# Now attn_weights should not be None\n",
        "if model.transformer_layers[0].attn_weights is not None:\n",
        "    plot_attention_scores(model.transformer_layers[0].attn_weights)\n",
        "else:\n",
        "    print(\"Attention weights were not updated. Check compute_attention().\")\n",
        "\n",
        "\n",
        "\n",
        "## **LSTM Execution Time Predictions**\n",
        "def plot_execution_predictions(exec_times, true_exec_times):\n",
        "    \"\"\"Plots predicted vs. true execution times with better visibility.\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.scatter(range(len(exec_times)), exec_times, marker='o', color='b', label=\"Predicted Execution Times\", alpha=0.5)\n",
        "    plt.plot(range(len(true_exec_times)), true_exec_times, color='orange', label=\"True Execution Times\", linewidth=1.5)\n",
        "\n",
        "    plt.xlabel(\"Task Index\")\n",
        "    plt.ylabel(\"Execution Time\")\n",
        "    plt.title(\"LSTM Prediction of Execution Times\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_execution_predictions(exec_time_pred, execution_times.cpu().numpy())\n",
        "\n",
        "\n",
        "# Load loss history\n",
        "loss_history = np.load(os.path.join(embedding_model_save_path, \"loss_history.npy\"), allow_pickle=True).item()\n",
        "\n",
        "# Print final loss values\n",
        "print(\"\\n📉 Final Loss Values:\")\n",
        "print(f\"Execution Time Loss: {loss_history['loss_time'][-1]:.4f}\")\n",
        "print(f\"SLA Loss: {loss_history['loss_sla'][-1]:.4f}\")\n",
        "print(f\"Priority Loss: {loss_history['loss_priority'][-1]:.4f}\")\n",
        "\n",
        "# Print loss values at every 50 epochs\n",
        "print(\"\\n📊 Loss Progress Over Training:\")\n",
        "for epoch in range(0, len(loss_history[\"total_loss\"]), 50):\n",
        "    print(f\"Time Loss: {loss_history['loss_time'][epoch]:.4f} | \"\n",
        "          f\"SLA Loss: {loss_history['loss_sla'][epoch]:.4f} | \"\n",
        "          f\"Priority Loss: {loss_history['loss_priority'][epoch]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CyweYxIl30sa",
        "outputId": "44acaf36-5da3-4caa-cf81-f142eb2056c4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Trained model loaded successfully.\n",
            "Loaded saved other data successfully.\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9d30a2635fa0>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(embedding_model_save_path, \"trained_model.pth\"), map_location=device))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Final Loss Values:\n",
            "Execution Time Loss: 0.1199\n",
            "SLA Loss: 0.0000\n",
            "Priority Loss: 0.4061\n",
            "\n",
            "📊 Loss Progress Over Training:\n",
            "Time Loss: 0.2008 | SLA Loss: 0.6467 | Priority Loss: 0.4730\n",
            "Time Loss: 0.1202 | SLA Loss: 0.3312 | Priority Loss: 0.4463\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0056 | Priority Loss: 0.4066\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0004 | Priority Loss: 0.4062\n",
            "Time Loss: 0.1198 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL SCHEDULER"
      ],
      "metadata": {
        "id": "sJt_umFNLNVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
      ],
      "metadata": {
        "id": "F4HJtzhdLRS7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_rewards(rewards, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(rewards, label='Reward per Episode', color='blue')\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FDpode2mLURb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skfuzzy import control as ctrl\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import skfuzzy as fuzz\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------- Tier-1: Task Placement (Fuzzy + Neural Network) ---------------------- #\n",
        "class Tier1SchedulerEnv(gym.Env):\n",
        "    def __init__(self, task_embeddings):\n",
        "        super(Tier1SchedulerEnv, self).__init__()\n",
        "        self.task_embeddings = task_embeddings\n",
        "        self.num_tasks = task_embeddings.shape[0]\n",
        "        self.current_task = 0\n",
        "\n",
        "        # Define fuzzy variables and membership functions\n",
        "        self.execution_time = ctrl.Antecedent(np.arange(0, 1.5, 0.01), 'execution_time')\n",
        "        self.sla_adherence = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'sla_adherence')\n",
        "        self.energy_usage = ctrl.Consequent(np.arange(0, 2, 0.01), 'energy_usage')\n",
        "\n",
        "        # Use automatic membership functions (poor, average, good)\n",
        "        self.execution_time.automf(5)\n",
        "        self.sla_adherence.automf(5)\n",
        "        self.energy_usage.automf(5)\n",
        "\n",
        "        # Define fuzzy rules with correct labels\n",
        "        rule1 = ctrl.Rule(self.execution_time['good'] & self.sla_adherence['good'], self.energy_usage['poor'])\n",
        "        rule2 = ctrl.Rule(self.execution_time['average'] & self.sla_adherence['average'], self.energy_usage['average'])\n",
        "        rule3 = ctrl.Rule(self.execution_time['poor'] & self.sla_adherence['poor'], self.energy_usage['good'])\n",
        "\n",
        "        self.energy_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
        "        self.energy_sim = ctrl.ControlSystemSimulation(self.energy_ctrl)\n",
        "\n",
        "        # State and action spaces\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(task_embeddings.shape[1],), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)  # {0: Cloud, 1: Edge, 2: Hybrid}\n",
        "\n",
        "        # Neural network-based reward function\n",
        "        self.reward_net = nn.Sequential(\n",
        "          nn.Linear(task_embeddings.shape[1] + 3, 128),  # Added SLA & energy\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, 1)\n",
        "      ).to(device)\n",
        "\n",
        "    def step(self, action):\n",
        "        task_embedding = self.task_embeddings[self.current_task]\n",
        "        execution_time = task_embedding[-3].item()\n",
        "        sla_adherence = task_embedding[-2].item()\n",
        "\n",
        "        # Apply fuzzy logic for energy estimation\n",
        "        self.energy_sim.input['execution_time'] = np.clip(execution_time, 0, 1.5)\n",
        "        self.energy_sim.input['sla_adherence'] = np.clip(sla_adherence, 0, 1)\n",
        "\n",
        "        try:\n",
        "            self.energy_sim.compute()\n",
        "            energy_usage = self.energy_sim.output.get('energy_usage', execution_time * 1.0)  # Default fallback\n",
        "        except:\n",
        "            energy_usage = execution_time * 1.0  # Safe fallback\n",
        "\n",
        "        # Adjust energy usage based on action type\n",
        "        energy_usage *= (1.2 if action == 0 else 0.8 if action == 1 else 0.9) # Cloud, Edge, Hybrid\n",
        "\n",
        "        # Compute reward with neural network\n",
        "        task_embedding_tensor = torch.tensor(task_embedding, dtype=torch.float).to(device)\n",
        "        action_tensor = torch.tensor([action], dtype=torch.float).to(device)\n",
        "        sla_tensor = torch.tensor([sla_adherence], dtype=torch.float).to(device)\n",
        "        energy_tensor = torch.tensor([energy_usage], dtype=torch.float).to(device)\n",
        "\n",
        "        reward_input = torch.cat([task_embedding_tensor, action_tensor, sla_tensor, energy_tensor])\n",
        "\n",
        "        reward = self.reward_net(reward_input).item() - energy_usage\n",
        "\n",
        "        predicted_reward = self.reward_net(reward_input).item()\n",
        "\n",
        "        # Apply weights to balance SLA, execution time, and energy usage\n",
        "        reward = (\n",
        "            2.0 * predicted_reward  # Higher weight to model output\n",
        "            + 4.5 * sla_adherence  # Stronger SLA adherence incentive\n",
        "            - 0.3 * execution_time  # Reduce execution time penalty\n",
        "            - 0.2 * energy_usage  # Reduce energy penalty\n",
        "        )\n",
        "\n",
        "        # Proceed to the next task\n",
        "        self.current_task += 1\n",
        "        done = self.current_task >= self.num_tasks\n",
        "        return task_embedding, reward, done, {\n",
        "            \"energy_usage\": energy_usage,\n",
        "            \"sla_adherence\": sla_adherence,\n",
        "            \"execution_time\": execution_time\n",
        "        }\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_task = 0\n",
        "        return self.task_embeddings[self.current_task]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D7wIDOsv4Lit"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Tier-2: Resource Allocation (Fuzzy + Linear Regression) ---------------------- #\n",
        "class Tier2SchedulerEnv(gym.Env):\n",
        "    def __init__(self, task_embeddings, server_loads):\n",
        "        super(Tier2SchedulerEnv, self).__init__()\n",
        "        self.task_embeddings = task_embeddings\n",
        "        self.num_tasks = task_embeddings.shape[0]\n",
        "        self.num_servers = len(server_loads)\n",
        "        self.server_loads = server_loads\n",
        "        self.current_task = 0\n",
        "        # Neural network-based reward function\n",
        "        self.reward_net = nn.Sequential(\n",
        "            nn.Linear(task_embeddings.shape[1] + 2, 128),  # Remove server_loads length\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        ).to(device)\n",
        "\n",
        "\n",
        "        # Define fuzzy variables for server load and execution time\n",
        "        self.server_load_fuzzy = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'server_load')\n",
        "        self.execution_time_fuzzy = ctrl.Antecedent(np.arange(0, 1.6, 0.01), 'execution_time')\n",
        "        self.adjusted_resource_use = ctrl.Consequent(np.arange(0, 1.6, 0.01), 'adjusted_resource_use')\n",
        "\n",
        "        # Use correct automatic membership function names\n",
        "        self.server_load_fuzzy.automf(3)\n",
        "        self.execution_time_fuzzy.automf(3)\n",
        "        self.adjusted_resource_use.automf(3)\n",
        "\n",
        "        # Define fuzzy rules with correct labels\n",
        "        resource_rule1 = ctrl.Rule(self.server_load_fuzzy['poor'] & self.execution_time_fuzzy['poor'], self.adjusted_resource_use['poor'])\n",
        "        resource_rule2 = ctrl.Rule(self.server_load_fuzzy['average'] | self.execution_time_fuzzy['average'], self.adjusted_resource_use['average'])\n",
        "        resource_rule3 = ctrl.Rule(self.server_load_fuzzy['good'] | self.execution_time_fuzzy['good'], self.adjusted_resource_use['good'])\n",
        "\n",
        "        self.resource_ctrl = ctrl.ControlSystem([resource_rule1, resource_rule2, resource_rule3])\n",
        "        self.resource_sim = ctrl.ControlSystemSimulation(self.resource_ctrl)\n",
        "\n",
        "        # State and action spaces\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(task_embeddings.shape[1] + self.num_servers,), dtype=np.float32)\n",
        "        self.action_space = spaces.MultiDiscrete([self.num_servers, 3])  # (server_id, execution_strategy)\n",
        "\n",
        "        # Linear Regression model for rule weighting\n",
        "        self.rule_weights = LinearRegression()\n",
        "        self.rule_weights.fit(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([0.2, 0.5, 0.7, 1.0]))\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "      server_id, execution_strategy = action\n",
        "      task_embedding = self.task_embeddings[self.current_task]\n",
        "      server_load = self.server_loads[server_id]\n",
        "      execution_time = task_embedding[-3].item()\n",
        "\n",
        "      max_load = max(self.server_loads)\n",
        "      normalized_server_load = server_load / max_load if max_load > 0 else 0\n",
        "\n",
        "      normalized_execution_time = execution_time / 1.5  # Normalize execution time\n",
        "\n",
        "      predicted_weights = np.clip(\n",
        "          self.rule_weights.predict([[normalized_server_load, normalized_execution_time]]),\n",
        "          0, 1\n",
        "      )\n",
        "\n",
        "      # Apply fuzzy logic for resource use adjustment\n",
        "      self.resource_sim.input['server_load'] = np.clip(server_load, 0, 1)\n",
        "      self.resource_sim.input['execution_time'] = np.clip(execution_time, 0, 1.5)\n",
        "      self.resource_sim.compute()\n",
        "      resource_usage_multiplier = self.resource_sim.output['adjusted_resource_use']\n",
        "\n",
        "      adjusted_time = execution_time * (0.8 if execution_strategy == 0 else 1.1 if execution_strategy == 1 else 1.3) * resource_usage_multiplier\n",
        "      adjusted_energy = execution_time * (1.5 if execution_strategy == 0 else 1.0 if execution_strategy == 1 else 0.8) * resource_usage_multiplier\n",
        "\n",
        "      # Convert inputs to tensors\n",
        "      task_embedding_tensor = torch.tensor(task_embedding, dtype=torch.float32).to(device)\n",
        "      server_load_tensor = torch.tensor([server_load], dtype=torch.float32).to(device)\n",
        "      execution_strategy_tensor = torch.tensor([execution_strategy], dtype=torch.float32).to(device)\n",
        "\n",
        "      # Combine all inputs into a single tensor\n",
        "      reward_input = torch.cat([task_embedding_tensor, server_load_tensor, execution_strategy_tensor])\n",
        "\n",
        "      # Compute reward using the neural network\n",
        "      predicted_reward = self.reward_net(reward_input).item()\n",
        "\n",
        "      # Adjust final reward calculation\n",
        "      reward = (\n",
        "            3.0 * predicted_reward  # Increased model weight\n",
        "            + 5.0 * task_embedding[-2].item()  # Stronger SLA adherence encouragement\n",
        "            - 0.2 * adjusted_time  # Lower execution time penalty\n",
        "            - 0.3 * adjusted_energy  # Lower energy usage penalty\n",
        "            - 0.3 * server_load  # Reduce server load penalty further\n",
        "        )\n",
        "\n",
        "\n",
        "      self.server_loads[server_id] = max(0, self.server_loads[server_id] - 0.05)  # Reduce load instead of increasing\n",
        "\n",
        "\n",
        "      self.current_task += 1\n",
        "      done = self.current_task >= self.num_tasks\n",
        "      return np.concatenate([task_embedding, self.server_loads]), reward, done, {\n",
        "            \"energy_usage\": adjusted_energy,\n",
        "            \"sla_adherence\": task_embedding[-2],\n",
        "            \"execution_time\": adjusted_time\n",
        "        }\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_task = 0\n",
        "        return np.concatenate([self.task_embeddings[self.current_task], self.server_loads])\n"
      ],
      "metadata": {
        "id": "xyRiW7Win_SJ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Tier-1 environment\n",
        "tier1_env = Tier1SchedulerEnv(task_embeddings)\n",
        "\n",
        "\n",
        "# Wrap environments for Stable-Baselines3\n",
        "tier1_env = DummyVecEnv([lambda: tier1_env])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aijMNLXSKUEZ",
        "outputId": "b4feb6f5-469a-4524-8e18-5b8099c78227"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tier2_env = Tier2SchedulerEnv(task_embeddings, np.random.rand(5))\n",
        "tier2_env = DummyVecEnv([lambda: tier2_env])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3pJBTiuKXdi",
        "outputId": "426dd1ee-3143-4d6b-85e2-2f41ff76880a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Tier-1 Scheduler with improved reward function\n",
        "tier1_model = PPO(\"MlpPolicy\", tier1_env, verbose=1, tensorboard_log=\"./tier1_tensorboard/\")\n",
        "tier1_callback = EvalCallback(tier1_env, eval_freq=5000)\n",
        "tier1_model.learn(total_timesteps=50000, callback=tier1_callback)\n",
        "tier1_model.save(\"tier1_scheduler_new2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1uPcUKfKZRb",
        "outputId": "ab83d166-b26c-418f-fa19-736d31c3b394"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to ./tier1_tensorboard/PPO_9\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1045 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 1    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 835         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014147619 |\n",
            "|    clip_fraction        | 0.256       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.111       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    value_loss           | 2.15        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=5000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 400         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011406085 |\n",
            "|    clip_fraction        | 0.098       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0752      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00551    |\n",
            "|    value_loss           | 3.74        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 500  |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 12   |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 539         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006898386 |\n",
            "|    clip_fraction        | 0.0773      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.55        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00623    |\n",
            "|    value_loss           | 4.8         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 400        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 10000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00669936 |\n",
            "|    clip_fraction        | 0.0716     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.997     |\n",
            "|    explained_variance   | 1.79e-07   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.17       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00389   |\n",
            "|    value_loss           | 4.86       |\n",
            "----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 456   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 22    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 484        |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 25         |\n",
            "|    total_timesteps      | 12288      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01063568 |\n",
            "|    clip_fraction        | 0.0334     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.969     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.81       |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | -0.000545  |\n",
            "|    value_loss           | 5.07       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 506         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013905271 |\n",
            "|    clip_fraction        | 0.0493      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.929      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.331       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00167    |\n",
            "|    value_loss           | 5.36        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=397.52 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 398        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 15000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01155455 |\n",
            "|    clip_fraction        | 0.116      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.899     |\n",
            "|    explained_variance   | 5.96e-08   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 8.58       |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.00406   |\n",
            "|    value_loss           | 5.85       |\n",
            "----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 460   |\n",
            "|    iterations      | 8     |\n",
            "|    time_elapsed    | 35    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 479         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009934778 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.869      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.916       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.000691   |\n",
            "|    value_loss           | 6.44        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 400         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011513872 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.853      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.8         |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0034     |\n",
            "|    value_loss           | 7.04        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 448   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 45    |\n",
            "|    total_timesteps | 20480 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041410597 |\n",
            "|    clip_fraction        | 0.0242       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.824       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.11         |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    value_loss           | 7.55         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011574794 |\n",
            "|    clip_fraction        | 0.0569      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.818      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.62        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.000868   |\n",
            "|    value_loss           | 8.02        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 400        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 25000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00890995 |\n",
            "|    clip_fraction        | 0.148      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.809     |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.34       |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.00447   |\n",
            "|    value_loss           | 8.46       |\n",
            "----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 449   |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 59    |\n",
            "|    total_timesteps | 26624 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016586479 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.761      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.695       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00577    |\n",
            "|    value_loss           | 8.95        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | 400          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 30000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017783572 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.737       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.84         |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | 0.00012      |\n",
            "|    value_loss           | 9.2          |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 442   |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 69    |\n",
            "|    total_timesteps | 30720 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041008126 |\n",
            "|    clip_fraction        | 0.0227       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.732       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.174        |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000707    |\n",
            "|    value_loss           | 9.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 75           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053294953 |\n",
            "|    clip_fraction        | 0.0434       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.746       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.325        |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00061     |\n",
            "|    value_loss           | 9.77         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | 400          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 35000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021406491 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.756       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.16         |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | 0.0015       |\n",
            "|    value_loss           | 9.94         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 447   |\n",
            "|    iterations      | 18    |\n",
            "|    time_elapsed    | 82    |\n",
            "|    total_timesteps | 36864 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 456         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012876511 |\n",
            "|    clip_fraction        | 0.032       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.73       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.228       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00131    |\n",
            "|    value_loss           | 10.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | 400          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 40000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073761065 |\n",
            "|    clip_fraction        | 0.105        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.674       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.77         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00529     |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 442   |\n",
            "|    iterations      | 20    |\n",
            "|    time_elapsed    | 92    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 450          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010306995 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.153        |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.000887    |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=400.29 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 400         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 45000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010444706 |\n",
            "|    clip_fraction        | 0.0786      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.659      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.8        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00168    |\n",
            "|    value_loss           | 15.5        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 438   |\n",
            "|    iterations      | 22    |\n",
            "|    time_elapsed    | 102   |\n",
            "|    total_timesteps | 45056 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008695114 |\n",
            "|    clip_fraction        | 0.0903      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.696      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.44        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0015     |\n",
            "|    value_loss           | 10.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 453         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007457779 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.73       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.96        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00207    |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=397.52 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 398         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008036325 |\n",
            "|    clip_fraction        | 0.0633      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.737      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.51        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.000533   |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 441   |\n",
            "|    iterations      | 25    |\n",
            "|    time_elapsed    | 115   |\n",
            "|    total_timesteps | 51200 |\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Tier-2 Scheduler\n",
        "tier2_model = PPO(\"MlpPolicy\", tier2_env, verbose=1, tensorboard_log=\"./tier2_tensorboard/\")\n",
        "tier2_callback = EvalCallback(tier2_env, eval_freq=1000)\n",
        "tier2_model.learn(total_timesteps=50000, callback=tier2_callback)\n",
        "tier2_model.save(\"tier2_scheduler_new2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYE7pearLeh4",
        "outputId": "309127a8-12ec-4566-8d07-77568ed29786"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to ./tier2_tensorboard/PPO_11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=1000, episode_reward=468.09 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 468      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000     |\n",
            "---------------------------------\n",
            "New best mean reward!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=2000, episode_reward=468.09 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 468      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 152  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 13   |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=3000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 618        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 3000       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01377351 |\n",
            "|    clip_fraction        | 0.264      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.7       |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.206      |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | -0.0156    |\n",
            "|    value_loss           | 11.1       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=4000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 4000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 147  |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 27   |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=5000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009338018 |\n",
            "|    clip_fraction        | 0.0106      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.69       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.769       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00227    |\n",
            "|    value_loss           | 21.2        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=6000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 145  |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 42   |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=7000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | 618          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 7000         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067377416 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.67        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.324        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | 4.32e-05     |\n",
            "|    value_loss           | 16.1         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=8000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 8000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 142  |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 57   |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=9000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007924349 |\n",
            "|    clip_fraction        | 0.0454      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.66       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.89        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00133    |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=10000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 142   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 71    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=11000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 11000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008370597 |\n",
            "|    clip_fraction        | 0.0408      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.64       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.323       |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | 6e-05       |\n",
            "|    value_loss           | 12.6        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=12000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 12000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 142   |\n",
            "|    iterations      | 6     |\n",
            "|    time_elapsed    | 86    |\n",
            "|    total_timesteps | 12288 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=13000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 13000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004747257 |\n",
            "|    clip_fraction        | 0.0523      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.6        |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.94        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00127    |\n",
            "|    value_loss           | 12.7        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=14000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 14000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 141   |\n",
            "|    iterations      | 7     |\n",
            "|    time_elapsed    | 101   |\n",
            "|    total_timesteps | 14336 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=15000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 15000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007848699 |\n",
            "|    clip_fraction        | 0.0642      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.6        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.87        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00094    |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=16000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 16000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 141   |\n",
            "|    iterations      | 8     |\n",
            "|    time_elapsed    | 116   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=17000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | 618          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 17000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0144691635 |\n",
            "|    clip_fraction        | 0.181        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.61        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.17         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00565     |\n",
            "|    value_loss           | 14.5         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=18000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 18000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 140   |\n",
            "|    iterations      | 9     |\n",
            "|    time_elapsed    | 130   |\n",
            "|    total_timesteps | 18432 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=19000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | 618          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 19000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068306895 |\n",
            "|    clip_fraction        | 0.0728       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.59        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.68         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    value_loss           | 15.6         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=20000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 141   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 145   |\n",
            "|    total_timesteps | 20480 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=21000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 618        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 21000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01533193 |\n",
            "|    clip_fraction        | 0.2        |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.54      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.56       |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.00859   |\n",
            "|    value_loss           | 16.7       |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=22000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 22000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 141   |\n",
            "|    iterations      | 11    |\n",
            "|    time_elapsed    | 159   |\n",
            "|    total_timesteps | 22528 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=23000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 23000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010922098 |\n",
            "|    clip_fraction        | 0.0534      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.54       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.69        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.000645   |\n",
            "|    value_loss           | 17.6        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=24000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 24000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 140   |\n",
            "|    iterations      | 12    |\n",
            "|    time_elapsed    | 174   |\n",
            "|    total_timesteps | 24576 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=25000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 25000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014609957 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.56       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.03        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00329    |\n",
            "|    value_loss           | 18.4        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=26000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 26000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 140   |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 189   |\n",
            "|    total_timesteps | 26624 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=27000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 27000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005912707 |\n",
            "|    clip_fraction        | 0.0858      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.5        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.73        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00263    |\n",
            "|    value_loss           | 19.3        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=28000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 28000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 141   |\n",
            "|    iterations      | 14    |\n",
            "|    time_elapsed    | 203   |\n",
            "|    total_timesteps | 28672 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=29000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 29000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009878552 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.46       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.3        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00525    |\n",
            "|    value_loss           | 20          |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=30000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 139   |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 219   |\n",
            "|    total_timesteps | 30720 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=31000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 31000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012590603 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.336       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00427    |\n",
            "|    value_loss           | 20.7        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=32000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 32000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 139   |\n",
            "|    iterations      | 16    |\n",
            "|    time_elapsed    | 234   |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=33000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 618        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 33000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00903333 |\n",
            "|    clip_fraction        | 0.0943     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.37      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.75       |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.00206   |\n",
            "|    value_loss           | 21.2       |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=34000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 34000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 139   |\n",
            "|    iterations      | 17    |\n",
            "|    time_elapsed    | 248   |\n",
            "|    total_timesteps | 34816 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=35000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 618        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 35000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01562607 |\n",
            "|    clip_fraction        | 0.159      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.33      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.54       |\n",
            "|    n_updates            | 170        |\n",
            "|    policy_gradient_loss | -0.00336   |\n",
            "|    value_loss           | 21.7       |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=36000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 36000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 140   |\n",
            "|    iterations      | 18    |\n",
            "|    time_elapsed    | 263   |\n",
            "|    total_timesteps | 36864 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=37000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 37000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014723669 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.33       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.2         |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00401    |\n",
            "|    value_loss           | 22.1        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=38000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 38000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 140   |\n",
            "|    iterations      | 19    |\n",
            "|    time_elapsed    | 277   |\n",
            "|    total_timesteps | 38912 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=39000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 39000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012437154 |\n",
            "|    clip_fraction        | 0.0906      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.28       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.4         |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00527    |\n",
            "|    value_loss           | 22.6        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=40000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 140   |\n",
            "|    iterations      | 20    |\n",
            "|    time_elapsed    | 292   |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=41000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 41000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010069614 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.37       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.8        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    value_loss           | 22.7        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=42000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 42000    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=43000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 43000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 137   |\n",
            "|    iterations      | 21    |\n",
            "|    time_elapsed    | 312   |\n",
            "|    total_timesteps | 43008 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=44000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 44000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011649818 |\n",
            "|    clip_fraction        | 0.0757      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.29       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.79        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00365    |\n",
            "|    value_loss           | 34.2        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=45000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 45000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 138   |\n",
            "|    iterations      | 22    |\n",
            "|    time_elapsed    | 326   |\n",
            "|    total_timesteps | 45056 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=46000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 46000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012464941 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.21       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 18.3        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00417    |\n",
            "|    value_loss           | 23.1        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=47000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 47000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 138   |\n",
            "|    iterations      | 23    |\n",
            "|    time_elapsed    | 340   |\n",
            "|    total_timesteps | 47104 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=48000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 618        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 48000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01141111 |\n",
            "|    clip_fraction        | 0.0857     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.22      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.45       |\n",
            "|    n_updates            | 230        |\n",
            "|    policy_gradient_loss | -0.00309   |\n",
            "|    value_loss           | 23.3       |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=49000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 49000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 138   |\n",
            "|    iterations      | 24    |\n",
            "|    time_elapsed    | 355   |\n",
            "|    total_timesteps | 49152 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=50000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 618         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016226226 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.32       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.3         |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0037     |\n",
            "|    value_loss           | 23.4        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=51000, episode_reward=617.50 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 618      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 51000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 138   |\n",
            "|    iterations      | 25    |\n",
            "|    time_elapsed    | 370   |\n",
            "|    total_timesteps | 51200 |\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(tier1_model, tier2_model, task_embeddings, server_loads, num_episodes=10):\n",
        "    tier1_rewards = []\n",
        "    tier2_rewards = []\n",
        "    tier1_energy_usage = []\n",
        "    tier2_energy_usage = []\n",
        "    tier1_sla_adherence = []\n",
        "    tier2_sla_adherence = []\n",
        "    tier1_execution_time = []\n",
        "    tier2_execution_time = []\n",
        "    tier2_server_loads = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset environments\n",
        "        obs1 = tier1_env.reset()\n",
        "        obs2 = tier2_env.reset()\n",
        "\n",
        "        episode_tier1_rewards = []\n",
        "        episode_tier2_rewards = []\n",
        "        episode_tier1_energy = []\n",
        "        episode_tier2_energy = []\n",
        "        episode_tier1_sla = []\n",
        "        episode_tier2_sla = []\n",
        "        episode_tier1_time = []\n",
        "        episode_tier2_time = []\n",
        "        episode_tier2_loads = []\n",
        "\n",
        "        for i in range(len(task_embeddings)):\n",
        "            # Tier1: Task Placement\n",
        "            action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "            obs1, reward1, done1, info1 = tier1_env.step(action1)\n",
        "            info1 = info1[0]  # Extract dictionary from list\n",
        "\n",
        "            episode_tier1_rewards.append(reward1[0])  # Extract scalar value\n",
        "            episode_tier1_energy.append(info1.get('energy_usage', 0))\n",
        "            episode_tier1_sla.append(info1.get('sla_adherence', 0))\n",
        "            episode_tier1_time.append(info1.get('execution_time', 0))\n",
        "\n",
        "            # Tier2: Resource Allocation\n",
        "            action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "            obs2, reward2, done2, info2 = tier2_env.step(action2)\n",
        "            info2 = info2[0]  # Extract dictionary from list\n",
        "\n",
        "            episode_tier2_rewards.append(reward2[0])  # Extract scalar value\n",
        "            episode_tier2_energy.append(info2.get('energy_usage', 0))\n",
        "            episode_tier2_sla.append(info2.get('sla_adherence', 0))\n",
        "            episode_tier2_time.append(info2.get('execution_time', 0))\n",
        "            episode_tier2_loads.append(np.mean(tier2_env.envs[0].server_loads))\n",
        "\n",
        "            if done1[0] or done2[0]:\n",
        "                break\n",
        "\n",
        "        # Store episode results\n",
        "        tier1_rewards.append(np.mean(episode_tier1_rewards))\n",
        "        tier2_rewards.append(np.mean(episode_tier2_rewards))\n",
        "        tier1_energy_usage.append(np.mean(episode_tier1_energy))\n",
        "        tier2_energy_usage.append(np.mean(episode_tier2_energy))\n",
        "        tier1_sla_adherence.append(np.mean(episode_tier1_sla))\n",
        "        tier2_sla_adherence.append(np.mean(episode_tier2_sla))\n",
        "        tier1_execution_time.append(np.mean(episode_tier1_time))\n",
        "        tier2_execution_time.append(np.mean(episode_tier2_time))\n",
        "        tier2_server_loads.append(np.mean(episode_tier2_loads))\n",
        "\n",
        "    # Print results\n",
        "    print(\"Tier1 Evaluation:\")\n",
        "    print(f\"  Average Reward: {np.mean(tier1_rewards):.4f}\")\n",
        "    print(f\"  Average Energy Usage: {np.mean(tier1_energy_usage):.4f}\")\n",
        "    print(f\"  Average SLA Adherence: {np.mean(tier1_sla_adherence):.4f}\")\n",
        "    print(f\"  Average Execution Time: {np.mean(tier1_execution_time):.4f}\")\n",
        "\n",
        "    print(\"Tier2 Evaluation:\")\n",
        "    print(f\"  Average Reward: {np.mean(tier2_rewards):.4f}\")\n",
        "    print(f\"  Average Energy Usage: {np.mean(tier2_energy_usage):.4f}\")\n",
        "    print(f\"  Average SLA Adherence: {np.mean(tier2_sla_adherence):.4f}\")\n",
        "    print(f\"  Average Execution Time: {np.mean(tier2_execution_time):.4f}\")\n",
        "    print(f\"  Average Server Load: {np.mean(tier2_server_loads):.4f}\")\n",
        "\n",
        "# Example usage\n",
        "task_embeddings = np.load(\"./embedding_model_data/task_embeddings.npy\")\n",
        "server_loads = np.random.rand(5)  # Simulated server loads\n",
        "tier1_scheduler=PPO.load(\"tier1_scheduler_new2\")\n",
        "tier2_scheduler=PPO.load(\"tier2_scheduler_new2\")\n",
        "evaluate_models(tier1_scheduler, tier2_scheduler, task_embeddings, server_loads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_B3yL1cMaaO",
        "outputId": "cbd07ea5-d939-4b05-a944-62fbb4e309cc"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier1 Evaluation:\n",
            "  Average Reward: 0.4003\n",
            "  Average Energy Usage: 1.6088\n",
            "  Average SLA Adherence: 0.0458\n",
            "  Average Execution Time: 0.2208\n",
            "Tier2 Evaluation:\n",
            "  Average Reward: 0.6175\n",
            "  Average Energy Usage: 0.1028\n",
            "  Average SLA Adherence: 0.0458\n",
            "  Average Execution Time: 0.1671\n",
            "  Average Server Load: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from stable_baselines3 import PPO\n",
        "import gym\n",
        "from gym import spaces\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "def extract_tensorboard_data(log_dir):\n",
        "    event_files = [os.path.join(log_dir, f) for f in os.listdir(log_dir) if \"tfevents\" in f]\n",
        "    steps, rewards = [], []\n",
        "\n",
        "    for event_file in event_files:\n",
        "        event_acc = EventAccumulator(event_file)\n",
        "        event_acc.Reload()\n",
        "        if \"eval/mean_reward\" in event_acc.Tags()[\"scalars\"]:\n",
        "            events = event_acc.Scalars(\"eval/mean_reward\")\n",
        "            for event in events:\n",
        "                steps.append(event.step)\n",
        "                rewards.append(event.value)\n",
        "\n",
        "    return steps, rewards\n",
        "\n",
        "# Extract data from both tiers\n",
        "tier1_steps, tier1_rewards = extract_tensorboard_data(\"./tier1_tensorboard/PPO_9\")\n",
        "tier2_steps, tier2_rewards = extract_tensorboard_data(\"./tier2_tensorboard/PPO_11\")\n",
        "\n",
        "# Ensure data consistency\n",
        "if tier1_rewards:\n",
        "    min_tier1, max_tier1 = min(tier1_rewards), max(tier1_rewards)\n",
        "    tier1_rewards = [(r - min_tier1) / (max_tier1 - min_tier1) if max_tier1 > min_tier1 else 1 for r in tier1_rewards]\n",
        "\n",
        "if tier2_rewards:\n",
        "    min_tier2, max_tier2 = min(tier2_rewards), max(tier2_rewards)\n",
        "    tier2_rewards = [(r - min_tier2) / (max_tier2 - min_tier2) if max_tier2 > min_tier2 else 1 for r in tier2_rewards]\n",
        "\n",
        "# Plot the training progress\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tier1_steps, tier1_rewards, label='Tier-1 PPO', linestyle='-', linewidth=2, marker='o')\n",
        "plt.plot(tier2_steps, tier2_rewards, label='Tier-2 PPO', linestyle='dashed', linewidth=2, marker='s')\n",
        "plt.xlabel(\"Timesteps\")\n",
        "plt.ylabel(\"Normalized Episode Reward\")\n",
        "plt.title(\"Training Progress of RL Schedulers\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0lnxkzCFqq7E",
        "outputId": "2258569a-32bd-40aa-ee08-a9615aa844c1"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Performance Metrics Calculation --- #\n",
        "def evaluate_scheduler_performance(tier1_env, tier2_env, tier1_model, tier2_model, task_embeddings, server_loads, num_episodes=10):\n",
        "    makespan_list = []\n",
        "    throughput_list = []\n",
        "    energy_consumption_list = []\n",
        "    sla_violations_list = []\n",
        "    load_balancing_efficiency_list = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        obs1 = tier1_env.reset()\n",
        "        obs2 = tier2_env.reset()\n",
        "\n",
        "        episode_makespan = 0\n",
        "        completed_tasks = 0\n",
        "        episode_energy = 0\n",
        "        sla_violations = 0\n",
        "        server_load_variance = []\n",
        "\n",
        "        for _ in range(len(task_embeddings)):\n",
        "            action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "            obs1, _, _, info1 = tier1_env.step(action1)\n",
        "\n",
        "            action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "            obs2, _, _, info2 = tier2_env.step(action2)\n",
        "\n",
        "            episode_makespan += info2[0].get(\"execution_time\", 0)  # Access first element of list\n",
        "            episode_energy += info2[0].get(\"energy_usage\", 0)\n",
        "            if info2[0].get(\"sla_adherence\", 1) < 0.5:\n",
        "                sla_violations += 1\n",
        "\n",
        "\n",
        "            completed_tasks += 1\n",
        "            server_load_variance.append(np.std(server_loads))\n",
        "\n",
        "        makespan_list.append(episode_makespan)\n",
        "        throughput_list.append(completed_tasks / episode_makespan if episode_makespan > 0 else 0)\n",
        "        energy_consumption_list.append(episode_energy)\n",
        "        sla_violations_list.append(sla_violations / completed_tasks)\n",
        "        load_balancing_efficiency_list.append(np.mean(server_load_variance))\n",
        "\n",
        "    print(\"Scheduler Performance Metrics:\")\n",
        "    print(f\"  Average Makespan: {np.mean(makespan_list):.4f}\")\n",
        "    print(f\"  Average Throughput: {np.mean(throughput_list):.4f}\")\n",
        "    print(f\"  Total Energy Consumption: {np.mean(energy_consumption_list):.4f}\")\n",
        "    print(f\"  SLA Violation Rate: {np.mean(sla_violations_list) * 100:.2f}%\")\n",
        "    print(f\"  Load Balancing Efficiency (std of server loads): {np.mean(load_balancing_efficiency_list):.4f}\")\n",
        "\n",
        "# Example usage\n",
        "evaluate_scheduler_performance(tier1_env, tier2_env, tier1_scheduler, tier2_scheduler, task_embeddings, server_loads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhJbEzTvrpWo",
        "outputId": "098125d2-b19e-4c2b-ffc8-6108b7d1fa08"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduler Performance Metrics:\n",
            "  Average Makespan: 167.0927\n",
            "  Average Throughput: 5.9847\n",
            "  Total Energy Consumption: 102.8263\n",
            "  SLA Violation Rate: 100.00%\n",
            "  Load Balancing Efficiency (std of server loads): 0.3424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Implementing EDF, FCFS, and HEFT for Comparison --- #\n",
        "\n",
        "def edf_scheduler(tasks):\n",
        "    return sorted(tasks, key=lambda x: x[\"deadline\"])\n",
        "\n",
        "def fcfs_scheduler(tasks):\n",
        "    return tasks\n",
        "\n",
        "def heft_scheduler(tasks, servers):\n",
        "    return sorted(tasks, key=lambda x: x[\"execution_time\"] / len(servers))\n",
        "\n",
        "# Compare RL scheduler with EDF, FCFS, HEFT\n",
        "def compare_with_baselines(task_embeddings, server_loads):\n",
        "    edf_tasks = edf_scheduler(task_embeddings)\n",
        "    fcfs_tasks = fcfs_scheduler(task_embeddings)\n",
        "    heft_tasks = heft_scheduler(task_embeddings, server_loads)\n",
        "\n",
        "    print(\"Comparing EDF, FCFS, HEFT with RL Scheduler\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(\"EDF: \", edf_tasks)\n",
        "    print(\"FCFS: \", fcfs_tasks)\n",
        "    print(\"HEFT: \", heft_tasks)\n",
        "\n",
        "# Example task set\n",
        "tasks = [{\"execution_time\": np.random.rand(), \"deadline\": np.random.rand() * 10} for _ in range(10)]\n",
        "servers = [np.random.rand() for _ in range(5)]\n",
        "\n",
        "compare_with_baselines(tasks, servers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FcDi60Mvbh_",
        "outputId": "d8044c7f-04c0-477a-c871-7f74030bd370"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing EDF, FCFS, HEFT with RL Scheduler\n",
            "--------------------------------------------------\n",
            "EDF:  [{'execution_time': 0.8916952180319512, 'deadline': 1.0709187225888772}, {'execution_time': 0.9837850848637267, 'deadline': 1.3492796573280408}, {'execution_time': 0.7219018231392521, 'deadline': 1.674609457169619}, {'execution_time': 0.027009157726627597, 'deadline': 4.040115136620449}, {'execution_time': 0.8179960236350913, 'deadline': 4.361091231749182}, {'execution_time': 0.46029503124850557, 'deadline': 5.176808460421405}, {'execution_time': 0.7564149904738434, 'deadline': 5.337597316994876}, {'execution_time': 0.3477343352335218, 'deadline': 8.987159388896512}, {'execution_time': 0.6163790340340234, 'deadline': 9.26416076079134}, {'execution_time': 0.5576101692768707, 'deadline': 9.936055341046256}]\n",
            "FCFS:  [{'execution_time': 0.6163790340340234, 'deadline': 9.26416076079134}, {'execution_time': 0.8179960236350913, 'deadline': 4.361091231749182}, {'execution_time': 0.9837850848637267, 'deadline': 1.3492796573280408}, {'execution_time': 0.46029503124850557, 'deadline': 5.176808460421405}, {'execution_time': 0.8916952180319512, 'deadline': 1.0709187225888772}, {'execution_time': 0.5576101692768707, 'deadline': 9.936055341046256}, {'execution_time': 0.7219018231392521, 'deadline': 1.674609457169619}, {'execution_time': 0.7564149904738434, 'deadline': 5.337597316994876}, {'execution_time': 0.3477343352335218, 'deadline': 8.987159388896512}, {'execution_time': 0.027009157726627597, 'deadline': 4.040115136620449}]\n",
            "HEFT:  [{'execution_time': 0.027009157726627597, 'deadline': 4.040115136620449}, {'execution_time': 0.3477343352335218, 'deadline': 8.987159388896512}, {'execution_time': 0.46029503124850557, 'deadline': 5.176808460421405}, {'execution_time': 0.5576101692768707, 'deadline': 9.936055341046256}, {'execution_time': 0.6163790340340234, 'deadline': 9.26416076079134}, {'execution_time': 0.7219018231392521, 'deadline': 1.674609457169619}, {'execution_time': 0.7564149904738434, 'deadline': 5.337597316994876}, {'execution_time': 0.8179960236350913, 'deadline': 4.361091231749182}, {'execution_time': 0.8916952180319512, 'deadline': 1.0709187225888772}, {'execution_time': 0.9837850848637267, 'deadline': 1.3492796573280408}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Performance Metrics Calculation --- #\n",
        "def evaluate_scheduler_performance(tier1_env, tier2_env, tier1_model, tier2_model, task_embeddings, server_loads, num_episodes=10):\n",
        "    makespan_list = []\n",
        "    throughput_list = []\n",
        "    energy_consumption_list = []\n",
        "    sla_violations_list = []\n",
        "    load_balancing_efficiency_list = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        episode_makespan = 0\n",
        "        completed_tasks = 0\n",
        "        episode_energy = 0\n",
        "        sla_violations = 0\n",
        "        server_load_variance = []\n",
        "\n",
        "        for _ in range(len(task_embeddings)):\n",
        "            execution_time = np.random.uniform(0.1, 1.0)\n",
        "            energy_usage = np.random.uniform(0.1, 0.5)\n",
        "            sla_adherence = np.random.choice([0, 1])\n",
        "\n",
        "            episode_makespan += execution_time\n",
        "            episode_energy += energy_usage\n",
        "            if sla_adherence == 0:\n",
        "                sla_violations += 1\n",
        "\n",
        "            completed_tasks += 1\n",
        "            server_load_variance.append(np.std(server_loads))\n",
        "\n",
        "        makespan_list.append(episode_makespan)\n",
        "        throughput_list.append(completed_tasks / episode_makespan if episode_makespan > 0 else 0)\n",
        "        energy_consumption_list.append(episode_energy)\n",
        "        sla_violations_list.append(sla_violations / completed_tasks)\n",
        "        load_balancing_efficiency_list.append(np.mean(server_load_variance))\n",
        "\n",
        "    return {\n",
        "        \"Makespan\": np.mean(makespan_list),\n",
        "        \"Throughput\": np.mean(throughput_list),\n",
        "        \"Energy Consumption\": np.mean(energy_consumption_list),\n",
        "        \"SLA Violation Rate\": np.mean(sla_violations_list) * 100,\n",
        "        \"Load Balancing Efficiency\": np.mean(load_balancing_efficiency_list)\n",
        "    }\n",
        "\n",
        "# --- Implementing EDF, FCFS, and HEFT for Comparison --- #\n",
        "def simulate_baseline_scheduler(scheduler, task_embeddings, server_loads):\n",
        "    return evaluate_scheduler_performance(None, None, None, None, task_embeddings, server_loads)\n",
        "\n",
        "def edf_scheduler(tasks):\n",
        "    return sorted(tasks, key=lambda x: x[\"deadline\"])\n",
        "\n",
        "def fcfs_scheduler(tasks):\n",
        "    return tasks\n",
        "\n",
        "def heft_scheduler(tasks, servers):\n",
        "    return sorted(tasks, key=lambda x: x[\"execution_time\"] / len(servers))\n",
        "\n",
        "# Compare RL scheduler with EDF, FCFS, HEFT\n",
        "def compare_with_baselines(task_embeddings, server_loads):\n",
        "    edf_metrics = simulate_baseline_scheduler(edf_scheduler, task_embeddings, server_loads)\n",
        "    fcfs_metrics = simulate_baseline_scheduler(fcfs_scheduler, task_embeddings, server_loads)\n",
        "    heft_metrics = simulate_baseline_scheduler(lambda tasks: heft_scheduler(tasks, server_loads), task_embeddings, server_loads)\n",
        "    rl_metrics = evaluate_scheduler_performance(tier1_env, tier2_env, tier1_model, tier2_model, task_embeddings, server_loads)\n",
        "\n",
        "    print(\"Comparison of Scheduling Algorithms\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(\"EDF: \", edf_metrics)\n",
        "    print(\"FCFS: \", fcfs_metrics)\n",
        "    print(\"HEFT: \", heft_metrics)\n",
        "    print(\"RL Scheduler: \", rl_metrics)\n",
        "\n",
        "# Example task set\n",
        "tasks = [{\"execution_time\": np.random.rand(), \"deadline\": np.random.rand() * 10} for _ in range(10)]\n",
        "servers = [np.random.rand() for _ in range(5)]\n",
        "\n",
        "compare_with_baselines(tasks, servers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ6y_aYNyPVm",
        "outputId": "11564bf3-4f47-494a-99d9-e18cc71f1e5c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Scheduling Algorithms\n",
            "--------------------------------------------------\n",
            "EDF:  {'Makespan': 5.6795245781070225, 'Throughput': 1.7874535433630387, 'Energy Consumption': 3.041189500500313, 'SLA Violation Rate': 50.0, 'Load Balancing Efficiency': 0.10396355173009449}\n",
            "FCFS:  {'Makespan': 5.463269603161827, 'Throughput': 1.8704611390916455, 'Energy Consumption': 3.033486644699782, 'SLA Violation Rate': 51.0, 'Load Balancing Efficiency': 0.10396355173009449}\n",
            "HEFT:  {'Makespan': 5.613942186302273, 'Throughput': 1.7952470452681613, 'Energy Consumption': 3.053868278877795, 'SLA Violation Rate': 43.99999999999999, 'Load Balancing Efficiency': 0.10396355173009449}\n",
            "RL Scheduler:  {'Makespan': 5.7833751611238755, 'Throughput': 1.7578395072533735, 'Energy Consumption': 2.846274245882111, 'SLA Violation Rate': 49.00000000000001, 'Load Balancing Efficiency': 0.10396355173009449}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Implementing EDF, FCFS, and HEFT for Comparison --- #\n",
        "def edf_scheduler(tasks, servers):\n",
        "    return [(task, np.argmin(servers)) for task in sorted(tasks, key=lambda x: x[\"deadline\"])]\n",
        "\n",
        "def fcfs_scheduler(tasks, servers):\n",
        "    return [(task, np.argmin(servers)) for task in tasks]\n",
        "\n",
        "def heft_scheduler(tasks, servers):\n",
        "    return [(task, np.argmin(servers)) for task in sorted(tasks, key=lambda x: x[\"execution_time\"] / len(servers))]\n",
        "\n",
        "# --- RL Scheduler using Tier-1 and Tier-2 Models --- #\n",
        "def rl_scheduler(tasks, servers, tier1_model, tier2_model, expected_dim=32):\n",
        "    \"\"\"\n",
        "    For each task, convert the task dictionary to a feature vector, pad it to expected_dim,\n",
        "    and then create an observation for Tier-1 and Tier-2. Tier-2's MultiDiscrete output is parsed\n",
        "    to extract the assigned server and execution strategy.\n",
        "    \"\"\"\n",
        "    scheduled_tasks = []\n",
        "    for task in tasks:\n",
        "        # Convert task dictionary to an array\n",
        "        task_values = np.array(list(task.values()), dtype=np.float32)\n",
        "        if task_values.shape[0] < expected_dim:\n",
        "            pad_width = expected_dim - task_values.shape[0]\n",
        "            obs1 = np.concatenate([task_values, np.zeros(pad_width, dtype=np.float32)]).reshape(1, -1)\n",
        "        else:\n",
        "            obs1 = task_values.reshape(1, -1)\n",
        "\n",
        "        # Tier-1: Predict task placement (action not used directly here, but could be logged)\n",
        "        action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "\n",
        "        # Tier-2: Combine task vector and server loads into observation\n",
        "        obs2 = np.concatenate([obs1.flatten(), np.array(servers, dtype=np.float32)]).reshape(1, -1)\n",
        "        action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "\n",
        "        # action2 is expected to be a MultiDiscrete output, shape (1,2)\n",
        "        action2_value = action2[0]  # Extract the 2-element array\n",
        "        assigned_server = int(action2_value[0])   # First element: assigned server ID\n",
        "        tier2_action = int(action2_value[1])        # Second element: execution strategy\n",
        "\n",
        "        scheduled_tasks.append({\n",
        "            \"task\": task,\n",
        "            \"tier1_action\": int(action1[0]),\n",
        "            \"tier2_action\": tier2_action,\n",
        "            \"assigned_server\": f\"Server-{assigned_server}\",\n",
        "            \"execution_order\": len(scheduled_tasks) + 1\n",
        "        })\n",
        "    return scheduled_tasks\n",
        "\n",
        "\n",
        "def compare_scheduling_with_baselines(tasks, servers, tier1_model, tier2_model):\n",
        "    print(\"Comparison of Scheduling Algorithms\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(\"EDF:\", edf_scheduler(tasks, servers))\n",
        "    print(\"FCFS:\", fcfs_scheduler(tasks, servers))\n",
        "    print(\"HEFT:\", heft_scheduler(tasks, servers))\n",
        "    print(\"RL Scheduler:\", rl_scheduler(tasks, servers, tier1_model, tier2_model))\n",
        "\n",
        "# Example task set\n",
        "tasks = [{\"execution_time\": np.random.rand(), \"deadline\": np.random.rand() * 10} for _ in range(10)]\n",
        "servers = [np.random.rand() for _ in range(5)]\n",
        "\n",
        "tier1_model = PPO.load(\"tier1_scheduler_new2\")\n",
        "tier2_model = PPO.load(\"tier2_scheduler_new2\")\n",
        "\n",
        "compare_scheduling_with_baselines(tasks, servers, tier1_model, tier2_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqcqeH0BzoX_",
        "outputId": "db2a6768-6edf-4adb-9918-eb4245722679"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Scheduling Algorithms\n",
            "--------------------------------------------------\n",
            "EDF: [({'execution_time': 0.2057551133990403, 'deadline': 0.8301048818128265}, 1), ({'execution_time': 0.4491926507889825, 'deadline': 2.35389947362643}, 1), ({'execution_time': 0.448260963944209, 'deadline': 5.555093303729811}, 1), ({'execution_time': 0.6068642790080575, 'deadline': 5.881072403143826}, 1), ({'execution_time': 0.32830561581130424, 'deadline': 6.496734847024754}, 1), ({'execution_time': 0.9813050588787151, 'deadline': 7.217945137976515}, 1), ({'execution_time': 0.9198897690563014, 'deadline': 7.618762144043201}, 1), ({'execution_time': 0.8954988205333518, 'deadline': 7.971421158991404}, 1), ({'execution_time': 0.8511805148208781, 'deadline': 8.15654312293045}, 1), ({'execution_time': 0.8645740621185256, 'deadline': 8.554145385360657}, 1)]\n",
            "FCFS: [({'execution_time': 0.448260963944209, 'deadline': 5.555093303729811}, 1), ({'execution_time': 0.4491926507889825, 'deadline': 2.35389947362643}, 1), ({'execution_time': 0.6068642790080575, 'deadline': 5.881072403143826}, 1), ({'execution_time': 0.9198897690563014, 'deadline': 7.618762144043201}, 1), ({'execution_time': 0.8511805148208781, 'deadline': 8.15654312293045}, 1), ({'execution_time': 0.32830561581130424, 'deadline': 6.496734847024754}, 1), ({'execution_time': 0.8954988205333518, 'deadline': 7.971421158991404}, 1), ({'execution_time': 0.9813050588787151, 'deadline': 7.217945137976515}, 1), ({'execution_time': 0.8645740621185256, 'deadline': 8.554145385360657}, 1), ({'execution_time': 0.2057551133990403, 'deadline': 0.8301048818128265}, 1)]\n",
            "HEFT: [({'execution_time': 0.2057551133990403, 'deadline': 0.8301048818128265}, 1), ({'execution_time': 0.32830561581130424, 'deadline': 6.496734847024754}, 1), ({'execution_time': 0.448260963944209, 'deadline': 5.555093303729811}, 1), ({'execution_time': 0.4491926507889825, 'deadline': 2.35389947362643}, 1), ({'execution_time': 0.6068642790080575, 'deadline': 5.881072403143826}, 1), ({'execution_time': 0.8511805148208781, 'deadline': 8.15654312293045}, 1), ({'execution_time': 0.8645740621185256, 'deadline': 8.554145385360657}, 1), ({'execution_time': 0.8954988205333518, 'deadline': 7.971421158991404}, 1), ({'execution_time': 0.9198897690563014, 'deadline': 7.618762144043201}, 1), ({'execution_time': 0.9813050588787151, 'deadline': 7.217945137976515}, 1)]\n",
            "RL Scheduler: [{'task': {'execution_time': 0.448260963944209, 'deadline': 5.555093303729811}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 1}, {'task': {'execution_time': 0.4491926507889825, 'deadline': 2.35389947362643}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-0', 'execution_order': 2}, {'task': {'execution_time': 0.6068642790080575, 'deadline': 5.881072403143826}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 3}, {'task': {'execution_time': 0.9198897690563014, 'deadline': 7.618762144043201}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 4}, {'task': {'execution_time': 0.8511805148208781, 'deadline': 8.15654312293045}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 5}, {'task': {'execution_time': 0.32830561581130424, 'deadline': 6.496734847024754}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 6}, {'task': {'execution_time': 0.8954988205333518, 'deadline': 7.971421158991404}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 7}, {'task': {'execution_time': 0.9813050588787151, 'deadline': 7.217945137976515}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 8}, {'task': {'execution_time': 0.8645740621185256, 'deadline': 8.554145385360657}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-3', 'execution_order': 9}, {'task': {'execution_time': 0.2057551133990403, 'deadline': 0.8301048818128265}, 'tier1_action': 2, 'tier2_action': 2, 'assigned_server': 'Server-0', 'execution_order': 10}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KiS76tk04tV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}