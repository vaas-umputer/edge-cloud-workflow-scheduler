{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWSPS56EbGV79sBkU0hjFZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaas-umputer/edge-cloud-workflow-scheduler/blob/main/uncertainty_aware_scheduler_review2_mar11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2oMvgmdldww",
        "outputId": "bcbad836-be89-4a05-f278-7938c0c68516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd_MzCcCli_d",
        "outputId": "b70d317c-1e93-4430-c873-625eb99bde2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m859.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.0\n",
            "    Uninstalling gymnasium-1.1.0:\n",
            "      Successfully uninstalled gymnasium-1.1.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZujlZYbrlloa",
        "outputId": "7f88c2dc-d589-4758-c323-f07b8db9e18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch_geometric networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3NlPxp3lob4",
        "outputId": "0a419ca0-095d-4580-cd53-d33c3e97ffe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lerg0i9rlp6x",
        "outputId": "5f91f483-bdb8-4931-eba6-4777a98378b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.2+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_cluster -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKh6rikAlr18",
        "outputId": "c865c8d2-6b26-4110-e70a-21bd40c468e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_cluster) (1.26.4)\n",
            "Installing collected packages: torch_cluster\n",
            "Successfully installed torch_cluster-1.6.3+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2dNjfjkltHo",
        "outputId": "5a686ba4-55b5-4866-bc8c-d191a7daf501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_spline_conv\n",
            "Successfully installed torch_spline_conv-1.2.2+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a7U1wMNlx2w",
        "outputId": "7976d0ec-f362-46b8-818b-f1fa1026895a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/920.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CTlRnIMlzUX",
        "outputId": "054b4642-f718-465c-c8c0-76284eb94d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43QRsHCwtlWi",
        "outputId": "d776c400-6de5-42ac-f52e-e0a98da1b2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.1.6)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/756.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, pyvis\n",
            "Successfully installed jedi-0.19.2 pyvis-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING AND VISUALIZING THE WORKFLOW"
      ],
      "metadata": {
        "id": "Dro_P-C6m5xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "def load_dag(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        dag_data = json.load(f)\n",
        "\n",
        "    cybershake_dag = nx.DiGraph()\n",
        "    for node, attributes in dag_data[\"nodes\"].items():\n",
        "        cybershake_dag.add_node(node, **attributes)\n",
        "    for parent, child, attributes in dag_data[\"edges\"]:\n",
        "        cybershake_dag.add_edge(parent, child, **attributes)\n",
        "    return cybershake_dag"
      ],
      "metadata": {
        "id": "W8Xj0JQLl0vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow_dag = load_dag(\"cybershake_dag.json\")"
      ],
      "metadata": {
        "id": "BBPlvHESm3AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_attributes = {node: workflow_dag.nodes[node] for node in workflow_dag.nodes()}\n",
        "print(\"Sample Node Attributes:\", list(node_attributes.items())[:5])  # Show first 5 nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqEx4hpEnlLT",
        "outputId": "bfae7573-e072-4708-ea09-46fe6c2710db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Node Attributes: [('ID00000', {'runtime': 3.81, 'execution_time': 4.0, 'cpu_usage': 1.26, 'memory_usage': 0.02247536844384094, 'disk_usage': 0.5, 'power_usage': 11.82, 'machine_type': 'cloud', 'network_latency': 4.40791560297728, 'migration_energy': 0.1576858346700459, 'data_size': 10, 'CCR': 0.005}), ('ID00001', {'runtime': 9.38, 'execution_time': 8.0, 'cpu_usage': 0.21, 'memory_usage': 0.0222659384464059, 'disk_usage': 0.5, 'power_usage': 4.47, 'machine_type': 'edge', 'network_latency': 30.57163749729113, 'migration_energy': 5.114316294420685, 'edge_queue_delay': 7.1, 'data_size': 10, 'CCR': 0.025}), ('ID00002', {'runtime': 99.15, 'execution_time': 100.50746268656717, 'cpu_usage': 0.16388059701492538, 'memory_usage': 0.02784441883456679, 'disk_usage': 0.5, 'power_usage': 4.147164179104478, 'machine_type': 'cloud', 'network_latency': 1.0169148405181474, 'migration_energy': 0.1621171199688822, 'data_size': 10, 'CCR': 0.00019899019899019898}), ('ID00003', {'runtime': 44.1, 'execution_time': 43.03001579778831, 'cpu_usage': 0.9952448657187993, 'memory_usage': 0.022653679285500296, 'disk_usage': 0.5, 'power_usage': 9.966714060031595, 'machine_type': 'cloud', 'network_latency': 3.2751709233900623, 'migration_energy': 0.19965715387778116, 'data_size': 10, 'CCR': 0.0004647918349364858}), ('ID00004', {'runtime': 1.47, 'execution_time': 1.3498495486459379, 'cpu_usage': 0.900370110330993, 'memory_usage': 0.022653679285500296, 'disk_usage': 0.5, 'power_usage': 9.30259077231695, 'machine_type': 'cloud', 'network_latency': 2.345371690597236, 'migration_energy': 0.2250751986368443, 'data_size': 10, 'CCR': 0.0148164660425026})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attributes = {edge: workflow_dag.edges[edge] for edge in workflow_dag.edges()}\n",
        "print(\"Sample Edge Attributes:\", list(edge_attributes.items())[:5])  # Show first 5 nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMMb_vSysiiJ",
        "outputId": "d4e79243-5543-4c80-8549-ae7a96b26eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Edge Attributes: [(('ID00002', 'ID00003'), {'CCR': 0.0004647918349364858, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00005'), {'CCR': 0.0007324573665082472, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00007'), {'CCR': 0.0005729166666666667, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00009'), {'CCR': 0.0006451612903225806, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5}), (('ID00002', 'ID00011'), {'CCR': 0.00036378783671202445, 'T_comm': 0.02, 'E_network': 0.002, 'bandwidth': 500, 'network_latency': 5})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list = list(workflow_dag.edges())\n",
        "print(\"Sample Edges (Task Dependencies):\", edge_list[:5])  # Show first 5 edges\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfAjlhY4sUvq",
        "outputId": "18bd8f91-f2eb-492f-d04f-c80c79a50cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Edges (Task Dependencies): [('ID00002', 'ID00003'), ('ID00002', 'ID00005'), ('ID00002', 'ID00007'), ('ID00002', 'ID00009'), ('ID00002', 'ID00011')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_workflow_dag(G):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    pos = nx.spring_layout(G)  # Positions for all nodes\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
        "    nx.draw(G, pos, node_color=\"lightblue\", edge_color=\"gray\", node_size=200)\n",
        "    plt.title(\"Workflow DAG (Task Dependencies)\")\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_workflow_dag(workflow_dag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "-elyHxmesfwX",
        "outputId": "3e3ca170-f801-43b7-ec6b-64e7e428a082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "def plot_large_dag(G):\n",
        "    net = Network(notebook=True, height=\"750px\", width=\"100%\")\n",
        "    net.from_nx(G)\n",
        "    net.show(\"dag.html\")  # Opens in a browser\n",
        "\n",
        "plot_large_dag(workflow_dag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBW0p5XBsye5",
        "outputId": "323ab15d-e887-4731-b942-980a61d692f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "dag.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing, GATConv, global_mean_pool\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "import os\n",
        "\n",
        "\n",
        "# ---------------------- LOAD DAG & EXTRACT FEATURES ---------------------- #\n",
        "def load_dag(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        dag_data = json.load(f)\n",
        "\n",
        "    cybershake_dag = nx.DiGraph()\n",
        "    for node, attributes in dag_data[\"nodes\"].items():\n",
        "        cybershake_dag.add_node(node, **attributes)\n",
        "    for parent, child, attributes in dag_data[\"edges\"]:\n",
        "        cybershake_dag.add_edge(parent, child, **attributes)\n",
        "    return cybershake_dag\n",
        "\n",
        "\n",
        "def compute_feature_stats(workflow_dag):\n",
        "    execution_times, input_sizes, output_sizes, sla_deadlines, critical_paths = [], [], [], [], []\n",
        "\n",
        "    for node in workflow_dag.nodes():\n",
        "        node_data = workflow_dag.nodes[node]\n",
        "        execution_times.append(node_data.get(\"runtime\", 1.0))\n",
        "        input_sizes.append(sum(f.get(\"size\", 0) for f in node_data.get(\"input_files\", []) if f is not None))\n",
        "        output_sizes.append(sum(f.get(\"size\", 0) for f in node_data.get(\"output_files\", []) if f is not None))\n",
        "        sla_deadlines.append(node_data.get(\"sla_deadline\", execution_times[-1] * 1.5))\n",
        "        try:\n",
        "            critical_paths.append(\n",
        "                max(len(path) for path in nx.all_simple_paths(workflow_dag, list(workflow_dag.nodes())[0], node))\n",
        "                if nx.has_path(workflow_dag, list(workflow_dag.nodes())[0], node) else 0)\n",
        "        except nx.NetworkXNoPath:\n",
        "            critical_paths.append(0)\n",
        "\n",
        "    stats = lambda x: {\"min\": np.min(x), \"max\": np.max(x), \"mean\": np.mean(x), \"std\": np.std(x)}\n",
        "    return {\n",
        "        \"execution_time\": stats(execution_times),\n",
        "        \"input_size\": stats(input_sizes),\n",
        "        \"output_size\": stats(output_sizes),\n",
        "        \"sla_deadline\": stats(sla_deadlines),\n",
        "        \"critical_path\": stats(critical_paths)\n",
        "    }\n",
        "\n",
        "\n",
        "def normalize(value, stats, method=\"minmax\"):\n",
        "    if method == \"minmax\":\n",
        "        return (value - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"]) if stats[\"max\"] > stats[\"min\"] else 0\n",
        "    elif method == \"zscore\":\n",
        "        return (value - stats[\"mean\"]) / stats[\"std\"] if stats[\"std\"] > 0 else 0\n",
        "    else:\n",
        "        raise ValueError(\"Invalid normalization method.\")\n",
        "\n",
        "\n",
        "def prepare_workflow_dag(workflow_dag):\n",
        "    feature_stats = compute_feature_stats(workflow_dag)\n",
        "    node_id_to_idx = {node_id: idx for idx, node_id in enumerate(workflow_dag.nodes())}\n",
        "    edges = [(node_id_to_idx[u], node_id_to_idx[v]) for u, v in workflow_dag.edges()]\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Adjacency matrix for DAG\n",
        "    num_nodes = workflow_dag.number_of_nodes()\n",
        "    adjacency_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float)\n",
        "    for u, v in edges:\n",
        "        adjacency_matrix[u, v] = 1\n",
        "\n",
        "    # Topological order for positional encoding\n",
        "    topo_order = list(nx.topological_sort(workflow_dag))\n",
        "    node_features_list, edge_attr, execution_times, sla_adherences, task_priorities = [], [], [], [], []  # Corrected var name\n",
        "\n",
        "    # Compute shortest path to each node\n",
        "    shortest_path_lengths = {}\n",
        "    for node in workflow_dag.nodes():\n",
        "        try:\n",
        "            shortest_path_lengths[node] = nx.shortest_path_length(workflow_dag, source=topo_order[0], target=node)\n",
        "        except nx.NetworkXNoPath:\n",
        "            shortest_path_lengths[node] = 0\n",
        "\n",
        "    # Compute degree centrality\n",
        "    degree_centrality = nx.degree_centrality(workflow_dag)\n",
        "\n",
        "    for node in workflow_dag.nodes():\n",
        "        node_data = workflow_dag.nodes[node]\n",
        "        execution_time = node_data.get(\"runtime\", 1.0)\n",
        "        input_size = sum(f.get(\"size\", 0) for f in node_data.get(\"input_files\", []) if f is not None)\n",
        "        output_size = sum(f.get(\"size\", 0) for f in node_data.get(\"output_files\", []) if f is not None)\n",
        "        in_degree = workflow_dag.in_degree(node)\n",
        "        out_degree = workflow_dag.out_degree(node)\n",
        "        sla_deadline = node_data.get(\"sla_deadline\", execution_time * 1.5)\n",
        "        try:\n",
        "            critical_path = max(len(path) for path in\n",
        "                                nx.all_simple_paths(workflow_dag, topo_order[0], node)) if topo_order and nx.has_path(\n",
        "                workflow_dag, topo_order[0], node) else 0\n",
        "        except nx.NetworkXNoPath:\n",
        "            critical_path = 0\n",
        "\n",
        "        topo_rank = topo_order.index(node) / len(topo_order)\n",
        "\n",
        "        # Positional Encodings\n",
        "        shortest_path = shortest_path_lengths[node] / max(1, num_nodes)\n",
        "        node_degree = degree_centrality[node]\n",
        "\n",
        "        node_features = [  # Corrected local variable\n",
        "            normalize(execution_time, feature_stats[\"execution_time\"], \"zscore\"),\n",
        "            normalize(input_size, feature_stats[\"input_size\"], \"minmax\"),\n",
        "            normalize(output_size, feature_stats[\"output_size\"], \"minmax\"),\n",
        "            in_degree / max(1, workflow_dag.number_of_nodes()),\n",
        "            out_degree / max(1, workflow_dag.number_of_nodes()),\n",
        "            normalize(sla_deadline, feature_stats[\"sla_deadline\"], \"minmax\"),\n",
        "            normalize(critical_path, feature_stats[\"critical_path\"], \"minmax\"),\n",
        "            topo_rank,\n",
        "            shortest_path,  # Shortest Path\n",
        "            node_degree  # Degree\n",
        "        ]\n",
        "\n",
        "        node_features_list.append(node_features) # Corrected append\n",
        "\n",
        "        sla_adherence = 1 if execution_time <= sla_deadline else 0\n",
        "\n",
        "        task_priority = 1 / (execution_time + critical_path + 1e-6)\n",
        "        execution_times.append(normalize(execution_time, feature_stats[\"execution_time\"], \"zscore\"))\n",
        "        sla_adherences.append(sla_adherence)\n",
        "        task_priorities.append(task_priority)\n",
        "\n",
        "    sla_adherences = torch.tensor(sla_adherences, dtype=torch.float)\n",
        "    sla_adherences = torch.clamp(sla_adherences, min=1e-6, max=1.0)  # Ensure valid BCELoss input\n",
        "\n",
        "\n",
        "    for u, v in workflow_dag.edges():\n",
        "        u_idx, v_idx = node_id_to_idx[u], node_id_to_idx[v]\n",
        "        u_features, v_features = node_features_list[u_idx], node_features_list[v_idx]  # accessing features using new list\n",
        "        edge_attr.append([\n",
        "            abs(u_features[0] - v_features[0]),  # Execution time diff\n",
        "            abs(u_features[1] - v_features[1]),  # Input size diff\n",
        "            abs(u_features[2] - v_features[2]),  # Output size diff\n",
        "            abs(u_features[5] - v_features[5])  # SLA diff\n",
        "        ])\n",
        "\n",
        "    node_features_tensor = torch.tensor(node_features_list, dtype=torch.float) # Creating node features tensor\n",
        "    return (\n",
        "        node_features_tensor,\n",
        "        edge_index,\n",
        "        torch.tensor(edge_attr, dtype=torch.float),\n",
        "        adjacency_matrix,\n",
        "        torch.tensor(execution_times, dtype=torch.float).unsqueeze(1),\n",
        "        torch.tensor(sla_adherences, dtype=torch.float).unsqueeze(1),\n",
        "        torch.tensor(task_priorities, dtype=torch.float).unsqueeze(1),\n",
        "        node_features_list  # Passing the node feature list too for initial printing\n",
        "    )"
      ],
      "metadata": {
        "id": "RkXKeeZDtpJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STATE REPRESENTATION MODULE"
      ],
      "metadata": {
        "id": "aBQ4c0L4LFA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trial cell\n",
        "# ---------------------- MODEL DEFINITION ---------------------- #\n",
        "class CustomGraphTransformerLayer(MessagePassing):\n",
        "    def __init__(self, in_features, out_features, heads=4, dropout=0.1, edge_dim=4):\n",
        "        super().__init__(aggr='add', node_dim=0)\n",
        "        self.heads = heads\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = out_features // heads\n",
        "\n",
        "        self.W_Q = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_K = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_V = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(edge_dim, heads * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(heads * 8, heads)\n",
        "        )\n",
        "        self.out_proj = nn.Linear(out_features, out_features)\n",
        "        self.gate = nn.Linear(out_features, out_features)\n",
        "        self.attn_weights = None\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        print(f\"GraphTransformerLayer input x shape: {x.shape}\")\n",
        "        Q = self.W_Q(x).view(-1, self.heads, self.head_dim)\n",
        "        print(f\"Q shape: {Q.shape}\")\n",
        "        K = self.W_K(x).view(-1, self.heads, self.head_dim)\n",
        "        V = self.W_V(x).view(-1, self.heads, self.head_dim)\n",
        "\n",
        "        alpha = self.compute_attention(Q, K, edge_index, edge_attr)\n",
        "        out = self.propagate(edge_index, x=V, alpha=alpha)\n",
        "        out = out.view(-1, self.heads * self.head_dim)\n",
        "        gate = torch.sigmoid(self.gate(out))\n",
        "        return self.out_proj(out * gate)\n",
        "\n",
        "    def compute_attention(self, Q, K, edge_index, edge_attr):\n",
        "        q_i, k_j = Q[edge_index[0]], K[edge_index[1]]\n",
        "        edge_weight = self.edge_mlp(edge_attr)\n",
        "        attn_scores = (q_i * k_j).sum(dim=-1) + edge_weight  # Compute raw attention scores\n",
        "        attn_scores = F.leaky_relu(attn_scores)\n",
        "        alpha = torch.softmax(attn_scores, dim=0)  # Apply softmax\n",
        "\n",
        "        self.attn_weights = alpha  # Store attention weights for visualization\n",
        "        return alpha\n",
        "\n",
        "    def message(self, x_j, alpha):\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "\n",
        "class TaskEmbeddingModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, heads=4, embedding_dim=32, lstm_hidden=32, lstm_layers=2,\n",
        "                 edge_dim=4, num_gnn_layers=2, num_transformer_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_transformer_layers = num_transformer_layers\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "\n",
        "        # ✅ Ensure Transformer layers output the same size as GNN input\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            CustomGraphTransformerLayer(input_dim if i == 0 else hidden_dim, hidden_dim, heads=heads,\n",
        "                                        edge_dim=edge_dim)\n",
        "            for i in range(num_transformer_layers)])\n",
        "\n",
        "        # ✅ Ensure GNN input matches the Transformer output\n",
        "        self.feature_projection = nn.Linear(hidden_dim, embedding_dim)  # Transform features\n",
        "\n",
        "        self.gnn_layers = nn.ModuleList([\n",
        "            GATConv(embedding_dim if i == 0 else embedding_dim, embedding_dim, heads=1)\n",
        "            for i in range(num_gnn_layers)])\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden, lstm_layers, batch_first=True)\n",
        "        self.fc_time = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_sla = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_priority = nn.Linear(lstm_hidden, 1)\n",
        "\n",
        "        # Learnable task weights for dynamic loss\n",
        "        self.log_sigma_time = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_sla = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_priority = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        # ✅ Fix Transformer-GNN Shape Mismatch\n",
        "        for i in range(max(self.num_transformer_layers, self.num_gnn_layers)):\n",
        "            if i < self.num_transformer_layers:\n",
        "                x = F.relu(self.transformer_layers[i](x, edge_index, edge_attr))\n",
        "\n",
        "        x = self.feature_projection(x)  # ✅ Ensures correct size before GNN\n",
        "\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x = F.relu(self.gnn_layers[i](x, edge_index))\n",
        "\n",
        "        # Graph-level read-out using global mean pooling\n",
        "        graph_embedding = global_mean_pool(x, batch)\n",
        "\n",
        "        lstm_input = x.unsqueeze(0)\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_out = lstm_out.squeeze(0)\n",
        "\n",
        "        exec_time_pred = self.fc_time(lstm_out)\n",
        "        sla_pred = torch.sigmoid(self.fc_sla(lstm_out))\n",
        "        priority_pred = torch.sigmoid(self.fc_priority(lstm_out))\n",
        "        return torch.cat([x, exec_time_pred, sla_pred, priority_pred], dim=1), graph_embedding\n"
      ],
      "metadata": {
        "id": "edAVCk1qvvQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- TRAINING ---------------------- #\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def train_embeddings(node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities, node_features_list,\n",
        "                     epochs=500, save_path=\"./model_data\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Ensure save directory exists\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # ✅ Normalize execution times BEFORE passing to the model\n",
        "    scaler = MinMaxScaler()\n",
        "    execution_times = torch.tensor(scaler.fit_transform(execution_times.cpu().numpy()), dtype=torch.float).to(device)\n",
        "\n",
        "    model = TaskEmbeddingModel(node_features.size(1), num_gnn_layers=1, num_transformer_layers=1).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scaler = GradScaler() if device.type == \"cuda\" else None\n",
        "\n",
        "    data = [node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities]\n",
        "    data = [x.to(device) for x in data]\n",
        "    node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities = data\n",
        "\n",
        "    criterion_time = nn.L1Loss()\n",
        "    criterion_sla = nn.BCELoss()\n",
        "    criterion_priority = nn.L1Loss()\n",
        "\n",
        "    # ✅ Print SLA labels to check if they are all 0s\n",
        "    print(\"Unique SLA Adherence Values:\", torch.unique(sla_adherences))\n",
        "\n",
        "    # ✅ Scale SLA loss for better training\n",
        "    sla_adherences = torch.clamp(sla_adherences, min=1e-6, max=1.0)  # Ensure valid BCELoss input\n",
        "\n",
        "    # Create a batch vector for graph-level pooling (assuming single graph)\n",
        "    batch = torch.zeros(node_features.size(0), dtype=torch.long).to(device)\n",
        "\n",
        "    # ✅ Add loss tracking dictionary\n",
        "    loss_history = {\n",
        "        \"total_loss\": [],\n",
        "        \"loss_time\": [],\n",
        "        \"loss_sla\": [],\n",
        "        \"loss_priority\": [],\n",
        "        \"sigma_time\": [],\n",
        "        \"sigma_sla\": [],\n",
        "        \"sigma_priority\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=device.type == \"cuda\"):\n",
        "            embeddings, graph_embedding = model(node_features, edge_index, edge_attr, batch)  # Get graph embedding too\n",
        "            exec_time_pred = embeddings[:, -3].unsqueeze(1)\n",
        "            sla_pred = embeddings[:, -2].unsqueeze(1)\n",
        "            priority_pred = embeddings[:, -1].unsqueeze(1)\n",
        "\n",
        "            loss_time = criterion_time(exec_time_pred, execution_times)\n",
        "            loss_sla = criterion_sla(sla_pred, sla_adherences)\n",
        "            loss_priority = criterion_priority(priority_pred, task_priorities)\n",
        "\n",
        "            # ✅ Scale SLA Loss to prevent it from vanishing\n",
        "            loss_sla_scaled = loss_sla * 10  # Increase SLA loss impact\n",
        "\n",
        "            # Normalize loss values before dynamic weighting\n",
        "            loss_time_norm = loss_time / loss_time.detach().max()\n",
        "            loss_sla_norm = loss_sla_scaled / loss_sla_scaled.detach().max()\n",
        "            loss_priority_norm = loss_priority / loss_priority.detach().max()\n",
        "\n",
        "            # ✅ Prevent dynamic loss scaling from becoming too small\n",
        "            sigma_time = torch.exp(-model.log_sigma_time).clamp(min=0.1)\n",
        "            sigma_sla = torch.exp(-model.log_sigma_sla).clamp(min=0.1)\n",
        "            sigma_priority = torch.exp(-model.log_sigma_priority).clamp(min=0.1)\n",
        "\n",
        "            loss_time_weighted = 0.5 * sigma_time * loss_time_norm + 0.5 * model.log_sigma_time\n",
        "            loss_sla_weighted = 0.3 * sigma_sla * loss_sla_norm + 0.3 * model.log_sigma_sla\n",
        "            loss_priority_weighted = 0.2 * sigma_priority * loss_priority_norm + 0.2 * model.log_sigma_priority\n",
        "\n",
        "            loss = loss_time_weighted + loss_sla_weighted + loss_priority_weighted\n",
        "\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # ✅ Track loss values\n",
        "        loss_history[\"total_loss\"].append(loss.item())\n",
        "        loss_history[\"loss_time\"].append(loss_time.item())\n",
        "        loss_history[\"loss_sla\"].append(loss_sla.item())\n",
        "        loss_history[\"loss_priority\"].append(loss_priority.item())\n",
        "        loss_history[\"sigma_time\"].append(sigma_time.item())\n",
        "        loss_history[\"sigma_sla\"].append(sigma_sla.item())\n",
        "        loss_history[\"sigma_priority\"].append(sigma_priority.item())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch}, Loss: {loss.item():.4f}, Time Loss: {loss_time.item():.4f}, SLA Loss: {loss_sla.item():.4f}, Priority Loss: {loss_priority.item():.4f}\")\n",
        "\n",
        "    # ✅ Save loss history\n",
        "    np.save(os.path.join(save_path, \"loss_history.npy\"), loss_history)\n",
        "    print(f\"Loss history saved to {save_path}/loss_history.npy\")\n",
        "\n",
        "    # Save model, embeddings, and graph embedding after training\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, \"model.pth\"))\n",
        "\n",
        "    # Detach and move to CPU before saving as numpy arrays\n",
        "    node_embeddings_cpu = embeddings[:, :-3].detach().cpu().numpy()\n",
        "    graph_embedding_cpu = graph_embedding.detach().cpu().numpy()\n",
        "\n",
        "    np.save(os.path.join(save_path, \"task_embeddings.npy\"), node_embeddings_cpu)\n",
        "    np.save(os.path.join(save_path, \"graph_embedding.npy\"), graph_embedding_cpu)\n",
        "\n",
        "    print(f\"Model, task embeddings, and graph embedding saved to {save_path}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6vId4BNG07Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Load and prepare data\n",
        "workflow_dag = load_dag(\"cybershake_dag.json\")\n",
        "(node_features, edge_index, edge_attr, adjacency_matrix, execution_times, sla_adherences,\n",
        " task_priorities, node_features_list) = prepare_workflow_dag(workflow_dag)\n",
        "\n",
        "# Print initial node features\n",
        "print(\"Initial Node Features:\")\n",
        "for i, features in enumerate(node_features_list):\n",
        "    print(f\"Node {i}: {features}\")\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Train model\n",
        "embedding_model_save_path = \"./embedding_model_data\"\n",
        "model = train_embeddings(node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "                         task_priorities, node_features_list, save_path=embedding_model_save_path)\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), os.path.join(embedding_model_save_path, \"trained_model.pth\"))\n",
        "\n",
        "# Save node features, edge index, and edge attributes for later visualization\n",
        "np.save(os.path.join(embedding_model_save_path, \"node_features.npy\"), node_features.cpu().numpy())\n",
        "np.save(os.path.join(embedding_model_save_path, \"edge_index.npy\"), edge_index.cpu().numpy())\n",
        "np.save(os.path.join(embedding_model_save_path, \"edge_attr.npy\"), edge_attr.cpu().numpy())\n",
        "\n",
        "print(f\"Model training complete. Saved at {embedding_model_save_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmUj6md0970",
        "outputId": "8a2e361d-ab19-4b75-a9e3-cfec624e935b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-31e26a87a9f0>:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(sla_adherences, dtype=torch.float).unsqueeze(1),\n",
            "<ipython-input-62-6ef5fed1a07e>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Node Features:\n",
            "Node 0: [-0.7908287615665436, 0, 0, 0.497, 0.0, 0.018099045081057072, 4.0, 0.999, 0.003, 0.4974974974974975]\n",
            "Node 1: [-0.5582804480397533, 0, 0, 0.497, 0.0, 0.0490228736397957, 3.0, 0.997, 0.002, 0.4974974974974975]\n",
            "Node 2: [3.1896301633246904, 0, 0, 0.0, 0.109, 0.5474128358871865, 1.0, 0.0, 0.0, 0.1091091091091091]\n",
            "Node 3: [0.8912846229925903, 0, 0, 0.001, 0.002, 0.24178325560737288, 2.0, 0.004, 0.001, 0.003003003003003003]\n",
            "Node 4: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.501, 0.002, 0.002002002002002002]\n",
            "Node 5: [0.14353950714612498, 0, 0, 0.001, 0.002, 0.1423495447479458, 2.0, 0.005, 0.001, 0.003003003003003003]\n",
            "Node 6: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.502, 0.002, 0.002002002002002002]\n",
            "Node 7: [0.4846382004161205, 0, 0, 0.001, 0.002, 0.18770819453697532, 2.0, 0.006, 0.001, 0.003003003003003003]\n",
            "Node 8: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 3.0, 0.503, 0.002, 0.002002002002002002]\n",
            "Node 9: [0.35354274180317236, 0, 0, 0.001, 0.002, 0.17027537197423936, 2.0, 0.007, 0.001, 0.003003003003003003]\n",
            "Node 10: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.504, 0.002, 0.002002002002002002]\n",
            "Node 11: [1.3893638654296827, 0, 0, 0.001, 0.002, 0.3080168776371308, 2.0, 0.008, 0.001, 0.003003003003003003]\n",
            "Node 12: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 3.0, 0.505, 0.002, 0.002002002002002002]\n",
            "Node 13: [0.15063703197548833, 0, 0, 0.001, 0.002, 0.14329335998223405, 2.0, 0.009, 0.001, 0.003003003003003003]\n",
            "Node 14: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.506, 0.002, 0.002002002002002002]\n",
            "Node 15: [1.0954428372019267, 0, 0, 0.001, 0.002, 0.2689318232289585, 2.0, 0.01, 0.001, 0.003003003003003003]\n",
            "Node 16: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.507, 0.002, 0.002002002002002002]\n",
            "Node 17: [1.1388629890992088, 0, 0, 0.001, 0.002, 0.2747057517210748, 2.0, 0.011, 0.001, 0.003003003003003003]\n",
            "Node 18: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.508, 0.002, 0.002002002002002002]\n",
            "Node 19: [0.049601678522197185, 0, 0, 0.001, 0.002, 0.12985787252942482, 2.0, 0.012, 0.001, 0.003003003003003003]\n",
            "Node 20: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.509, 0.002, 0.002002002002002002]\n",
            "Node 21: [1.7534251390299718, 0, 0, 0.001, 0.002, 0.3564290473017988, 2.0, 0.013, 0.001, 0.003003003003003003]\n",
            "Node 22: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 3.0, 0.51, 0.002, 0.002002002002002002]\n",
            "Node 23: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.014, 0.001, 0.003003003003003003]\n",
            "Node 24: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 3.0, 0.511, 0.002, 0.002002002002002002]\n",
            "Node 25: [1.3960438887984952, 0, 0, 0.001, 0.002, 0.3089051743282256, 2.0, 0.015, 0.001, 0.003003003003003003]\n",
            "Node 26: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 3.0, 0.512, 0.002, 0.002002002002002002]\n",
            "Node 27: [0.3218126308013124, 0, 0, 0.001, 0.002, 0.16605596269153894, 2.0, 0.016, 0.001, 0.003003003003003003]\n",
            "Node 28: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.513, 0.002, 0.002002002002002002]\n",
            "Node 29: [0.04459166099558766, 0, 0, 0.001, 0.002, 0.12919165001110372, 2.0, 0.017, 0.001, 0.003003003003003003]\n",
            "Node 30: [-0.9114866836657218, 0, 0, 0.001, 0.001, 0.0020541860981567843, 3.0, 0.514, 0.002, 0.002002002002002002]\n",
            "Node 31: [1.4048114194700623, 0, 0, 0.001, 0.002, 0.31007106373528753, 2.0, 0.018, 0.001, 0.003003003003003003]\n",
            "Node 32: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.515, 0.002, 0.002002002002002002]\n",
            "Node 33: [0.1147319063681204, 0, 0, 0.001, 0.002, 0.13851876526759938, 2.0, 0.019, 0.001, 0.003003003003003003]\n",
            "Node 34: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.516, 0.002, 0.002002002002002002]\n",
            "Node 35: [0.8019393104347211, 0, 0, 0.001, 0.002, 0.22990228736397955, 2.0, 0.02, 0.001, 0.003003003003003003]\n",
            "Node 36: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.517, 0.002, 0.002002002002002002]\n",
            "Node 37: [1.2231982841304683, 0, 0, 0.001, 0.002, 0.28592049744614695, 2.0, 0.021, 0.001, 0.003003003003003003]\n",
            "Node 38: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.518, 0.002, 0.002002002002002002]\n",
            "Node 39: [1.3689062938626941, 0, 0, 0.001, 0.002, 0.3052964690206529, 2.0, 0.022, 0.001, 0.003003003003003003]\n",
            "Node 40: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.519, 0.002, 0.002002002002002002]\n",
            "Node 41: [0.400302905384861, 0, 0, 0.001, 0.002, 0.17649344881190318, 2.0, 0.023, 0.001, 0.003003003003003003]\n",
            "Node 42: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.52, 0.002, 0.002002002002002002]\n",
            "Node 43: [0.08383679828736199, 0, 0, 0.001, 0.002, 0.1344103930712858, 2.0, 0.024, 0.001, 0.003003003003003003]\n",
            "Node 44: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.521, 0.002, 0.002002002002002002]\n",
            "Node 45: [0.125586944342441, 0, 0, 0.001, 0.002, 0.13996224739062846, 2.0, 0.025, 0.001, 0.003003003003003003]\n",
            "Node 46: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 3.0, 0.522, 0.002, 0.002002002002002002]\n",
            "Node 47: [0.9772899238660527, 0, 0, 0.001, 0.002, 0.2532200755052187, 2.0, 0.026, 0.001, 0.003003003003003003]\n",
            "Node 48: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.523, 0.002, 0.002002002002002002]\n",
            "Node 49: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 2.0, 0.027, 0.001, 0.003003003003003003]\n",
            "Node 50: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.524, 0.002, 0.002002002002002002]\n",
            "Node 51: [0.5209608274840392, 0, 0, 0.001, 0.002, 0.19253830779480344, 2.0, 0.028, 0.001, 0.003003003003003003]\n",
            "Node 52: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 3.0, 0.525, 0.002, 0.002002002002002002]\n",
            "Node 53: [1.0136125509339717, 0, 0, 0.001, 0.002, 0.25805018876304686, 2.0, 0.029, 0.001, 0.003003003003003003]\n",
            "Node 54: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.526, 0.002, 0.002002002002002002]\n",
            "Node 55: [0.155229548041547, 0, 0, 0.001, 0.002, 0.14390406395736174, 2.0, 0.03, 0.001, 0.003003003003003003]\n",
            "Node 56: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.527, 0.002, 0.002002002002002002]\n",
            "Node 57: [0.8908671215320395, 0, 0, 0.001, 0.002, 0.24172773706417944, 2.0, 0.031, 0.001, 0.003003003003003003]\n",
            "Node 58: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.528, 0.002, 0.002002002002002002]\n",
            "Node 59: [0.6219961809373304, 0, 0, 0.001, 0.002, 0.20597379524761267, 2.0, 0.032, 0.001, 0.003003003003003003]\n",
            "Node 60: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 3.0, 0.529, 0.002, 0.002002002002002002]\n",
            "Node 61: [1.7550951448721752, 0, 0, 0.001, 0.002, 0.3566511214745725, 2.0, 0.033, 0.001, 0.003003003003003003]\n",
            "Node 62: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.53, 0.002, 0.002002002002002002]\n",
            "Node 63: [0.6499687787942334, 0, 0, 0.001, 0.002, 0.20969353764157228, 2.0, 0.034, 0.001, 0.003003003003003003]\n",
            "Node 64: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 3.0, 0.531, 0.002, 0.002002002002002002]\n",
            "Node 65: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.035, 0.001, 0.003003003003003003]\n",
            "Node 66: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.532, 0.002, 0.002002002002002002]\n",
            "Node 67: [1.1150654058478138, 0, 0, 0.001, 0.002, 0.2715411947590495, 2.0, 0.036, 0.001, 0.003003003003003003]\n",
            "Node 68: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.533, 0.002, 0.002002002002002002]\n",
            "Node 69: [1.2227807826699175, 0, 0, 0.001, 0.002, 0.2858649789029536, 2.0, 0.037, 0.001, 0.003003003003003003]\n",
            "Node 70: [-0.8981266369280967, 0, 0, 0.001, 0.001, 0.0038307794803464344, 3.0, 0.534, 0.002, 0.002002002002002002]\n",
            "Node 71: [1.4110739413783238, 0, 0, 0.001, 0.002, 0.3109038418831889, 2.0, 0.038, 0.001, 0.003003003003003003]\n",
            "Node 72: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.535, 0.002, 0.002002002002002002]\n",
            "Node 73: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 2.0, 0.039, 0.001, 0.003003003003003003]\n",
            "Node 74: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.536, 0.002, 0.002002002002002002]\n",
            "Node 75: [0.3255701439462695, 0, 0, 0.001, 0.002, 0.1665556295802798, 2.0, 0.04, 0.001, 0.003003003003003003]\n",
            "Node 76: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.537, 0.002, 0.002002002002002002]\n",
            "Node 77: [1.4778741750664504, 0, 0, 0.001, 0.002, 0.3197868087941372, 2.0, 0.041, 0.001, 0.003003003003003003]\n",
            "Node 78: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.538, 0.002, 0.002002002002002002]\n",
            "Node 79: [1.4507365801306489, 0, 0, 0.001, 0.002, 0.3161781034865645, 2.0, 0.042, 0.001, 0.003003003003003003]\n",
            "Node 80: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.539, 0.002, 0.002002002002002002]\n",
            "Node 81: [0.342270202368301, 0, 0, 0.001, 0.002, 0.16877637130801684, 2.0, 0.043, 0.001, 0.003003003003003003]\n",
            "Node 82: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.54, 0.002, 0.002002002002002002]\n",
            "Node 83: [1.2732984593965633, 0, 0, 0.001, 0.002, 0.2925827226293582, 2.0, 0.044, 0.001, 0.003003003003003003]\n",
            "Node 84: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.541, 0.002, 0.002002002002002002]\n",
            "Node 85: [0.27630497160127626, 0, 0, 0.001, 0.002, 0.16000444148345547, 2.0, 0.045, 0.001, 0.003003003003003003]\n",
            "Node 86: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.542, 0.002, 0.002002002002002002]\n",
            "Node 87: [0.9877274603798225, 0, 0, 0.001, 0.002, 0.25460803908505436, 2.0, 0.046, 0.001, 0.003003003003003003]\n",
            "Node 88: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.543, 0.002, 0.002002002002002002]\n",
            "Node 89: [1.1271729482037867, 0, 0, 0.001, 0.002, 0.2731512325116589, 2.0, 0.047, 0.001, 0.003003003003003003]\n",
            "Node 90: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 3.0, 0.544, 0.002, 0.002002002002002002]\n",
            "Node 91: [0.6140636531868655, 0, 0, 0.001, 0.002, 0.20491894292693758, 2.0, 0.048, 0.001, 0.003003003003003003]\n",
            "Node 92: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 3.0, 0.545, 0.002, 0.002002002002002002]\n",
            "Node 93: [0.03164911571851322, 0, 0, 0.001, 0.002, 0.12747057517210747, 2.0, 0.049, 0.001, 0.003003003003003003]\n",
            "Node 94: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 3.0, 0.546, 0.002, 0.002002002002002002]\n",
            "Node 95: [1.1547280446001387, 0, 0, 0.001, 0.002, 0.276815456362425, 2.0, 0.05, 0.001, 0.003003003003003003]\n",
            "Node 96: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 3.0, 0.547, 0.002, 0.002002002002002002]\n",
            "Node 97: [1.0754027670954884, 0, 0, 0.001, 0.002, 0.26626693315567396, 2.0, 0.051, 0.001, 0.003003003003003003]\n",
            "Node 98: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.548, 0.002, 0.002002002002002002]\n",
            "Node 99: [1.3167186112938454, 0, 0, 0.001, 0.002, 0.2983566511214746, 2.0, 0.052, 0.001, 0.003003003003003003]\n",
            "Node 100: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 3.0, 0.549, 0.002, 0.002002002002002002]\n",
            "Node 101: [1.3125435966883374, 0, 0, 0.001, 0.002, 0.2978014656895403, 2.0, 0.053, 0.001, 0.003003003003003003]\n",
            "Node 102: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 3.0, 0.55, 0.002, 0.002002002002002002]\n",
            "Node 103: [1.3405161945452402, 0, 0, 0.001, 0.002, 0.30152120808349986, 2.0, 0.054, 0.001, 0.003003003003003003]\n",
            "Node 104: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.551, 0.002, 0.002002002002002002]\n",
            "Node 105: [1.1605730650478496, 0, 0, 0.001, 0.002, 0.277592715967133, 2.0, 0.055, 0.001, 0.003003003003003003]\n",
            "Node 106: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.552, 0.002, 0.002002002002002002]\n",
            "Node 107: [0.2696249482324636, 0, 0, 0.001, 0.002, 0.15911614479236064, 2.0, 0.056, 0.001, 0.003003003003003003]\n",
            "Node 108: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.553, 0.002, 0.002002002002002002]\n",
            "Node 109: [0.6424537525043192, 0, 0, 0.001, 0.002, 0.2086942038640906, 2.0, 0.057, 0.001, 0.003003003003003003]\n",
            "Node 110: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.554, 0.002, 0.002002002002002002]\n",
            "Node 111: [1.7258700426336198, 0, 0, 0.001, 0.002, 0.35276482345103266, 2.0, 0.058, 0.001, 0.003003003003003003]\n",
            "Node 112: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 3.0, 0.555, 0.002, 0.002002002002002002]\n",
            "Node 113: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.059, 0.001, 0.003003003003003003]\n",
            "Node 114: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 3.0, 0.556, 0.002, 0.002002002002002002]\n",
            "Node 115: [1.7112574915143424, 0, 0, 0.001, 0.002, 0.3508216744392627, 2.0, 0.06, 0.001, 0.003003003003003003]\n",
            "Node 116: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.557, 0.002, 0.002002002002002002]\n",
            "Node 117: [0.4144979550435877, 0, 0, 0.001, 0.002, 0.17838107928047964, 2.0, 0.061, 0.001, 0.003003003003003003]\n",
            "Node 118: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.558, 0.002, 0.002002002002002002]\n",
            "Node 119: [1.3743338128498543, 0, 0, 0.001, 0.002, 0.3060182100821674, 2.0, 0.062, 0.001, 0.003003003003003003]\n",
            "Node 120: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 3.0, 0.559, 0.002, 0.002002002002002002]\n",
            "Node 121: [0.06630173694422874, 0, 0, 0.001, 0.002, 0.13207861425716186, 2.0, 0.063, 0.001, 0.003003003003003003]\n",
            "Node 122: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.56, 0.002, 0.002002002002002002]\n",
            "Node 123: [1.6966449403950643, 0, 0, 0.001, 0.002, 0.3488785254274928, 2.0, 0.064, 0.001, 0.003003003003003003]\n",
            "Node 124: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 3.0, 0.561, 0.002, 0.002002002002002002]\n",
            "Node 125: [1.3831013435214212, 0, 0, 0.001, 0.002, 0.3071840994892294, 2.0, 0.065, 0.001, 0.003003003003003003]\n",
            "Node 126: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 3.0, 0.562, 0.002, 0.002002002002002002]\n",
            "Node 127: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 2.0, 0.066, 0.001, 0.003003003003003003]\n",
            "Node 128: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 3.0, 0.563, 0.002, 0.002002002002002002]\n",
            "Node 129: [0.1869596590434071, 0, 0, 0.001, 0.002, 0.14812347324006217, 2.0, 0.067, 0.001, 0.003003003003003003]\n",
            "Node 130: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.564, 0.002, 0.002002002002002002]\n",
            "Node 131: [1.1133954000056105, 0, 0, 0.001, 0.002, 0.2713191205862758, 2.0, 0.068, 0.001, 0.003003003003003003]\n",
            "Node 132: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.565, 0.002, 0.002002002002002002]\n",
            "Node 133: [0.9468123172458452, 0, 0, 0.001, 0.002, 0.24916722185209858, 2.0, 0.069, 0.001, 0.003003003003003003]\n",
            "Node 134: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.566, 0.002, 0.002002002002002002]\n",
            "Node 135: [0.8507869813191636, 0, 0, 0.001, 0.002, 0.23639795691761048, 2.0, 0.07, 0.001, 0.003003003003003003]\n",
            "Node 136: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.567, 0.002, 0.002002002002002002]\n",
            "Node 137: [0.32306513518296465, 0, 0, 0.001, 0.002, 0.16622251832111923, 2.0, 0.071, 0.001, 0.003003003003003003]\n",
            "Node 138: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.568, 0.002, 0.002002002002002002]\n",
            "Node 139: [0.704243968665836, 0, 0, 0.001, 0.002, 0.2169109482567177, 2.0, 0.072, 0.001, 0.003003003003003003]\n",
            "Node 140: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 3.0, 0.569, 0.002, 0.002002002002002002]\n",
            "Node 141: [0.7660341848273532, 0, 0, 0.001, 0.002, 0.22512769264934487, 2.0, 0.073, 0.001, 0.003003003003003003]\n",
            "Node 142: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.57, 0.002, 0.002002002002002002]\n",
            "Node 143: [1.299601051411263, 0, 0, 0.001, 0.002, 0.2960803908505441, 2.0, 0.074, 0.001, 0.003003003003003003]\n",
            "Node 144: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.571, 0.002, 0.002002002002002002]\n",
            "Node 145: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 2.0, 0.075, 0.001, 0.003003003003003003]\n",
            "Node 146: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.572, 0.002, 0.002002002002002002]\n",
            "Node 147: [0.40907043605642734, 0, 0, 0.001, 0.002, 0.1776593382189651, 2.0, 0.076, 0.001, 0.003003003003003003]\n",
            "Node 148: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.573, 0.002, 0.002002002002002002]\n",
            "Node 149: [0.9910674720642291, 0, 0, 0.001, 0.002, 0.2550521874306018, 2.0, 0.077, 0.001, 0.003003003003003003]\n",
            "Node 150: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 3.0, 0.574, 0.002, 0.002002002002002002]\n",
            "Node 151: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 2.0, 0.078, 0.001, 0.003003003003003003]\n",
            "Node 152: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.575, 0.002, 0.002002002002002002]\n",
            "Node 153: [1.6640798264721026, 0, 0, 0.001, 0.002, 0.34454807905840545, 2.0, 0.079, 0.001, 0.003003003003003003]\n",
            "Node 154: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 3.0, 0.576, 0.002, 0.002002002002002002]\n",
            "Node 155: [1.2975135441085088, 0, 0, 0.001, 0.002, 0.29580279813457694, 2.0, 0.08, 0.001, 0.003003003003003003]\n",
            "Node 156: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.577, 0.002, 0.002002002002002002]\n",
            "Node 157: [0.9960774895908384, 0, 0, 0.001, 0.002, 0.2557184099489229, 2.0, 0.081, 0.001, 0.003003003003003003]\n",
            "Node 158: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.578, 0.002, 0.002002002002002002]\n",
            "Node 159: [0.14938452759383591, 0, 0, 0.001, 0.002, 0.14312680435265376, 2.0, 0.082, 0.001, 0.003003003003003003]\n",
            "Node 160: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.579, 0.002, 0.002002002002002002]\n",
            "Node 161: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.083, 0.001, 0.003003003003003003]\n",
            "Node 162: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.58, 0.002, 0.002002002002002002]\n",
            "Node 163: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 2.0, 0.084, 0.001, 0.003003003003003003]\n",
            "Node 164: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.581, 0.002, 0.002002002002002002]\n",
            "Node 165: [-0.012606039099870637, 0, 0, 0.001, 0.002, 0.12158560959360425, 2.0, 0.085, 0.001, 0.003003003003003003]\n",
            "Node 166: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.582, 0.002, 0.002002002002002002]\n",
            "Node 167: [0.5714785042106848, 0, 0, 0.001, 0.002, 0.19925605152120807, 2.0, 0.086, 0.001, 0.003003003003003003]\n",
            "Node 168: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 3.0, 0.583, 0.002, 0.002002002002002002]\n",
            "Node 169: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 2.0, 0.087, 0.001, 0.003003003003003003]\n",
            "Node 170: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.584, 0.002, 0.002002002002002002]\n",
            "Node 171: [0.020794077744192608, 0, 0, 0.001, 0.002, 0.1260270930490784, 2.0, 0.088, 0.001, 0.003003003003003003]\n",
            "Node 172: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.585, 0.002, 0.002002002002002002]\n",
            "Node 173: [0.6971464438364728, 0, 0, 0.001, 0.002, 0.21596713302242948, 2.0, 0.089, 0.001, 0.003003003003003003]\n",
            "Node 174: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.586, 0.002, 0.002002002002002002]\n",
            "Node 175: [1.3810138362186668, 0, 0, 0.001, 0.002, 0.30690650677326226, 2.0, 0.09, 0.001, 0.003003003003003003]\n",
            "Node 176: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 3.0, 0.587, 0.002, 0.002002002002002002]\n",
            "Node 177: [0.5840035480272087, 0, 0, 0.001, 0.002, 0.20092160781701088, 2.0, 0.091, 0.001, 0.003003003003003003]\n",
            "Node 178: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.588, 0.002, 0.002002002002002002]\n",
            "Node 179: [1.1935556804313623, 0, 0, 0.001, 0.002, 0.28197868087941375, 2.0, 0.092, 0.001, 0.003003003003003003]\n",
            "Node 180: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 3.0, 0.589, 0.002, 0.002002002002002002]\n",
            "Node 181: [0.2550123971131859, 0, 0, 0.001, 0.002, 0.1571729957805907, 2.0, 0.093, 0.001, 0.003003003003003003]\n",
            "Node 182: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.59, 0.002, 0.002002002002002002]\n",
            "Node 183: [1.3956263873379449, 0, 0, 0.001, 0.002, 0.30884965578503215, 2.0, 0.094, 0.001, 0.003003003003003003]\n",
            "Node 184: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 3.0, 0.591, 0.002, 0.002002002002002002]\n",
            "Node 185: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 2.0, 0.095, 0.001, 0.003003003003003003]\n",
            "Node 186: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 3.0, 0.592, 0.002, 0.002002002002002002]\n",
            "Node 187: [1.7145975031987486, 0, 0, 0.001, 0.002, 0.3512658227848101, 2.0, 0.096, 0.001, 0.003003003003003003]\n",
            "Node 188: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 3.0, 0.593, 0.002, 0.002002002002002002]\n",
            "Node 189: [1.6198246716537188, 0, 0, 0.001, 0.002, 0.33866311347990224, 2.0, 0.097, 0.001, 0.003003003003003003]\n",
            "Node 190: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.594, 0.002, 0.002002002002002002]\n",
            "Node 191: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 2.0, 0.098, 0.001, 0.003003003003003003]\n",
            "Node 192: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.595, 0.002, 0.002002002002002002]\n",
            "Node 193: [1.4916517232646265, 0, 0, 0.001, 0.002, 0.3216189207195203, 2.0, 0.099, 0.001, 0.003003003003003003]\n",
            "Node 194: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 3.0, 0.596, 0.002, 0.002002002002002002]\n",
            "Node 195: [0.8850221010843284, 0, 0, 0.001, 0.002, 0.24095047745947148, 2.0, 0.1, 0.001, 0.003003003003003003]\n",
            "Node 196: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.597, 0.002, 0.002002002002002002]\n",
            "Node 197: [0.24707986936272097, 0, 0, 0.001, 0.002, 0.15611814345991562, 2.0, 0.101, 0.001, 0.003003003003003003]\n",
            "Node 198: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.598, 0.002, 0.002002002002002002]\n",
            "Node 199: [0.2917525256416554, 0, 0, 0.001, 0.002, 0.16205862758161224, 2.0, 0.102, 0.001, 0.003003003003003003]\n",
            "Node 200: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 3.0, 0.599, 0.002, 0.002002002002002002]\n",
            "Node 201: [0.557283454551958, 0, 0, 0.001, 0.002, 0.19736842105263158, 2.0, 0.103, 0.001, 0.003003003003003003]\n",
            "Node 202: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 3.0, 0.6, 0.002, 0.002002002002002002]\n",
            "Node 203: [0.6925539277704141, 0, 0, 0.001, 0.002, 0.2153564290473018, 2.0, 0.104, 0.001, 0.003003003003003003]\n",
            "Node 204: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.601, 0.002, 0.002002002002002002]\n",
            "Node 205: [0.8637295265962379, 0, 0, 0.001, 0.002, 0.23811903175660667, 2.0, 0.105, 0.001, 0.003003003003003003]\n",
            "Node 206: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.602, 0.002, 0.002002002002002002]\n",
            "Node 207: [0.02496909234970057, 0, 0, 0.001, 0.002, 0.12658227848101267, 2.0, 0.106, 0.001, 0.003003003003003003]\n",
            "Node 208: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.603, 0.002, 0.002002002002002002]\n",
            "Node 209: [0.5510209326436962, 0, 0, 0.001, 0.002, 0.1965356429047302, 2.0, 0.107, 0.001, 0.003003003003003003]\n",
            "Node 210: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 3.0, 0.604, 0.002, 0.002002002002002002]\n",
            "Node 211: [0.6837863970988476, 0, 0, 0.001, 0.002, 0.21419053964023985, 2.0, 0.108, 0.001, 0.003003003003003003]\n",
            "Node 212: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 3.0, 0.605, 0.002, 0.002002002002002002]\n",
            "Node 213: [0.3456102140527074, 0, 0, 0.001, 0.002, 0.16922051965356427, 2.0, 0.109, 0.001, 0.003003003003003003]\n",
            "Node 214: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.606, 0.002, 0.002002002002002002]\n",
            "Node 215: [0.8424369521081477, 0, 0, 0.001, 0.002, 0.23528758605374192, 2.0, 0.11, 0.001, 0.003003003003003003]\n",
            "Node 216: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.607, 0.002, 0.002002002002002002]\n",
            "Node 217: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 2.0, 0.111, 0.001, 0.003003003003003003]\n",
            "Node 218: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.608, 0.002, 0.002002002002002002]\n",
            "Node 219: [1.673682360064771, 0, 0, 0.001, 0.002, 0.3458250055518543, 2.0, 0.112, 0.001, 0.003003003003003003]\n",
            "Node 220: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 3.0, 0.609, 0.002, 0.002002002002002002]\n",
            "Node 221: [6.593102069734732, 0, 0, 0.0, 0.125, 1.0, 0.0, 0.001, 0.0, 0.12512512512512514]\n",
            "Node 222: [0.9217622296127977, 0, 0, 0.001, 0.002, 0.245836109260493, 0.0, 0.113, 0.0, 0.003003003003003003]\n",
            "Node 223: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.61, 0.0, 0.002002002002002002]\n",
            "Node 224: [1.682032389275787, 0, 0, 0.001, 0.002, 0.34693537641572286, 0.0, 0.114, 0.0, 0.003003003003003003]\n",
            "Node 225: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.611, 0.0, 0.002002002002002002]\n",
            "Node 226: [0.6533087904786397, 0, 0, 0.001, 0.002, 0.21013768598711965, 0.0, 0.115, 0.0, 0.003003003003003003]\n",
            "Node 227: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.612, 0.0, 0.002002002002002002]\n",
            "Node 228: [1.2344708235653397, 0, 0, 0.001, 0.002, 0.28741949811236955, 0.0, 0.116, 0.0, 0.003003003003003003]\n",
            "Node 229: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.613, 0.0, 0.002002002002002002]\n",
            "Node 230: [0.8023568118952717, 0, 0, 0.001, 0.002, 0.22995780590717296, 0.0, 0.117, 0.0, 0.003003003003003003]\n",
            "Node 231: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.614, 0.0, 0.002002002002002002]\n",
            "Node 232: [1.7672026872281477, 0, 0, 0.001, 0.002, 0.3582611592271819, 0.0, 0.118, 0.0, 0.003003003003003003]\n",
            "Node 233: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.615, 0.0, 0.002002002002002002]\n",
            "Node 234: [0.9305297602843644, 0, 0, 0.001, 0.002, 0.24700199866755496, 0.0, 0.119, 0.0, 0.003003003003003003]\n",
            "Node 235: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.616, 0.0, 0.002002002002002002]\n",
            "Node 236: [0.6683388430584681, 0, 0, 0.001, 0.002, 0.21213635354208304, 0.0, 0.12, 0.0, 0.003003003003003003]\n",
            "Node 237: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.617, 0.0, 0.002002002002002002]\n",
            "Node 238: [1.5830845431252494, 0, 0, 0.001, 0.002, 0.3337774816788807, 0.0, 0.121, 0.0, 0.003003003003003003]\n",
            "Node 239: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.618, 0.0, 0.002002002002002002]\n",
            "Node 240: [0.9209272266916964, 0, 0, 0.001, 0.002, 0.24572507217410614, 0.0, 0.122, 0.0, 0.003003003003003003]\n",
            "Node 241: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.619, 0.0, 0.002002002002002002]\n",
            "Node 242: [1.1584855577450959, 0, 0, 0.001, 0.002, 0.27731512325116586, 0.0, 0.123, 0.0, 0.003003003003003003]\n",
            "Node 243: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.62, 0.0, 0.002002002002002002]\n",
            "Node 244: [0.3431052052894026, 0, 0, 0.001, 0.002, 0.16888740839440372, 0.0, 0.124, 0.0, 0.003003003003003003]\n",
            "Node 245: [-0.8851840916510221, 0, 0, 0.001, 0.001, 0.00555185431934266, 0.0, 0.621, 0.0, 0.002002002002002002]\n",
            "Node 246: [1.0006700056568971, 0, 0, 0.001, 0.002, 0.2563291139240506, 0.0, 0.125, 0.0, 0.003003003003003003]\n",
            "Node 247: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.622, 0.0, 0.002002002002002002]\n",
            "Node 248: [0.9923199764458815, 0, 0, 0.001, 0.002, 0.2552187430601821, 0.0, 0.126, 0.0, 0.003003003003003003]\n",
            "Node 249: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.623, 0.0, 0.002002002002002002]\n",
            "Node 250: [0.5393308917482741, 0, 0, 0.001, 0.002, 0.19498112369531423, 0.0, 0.127, 0.0, 0.003003003003003003]\n",
            "Node 251: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.624, 0.0, 0.002002002002002002]\n",
            "Node 252: [0.157317055344301, 0, 0, 0.001, 0.002, 0.14418165667332888, 0.0, 0.128, 0.0, 0.003003003003003003]\n",
            "Node 253: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.625, 0.0, 0.002002002002002002]\n",
            "Node 254: [0.8679045412017459, 0, 0, 0.001, 0.002, 0.23867421718854095, 0.0, 0.129, 0.0, 0.003003003003003003]\n",
            "Node 255: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.626, 0.0, 0.002002002002002002]\n",
            "Node 256: [0.781899240328283, 0, 0, 0.001, 0.002, 0.22723739729069506, 0.0, 0.13, 0.0, 0.003003003003003003]\n",
            "Node 257: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.627, 0.0, 0.002002002002002002]\n",
            "Node 258: [0.3940403834765989, 0, 0, 0.001, 0.002, 0.17566067066400176, 0.0, 0.131, 0.0, 0.003003003003003003]\n",
            "Node 259: [-0.9110691822051711, 0, 0, 0.001, 0.001, 0.002109704641350211, 0.0, 0.628, 0.0, 0.002002002002002002]\n",
            "Node 260: [1.2553458965928792, 0, 0, 0.001, 0.002, 0.29019542527204084, 0.0, 0.132, 0.0, 0.003003003003003003]\n",
            "Node 261: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.629, 0.0, 0.002002002002002002]\n",
            "Node 262: [0.10972188884151088, 0, 0, 0.001, 0.002, 0.13785254274927825, 0.0, 0.133, 0.0, 0.003003003003003003]\n",
            "Node 263: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.63, 0.0, 0.002002002002002002]\n",
            "Node 264: [0.08007928514240488, 0, 0, 0.001, 0.002, 0.13391072618254496, 0.0, 0.134, 0.0, 0.003003003003003003]\n",
            "Node 265: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.631, 0.0, 0.002002002002002002]\n",
            "Node 266: [-0.041413639877875066, 0, 0, 0.001, 0.002, 0.11775483011325782, 0.0, 0.135, 0.0, 0.003003003003003003]\n",
            "Node 267: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.632, 0.0, 0.002002002002002002]\n",
            "Node 268: [1.4795441809086534, 0, 0, 0.001, 0.002, 0.32000888296691093, 0.0, 0.136, 0.0, 0.003003003003003003]\n",
            "Node 269: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.633, 0.0, 0.002002002002002002]\n",
            "Node 270: [1.0716452539505317, 0, 0, 0.001, 0.002, 0.26576726626693314, 0.0, 0.137, 0.0, 0.003003003003003003]\n",
            "Node 271: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.634, 0.0, 0.002002002002002002]\n",
            "Node 272: [0.06170922087817007, 0, 0, 0.001, 0.002, 0.1314679102820342, 0.0, 0.138, 0.0, 0.003003003003003003]\n",
            "Node 273: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.635, 0.0, 0.002002002002002002]\n",
            "Node 274: [1.15013552853408, 0, 0, 0.001, 0.002, 0.2762047523872973, 0.0, 0.139, 0.0, 0.003003003003003003]\n",
            "Node 275: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.636, 0.0, 0.002002002002002002]\n",
            "Node 276: [1.637777234457403, 0, 0, 0.001, 0.002, 0.3410504108372196, 0.0, 0.14, 0.0, 0.003003003003003003]\n",
            "Node 277: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.637, 0.0, 0.002002002002002002]\n",
            "Node 278: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.141, 0.0, 0.003003003003003003]\n",
            "Node 279: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.638, 0.0, 0.002002002002002002]\n",
            "Node 280: [1.2524233863690237, 0, 0, 0.001, 0.002, 0.28980679546968685, 0.0, 0.142, 0.0, 0.003003003003003003]\n",
            "Node 281: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.639, 0.0, 0.002002002002002002]\n",
            "Node 282: [0.7906667709998496, 0, 0, 0.001, 0.002, 0.22840328669775703, 0.0, 0.143, 0.0, 0.003003003003003003]\n",
            "Node 283: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.64, 0.0, 0.002002002002002002]\n",
            "Node 284: [0.9013046580458093, 0, 0, 0.001, 0.002, 0.2431157006440151, 0.0, 0.144, 0.0, 0.003003003003003003]\n",
            "Node 285: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.641, 0.0, 0.002002002002002002]\n",
            "Node 286: [0.30761758114258553, 0, 0, 0.001, 0.002, 0.16416833222296245, 0.0, 0.145, 0.0, 0.003003003003003003]\n",
            "Node 287: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.642, 0.0, 0.002002002002002002]\n",
            "Node 288: [0.1685895947791723, 0, 0, 0.001, 0.002, 0.1456806573395514, 0.0, 0.146, 0.0, 0.003003003003003003]\n",
            "Node 289: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.643, 0.0, 0.002002002002002002]\n",
            "Node 290: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.147, 0.0, 0.003003003003003003]\n",
            "Node 291: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.644, 0.0, 0.002002002002002002]\n",
            "Node 292: [1.3501187281379086, 0, 0, 0.001, 0.002, 0.3027981345769487, 0.0, 0.148, 0.0, 0.003003003003003003]\n",
            "Node 293: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.645, 0.0, 0.002002002002002002]\n",
            "Node 294: [0.5172033143390822, 0, 0, 0.001, 0.002, 0.19203864090606262, 0.0, 0.149, 0.0, 0.003003003003003003]\n",
            "Node 295: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.646, 0.0, 0.002002002002002002]\n",
            "Node 296: [1.3325836667947755, 0, 0, 0.001, 0.002, 0.30046635576282477, 0.0, 0.15, 0.0, 0.003003003003003003]\n",
            "Node 297: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.647, 0.0, 0.002002002002002002]\n",
            "Node 298: [1.6720123542225676, 0, 0, 0.001, 0.002, 0.34560293137908055, 0.0, 0.151, 0.0, 0.003003003003003003]\n",
            "Node 299: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.648, 0.0, 0.002002002002002002]\n",
            "Node 300: [0.9326172675871185, 0, 0, 0.001, 0.002, 0.2472795913835221, 0.0, 0.152, 0.0, 0.003003003003003003]\n",
            "Node 301: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.649, 0.0, 0.002002002002002002]\n",
            "Node 302: [0.4128279492013846, 0, 0, 0.001, 0.002, 0.17815900510770596, 0.0, 0.153, 0.0, 0.003003003003003003]\n",
            "Node 303: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.65, 0.0, 0.002002002002002002]\n",
            "Node 304: [0.953492340614658, 0, 0, 0.001, 0.002, 0.2500555185431934, 0.0, 0.154, 0.0, 0.003003003003003003]\n",
            "Node 305: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.651, 0.0, 0.002002002002002002]\n",
            "Node 306: [0.3209776278802108, 0, 0, 0.001, 0.002, 0.16594492560515212, 0.0, 0.155, 0.0, 0.003003003003003003]\n",
            "Node 307: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.652, 0.0, 0.002002002002002002]\n",
            "Node 308: [1.1831181439175926, 0, 0, 0.001, 0.002, 0.2805907172995781, 0.0, 0.156, 0.0, 0.003003003003003003]\n",
            "Node 309: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.653, 0.0, 0.002002002002002002]\n",
            "Node 310: [0.3201426249591092, 0, 0, 0.001, 0.002, 0.16583388851876527, 0.0, 0.157, 0.0, 0.003003003003003003]\n",
            "Node 311: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.654, 0.0, 0.002002002002002002]\n",
            "Node 312: [1.0374101341853668, 0, 0, 0.001, 0.002, 0.2612147457250722, 0.0, 0.158, 0.0, 0.003003003003003003]\n",
            "Node 313: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.655, 0.0, 0.002002002002002002]\n",
            "Node 314: [1.7388125879106944, 0, 0, 0.001, 0.002, 0.35448589829002886, 0.0, 0.159, 0.0, 0.003003003003003003]\n",
            "Node 315: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.656, 0.0, 0.002002002002002002]\n",
            "Node 316: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 0.0, 0.16, 0.0, 0.003003003003003003]\n",
            "Node 317: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.657, 0.0, 0.002002002002002002]\n",
            "Node 318: [0.7514216337080755, 0, 0, 0.001, 0.002, 0.22318454363757492, 0.0, 0.161, 0.0, 0.003003003003003003]\n",
            "Node 319: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.658, 0.0, 0.002002002002002002]\n",
            "Node 320: [0.5915185743171228, 0, 0, 0.001, 0.002, 0.20192094159449256, 0.0, 0.162, 0.0, 0.003003003003003003]\n",
            "Node 321: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.659, 0.0, 0.002002002002002002]\n",
            "Node 322: [0.8942071332164457, 0, 0, 0.001, 0.002, 0.2421718854097268, 0.0, 0.163, 0.0, 0.003003003003003003]\n",
            "Node 323: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.66, 0.0, 0.002002002002002002]\n",
            "Node 324: [0.4032254156087163, 0, 0, 0.001, 0.002, 0.17688207861425712, 0.0, 0.164, 0.0, 0.003003003003003003]\n",
            "Node 325: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.661, 0.0, 0.002002002002002002]\n",
            "Node 326: [1.1438730066258183, 0, 0, 0.001, 0.002, 0.2753719742393959, 0.0, 0.165, 0.0, 0.003003003003003003]\n",
            "Node 327: [-0.8960391296253427, 0, 0, 0.001, 0.001, 0.004108372196313569, 0.0, 0.662, 0.0, 0.002002002002002002]\n",
            "Node 328: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.166, 0.0, 0.003003003003003003]\n",
            "Node 329: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.663, 0.0, 0.002002002002002002]\n",
            "Node 330: [1.4720291546187394, 0, 0, 0.001, 0.002, 0.31900954918942925, 0.0, 0.167, 0.0, 0.003003003003003003]\n",
            "Node 331: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.664, 0.0, 0.002002002002002002]\n",
            "Node 332: [1.5192068196609785, 0, 0, 0.001, 0.002, 0.3252831445702865, 0.0, 0.168, 0.0, 0.003003003003003003]\n",
            "Node 333: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.665, 0.0, 0.002002002002002002]\n",
            "Node 334: [0.0608742179570685, 0, 0, 0.001, 0.002, 0.13135687319564732, 0.0, 0.169, 0.0, 0.003003003003003003]\n",
            "Node 335: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.666, 0.0, 0.002002002002002002]\n",
            "Node 336: [0.34185270090775033, 0, 0, 0.001, 0.002, 0.16872085276482346, 0.0, 0.17, 0.0, 0.003003003003003003]\n",
            "Node 337: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.667, 0.0, 0.002002002002002002]\n",
            "Node 338: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.171, 0.0, 0.003003003003003003]\n",
            "Node 339: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.668, 0.0, 0.002002002002002002]\n",
            "Node 340: [0.5280583523134026, 0, 0, 0.001, 0.002, 0.19348212302909168, 0.0, 0.172, 0.0, 0.003003003003003003]\n",
            "Node 341: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.669, 0.0, 0.002002002002002002]\n",
            "Node 342: [0.4332855207683734, 0, 0, 0.001, 0.002, 0.1808794137241839, 0.0, 0.173, 0.0, 0.003003003003003003]\n",
            "Node 343: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.67, 0.0, 0.002002002002002002]\n",
            "Node 344: [1.698732447697818, 0, 0, 0.001, 0.002, 0.34915611814345987, 0.0, 0.174, 0.0, 0.003003003003003003]\n",
            "Node 345: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.671, 0.0, 0.002002002002002002]\n",
            "Node 346: [0.5577009560125088, 0, 0, 0.001, 0.002, 0.197423939595825, 0.0, 0.175, 0.0, 0.003003003003003003]\n",
            "Node 347: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.672, 0.0, 0.002002002002002002]\n",
            "Node 348: [1.54634441459678, 0, 0, 0.001, 0.002, 0.3288918498778592, 0.0, 0.176, 0.0, 0.003003003003003003]\n",
            "Node 349: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.673, 0.0, 0.002002002002002002]\n",
            "Node 350: [1.6256696921014298, 0, 0, 0.001, 0.002, 0.3394403730846102, 0.0, 0.177, 0.0, 0.003003003003003003]\n",
            "Node 351: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.674, 0.0, 0.002002002002002002]\n",
            "Node 352: [0.883352095242125, 0, 0, 0.001, 0.002, 0.24072840328669773, 0.0, 0.178, 0.0, 0.003003003003003003]\n",
            "Node 353: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.675, 0.0, 0.002002002002002002]\n",
            "Node 354: [1.5212943269637322, 0, 0, 0.001, 0.002, 0.32556073728625357, 0.0, 0.179, 0.0, 0.003003003003003003]\n",
            "Node 355: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.676, 0.0, 0.002002002002002002]\n",
            "Node 356: [0.8040268177374749, 0, 0, 0.001, 0.002, 0.2301798800799467, 0.0, 0.18, 0.0, 0.003003003003003003]\n",
            "Node 357: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.677, 0.0, 0.002002002002002002]\n",
            "Node 358: [-0.025131082916394373, 0, 0, 0.001, 0.002, 0.11992005329780143, 0.0, 0.181, 0.0, 0.003003003003003003]\n",
            "Node 359: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.678, 0.0, 0.002002002002002002]\n",
            "Node 360: [1.122580432137728, 0, 0, 0.001, 0.002, 0.2725405285365312, 0.0, 0.182, 0.0, 0.003003003003003003]\n",
            "Node 361: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.679, 0.0, 0.002002002002002002]\n",
            "Node 362: [1.7617751682409877, 0, 0, 0.001, 0.002, 0.35753941816566737, 0.0, 0.183, 0.0, 0.003003003003003003]\n",
            "Node 363: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.68, 0.0, 0.002002002002002002]\n",
            "Node 364: [0.5606234662363643, 0, 0, 0.001, 0.002, 0.19781256939817896, 0.0, 0.184, 0.0, 0.003003003003003003]\n",
            "Node 365: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.681, 0.0, 0.002002002002002002]\n",
            "Node 366: [0.2516723854287796, 0, 0, 0.001, 0.002, 0.15672884743504328, 0.0, 0.185, 0.0, 0.003003003003003003]\n",
            "Node 367: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.682, 0.0, 0.002002002002002002]\n",
            "Node 368: [0.3977978966215562, 0, 0, 0.001, 0.002, 0.1761603375527426, 0.0, 0.186, 0.0, 0.003003003003003003]\n",
            "Node 369: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.683, 0.0, 0.002002002002002002]\n",
            "Node 370: [1.7162675090409514, 0, 0, 0.001, 0.002, 0.35148789695758376, 0.0, 0.187, 0.0, 0.003003003003003003]\n",
            "Node 371: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.684, 0.0, 0.002002002002002002]\n",
            "Node 372: [0.16733709039752004, 0, 0, 0.001, 0.002, 0.14551410170997112, 0.0, 0.188, 0.0, 0.003003003003003003]\n",
            "Node 373: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.685, 0.0, 0.002002002002002002]\n",
            "Node 374: [0.5873435597116149, 0, 0, 0.001, 0.002, 0.2013657561625583, 0.0, 0.189, 0.0, 0.003003003003003003]\n",
            "Node 375: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.686, 0.0, 0.002002002002002002]\n",
            "Node 376: [0.44288805436104145, 0, 0, 0.001, 0.002, 0.18215634021763266, 0.0, 0.19, 0.0, 0.003003003003003003]\n",
            "Node 377: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.687, 0.0, 0.002002002002002002]\n",
            "Node 378: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.191, 0.0, 0.003003003003003003]\n",
            "Node 379: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.688, 0.0, 0.002002002002002002]\n",
            "Node 380: [0.5426709034326803, 0, 0, 0.001, 0.002, 0.19542527204086163, 0.0, 0.192, 0.0, 0.003003003003003003]\n",
            "Node 381: [-0.9227592231005933, 0, 0, 0.001, 0.001, 0.0005551854319342662, 0.0, 0.689, 0.0, 0.002002002002002002]\n",
            "Node 382: [0.016201561678133938, 0, 0, 0.001, 0.002, 0.1254163890739507, 0.0, 0.193, 0.0, 0.003003003003003003]\n",
            "Node 383: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.69, 0.0, 0.002002002002002002]\n",
            "Node 384: [0.3973803951610055, 0, 0, 0.001, 0.002, 0.1761048190095492, 0.0, 0.194, 0.0, 0.003003003003003003]\n",
            "Node 385: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.691, 0.0, 0.002002002002002002]\n",
            "Node 386: [1.6945574330923105, 0, 0, 0.001, 0.002, 0.34860093271152565, 0.0, 0.195, 0.0, 0.003003003003003003]\n",
            "Node 387: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.692, 0.0, 0.002002002002002002]\n",
            "Node 388: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 0.0, 0.196, 0.0, 0.003003003003003003]\n",
            "Node 389: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.693, 0.0, 0.002002002002002002]\n",
            "Node 390: [0.5506034311831453, 0, 0, 0.001, 0.002, 0.19648012436153672, 0.0, 0.197, 0.0, 0.003003003003003003]\n",
            "Node 391: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.694, 0.0, 0.002002002002002002]\n",
            "Node 392: [0.13143196479015196, 0, 0, 0.001, 0.002, 0.1407395069953364, 0.0, 0.198, 0.0, 0.003003003003003003]\n",
            "Node 393: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.695, 0.0, 0.002002002002002002]\n",
            "Node 394: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.199, 0.0, 0.003003003003003003]\n",
            "Node 395: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.696, 0.0, 0.002002002002002002]\n",
            "Node 396: [1.6766048702886263, 0, 0, 0.001, 0.002, 0.3462136353542083, 0.0, 0.2, 0.0, 0.003003003003003003]\n",
            "Node 397: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.697, 0.0, 0.002002002002002002]\n",
            "Node 398: [0.8453594623320032, 0, 0, 0.001, 0.002, 0.2356762158560959, 0.0, 0.201, 0.0, 0.003003003003003003]\n",
            "Node 399: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.698, 0.0, 0.002002002002002002]\n",
            "Node 400: [1.5835020445858004, 0, 0, 0.001, 0.002, 0.3338330002220741, 0.0, 0.202, 0.0, 0.003003003003003003]\n",
            "Node 401: [-0.8826790828877173, 0, 0, 0.001, 0.001, 0.005884965578503219, 0.0, 0.699, 0.0, 0.002002002002002002]\n",
            "Node 402: [0.8603895149118317, 0, 0, 0.001, 0.002, 0.23767488341105925, 0.0, 0.203, 0.0, 0.003003003003003003]\n",
            "Node 403: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.7, 0.0, 0.002002002002002002]\n",
            "Node 404: [1.540499394149069, 0, 0, 0.001, 0.002, 0.3281145902731512, 0.0, 0.204, 0.0, 0.003003003003003003]\n",
            "Node 405: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.701, 0.0, 0.002002002002002002]\n",
            "Node 406: [1.7229475324097638, 0, 0, 0.001, 0.002, 0.35237619364867867, 0.0, 0.205, 0.0, 0.003003003003003003]\n",
            "Node 407: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.702, 0.0, 0.002002002002002002]\n",
            "Node 408: [0.5188733201812853, 0, 0, 0.001, 0.002, 0.1922607150788363, 0.0, 0.206, 0.0, 0.003003003003003003]\n",
            "Node 409: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.703, 0.0, 0.002002002002002002]\n",
            "Node 410: [0.4245179900968068, 0, 0, 0.001, 0.002, 0.17971352431712193, 0.0, 0.207, 0.0, 0.003003003003003003]\n",
            "Node 411: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.704, 0.0, 0.002002002002002002]\n",
            "Node 412: [-0.015111047863175325, 0, 0, 0.001, 0.002, 0.1212524983344437, 0.0, 0.208, 0.0, 0.003003003003003003]\n",
            "Node 413: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.705, 0.0, 0.002002002002002002]\n",
            "Node 414: [-0.007178520112710406, 0, 0, 0.001, 0.002, 0.12230735065511879, 0.0, 0.209, 0.0, 0.003003003003003003]\n",
            "Node 415: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.706, 0.0, 0.002002002002002002]\n",
            "Node 416: [0.38777786156833716, 0, 0, 0.001, 0.002, 0.17482789251610037, 0.0, 0.21, 0.0, 0.003003003003003003]\n",
            "Node 417: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.707, 0.0, 0.002002002002002002]\n",
            "Node 418: [-0.03556861943016413, 0, 0, 0.001, 0.002, 0.11853208971796576, 0.0, 0.211, 0.0, 0.003003003003003003]\n",
            "Node 419: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.708, 0.0, 0.002002002002002002]\n",
            "Node 420: [1.7279575499363735, 0, 0, 0.001, 0.002, 0.3530424161669998, 0.0, 0.212, 0.0, 0.003003003003003003]\n",
            "Node 421: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.709, 0.0, 0.002002002002002002]\n",
            "Node 422: [0.2600224146397954, 0, 0, 0.001, 0.002, 0.15783921829891182, 0.0, 0.213, 0.0, 0.003003003003003003]\n",
            "Node 423: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.71, 0.0, 0.002002002002002002]\n",
            "Node 424: [0.7764717213411229, 0, 0, 0.001, 0.002, 0.22651565622918055, 0.0, 0.214, 0.0, 0.003003003003003003]\n",
            "Node 425: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.711, 0.0, 0.002002002002002002]\n",
            "Node 426: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 0.0, 0.215, 0.0, 0.003003003003003003]\n",
            "Node 427: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.712, 0.0, 0.002002002002002002]\n",
            "Node 428: [0.2537598927315335, 0, 0, 0.001, 0.002, 0.15700644015101042, 0.0, 0.216, 0.0, 0.003003003003003003]\n",
            "Node 429: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.713, 0.0, 0.002002002002002002]\n",
            "Node 430: [0.6144811546474163, 0, 0, 0.001, 0.002, 0.20497446147013101, 0.0, 0.217, 0.0, 0.003003003003003003]\n",
            "Node 431: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.714, 0.0, 0.002002002002002002]\n",
            "Node 432: [1.386858856666378, 0, 0, 0.001, 0.002, 0.30768376637797024, 0.0, 0.218, 0.0, 0.003003003003003003]\n",
            "Node 433: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.715, 0.0, 0.002002002002002002]\n",
            "Node 434: [0.9196747223100439, 0, 0, 0.001, 0.002, 0.24555851654452587, 0.0, 0.219, 0.0, 0.003003003003003003]\n",
            "Node 435: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.716, 0.0, 0.002002002002002002]\n",
            "Node 436: [0.45833560840142057, 0, 0, 0.001, 0.002, 0.18421052631578946, 0.0, 0.22, 0.0, 0.003003003003003003]\n",
            "Node 437: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.717, 0.0, 0.002002002002002002]\n",
            "Node 438: [1.4695241458554344, 0, 0, 0.001, 0.002, 0.31867643793026873, 0.0, 0.221, 0.0, 0.003003003003003003]\n",
            "Node 439: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.718, 0.0, 0.002002002002002002]\n",
            "Node 440: [0.8829345937815742, 0, 0, 0.001, 0.002, 0.2406728847435043, 0.0, 0.222, 0.0, 0.003003003003003003]\n",
            "Node 441: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.719, 0.0, 0.002002002002002002]\n",
            "Node 442: [0.21910727150581794, 0, 0, 0.001, 0.002, 0.152398401065956, 0.0, 0.223, 0.0, 0.003003003003003003]\n",
            "Node 443: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.72, 0.0, 0.002002002002002002]\n",
            "Node 444: [0.9701923990366895, 0, 0, 0.001, 0.002, 0.2522762602709305, 0.0, 0.224, 0.0, 0.003003003003003003]\n",
            "Node 445: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.721, 0.0, 0.002002002002002002]\n",
            "Node 446: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.225, 0.0, 0.003003003003003003]\n",
            "Node 447: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.722, 0.0, 0.002002002002002002]\n",
            "Node 448: [0.7672866892090056, 0, 0, 0.001, 0.002, 0.22529424827892516, 0.0, 0.226, 0.0, 0.003003003003003003]\n",
            "Node 449: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.723, 0.0, 0.002002002002002002]\n",
            "Node 450: [1.6386122373785044, 0, 0, 0.001, 0.002, 0.3411614479236065, 0.0, 0.227, 0.0, 0.003003003003003003]\n",
            "Node 451: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.724, 0.0, 0.002002002002002002]\n",
            "Node 452: [1.4937392305673802, 0, 0, 0.001, 0.002, 0.3218965134354874, 0.0, 0.228, 0.0, 0.003003003003003003]\n",
            "Node 453: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.725, 0.0, 0.002002002002002002]\n",
            "Node 454: [1.09210282551752, 0, 0, 0.001, 0.002, 0.268487674883411, 0.0, 0.229, 0.0, 0.003003003003003003]\n",
            "Node 455: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.726, 0.0, 0.002002002002002002]\n",
            "Node 456: [0.4165854623463416, 0, 0, 0.001, 0.002, 0.1786586719964468, 0.0, 0.23, 0.0, 0.003003003003003003]\n",
            "Node 457: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.727, 0.0, 0.002002002002002002]\n",
            "Node 458: [0.43412052368947485, 0, 0, 0.001, 0.002, 0.1809904508105707, 0.0, 0.231, 0.0, 0.003003003003003003]\n",
            "Node 459: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.728, 0.0, 0.002002002002002002]\n",
            "Node 460: [0.9518223347724546, 0, 0, 0.001, 0.002, 0.24983344437041966, 0.0, 0.232, 0.0, 0.003003003003003003]\n",
            "Node 461: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.729, 0.0, 0.002002002002002002]\n",
            "Node 462: [0.44622806604544774, 0, 0, 0.001, 0.002, 0.18260048856318006, 0.0, 0.233, 0.0, 0.003003003003003003]\n",
            "Node 463: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.73, 0.0, 0.002002002002002002]\n",
            "Node 464: [1.6949749345528615, 0, 0, 0.001, 0.002, 0.34865645125471906, 0.0, 0.234, 0.0, 0.003003003003003003]\n",
            "Node 465: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.731, 0.0, 0.002002002002002002]\n",
            "Node 466: [1.610222138061051, 0, 0, 0.001, 0.002, 0.33738618698645345, 0.0, 0.235, 0.0, 0.003003003003003003]\n",
            "Node 467: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.732, 0.0, 0.002002002002002002]\n",
            "Node 468: [1.0040100173413034, 0, 0, 0.001, 0.002, 0.256773262269598, 0.0, 0.236, 0.0, 0.003003003003003003]\n",
            "Node 469: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.733, 0.0, 0.002002002002002002]\n",
            "Node 470: [0.3080350826031362, 0, 0, 0.001, 0.002, 0.1642238507661559, 0.0, 0.237, 0.0, 0.003003003003003003]\n",
            "Node 471: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.734, 0.0, 0.002002002002002002]\n",
            "Node 472: [3.5207088215414664, 0, 0, 0.0, 0.131, 0.5914390406395736, 0.0, 0.002, 0.0, 0.13113113113113112]\n",
            "Node 473: [0.3898653688710913, 0, 0, 0.001, 0.002, 0.1751054852320675, 0.0, 0.238, 0.0, 0.003003003003003003]\n",
            "Node 474: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.735, 0.0, 0.002002002002002002]\n",
            "Node 475: [1.5317318634775021, 0, 0, 0.001, 0.002, 0.32694870086608924, 0.0, 0.239, 0.0, 0.003003003003003003]\n",
            "Node 476: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.736, 0.0, 0.002002002002002002]\n",
            "Node 477: [0.7397315928126532, 0, 0, 0.001, 0.002, 0.221630024428159, 0.0, 0.24, 0.0, 0.003003003003003003]\n",
            "Node 478: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.737, 0.0, 0.002002002002002002]\n",
            "Node 479: [0.17025960062137543, 0, 0, 0.001, 0.002, 0.1459027315123251, 0.0, 0.241, 0.0, 0.003003003003003003]\n",
            "Node 480: [-0.9035541559152569, 0, 0, 0.001, 0.001, 0.0031090384188318895, 0.0, 0.738, 0.0, 0.002002002002002002]\n",
            "Node 481: [0.5627109735391181, 0, 0, 0.001, 0.002, 0.1980901621141461, 0.0, 0.242, 0.0, 0.003003003003003003]\n",
            "Node 482: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.739, 0.0, 0.002002002002002002]\n",
            "Node 483: [-0.008848525954913531, 0, 0, 0.001, 0.002, 0.1220852764823451, 0.0, 0.243, 0.0, 0.003003003003003003]\n",
            "Node 484: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.74, 0.0, 0.002002002002002002]\n",
            "Node 485: [0.8061143250402291, 0, 0, 0.001, 0.002, 0.23045747279591383, 0.0, 0.244, 0.0, 0.003003003003003003]\n",
            "Node 486: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.741, 0.0, 0.002002002002002002]\n",
            "Node 487: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.245, 0.0, 0.003003003003003003]\n",
            "Node 488: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.742, 0.0, 0.002002002002002002]\n",
            "Node 489: [1.615649657048211, 0, 0, 0.001, 0.002, 0.338107928047968, 0.0, 0.246, 0.0, 0.003003003003003003]\n",
            "Node 490: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.743, 0.0, 0.002002002002002002]\n",
            "Node 491: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.247, 0.0, 0.003003003003003003]\n",
            "Node 492: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.744, 0.0, 0.002002002002002002]\n",
            "Node 493: [0.36940779730410245, 0, 0, 0.001, 0.002, 0.1723850766155896, 0.0, 0.248, 0.0, 0.003003003003003003]\n",
            "Node 494: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.745, 0.0, 0.002002002002002002]\n",
            "Node 495: [0.22536979341407973, 0, 0, 0.001, 0.002, 0.1532311792138574, 0.0, 0.249, 0.0, 0.003003003003003003]\n",
            "Node 496: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.746, 0.0, 0.002002002002002002]\n",
            "Node 497: [1.5713945022298272, 0, 0, 0.001, 0.002, 0.3322229624694648, 0.0, 0.25, 0.0, 0.003003003003003003]\n",
            "Node 498: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.747, 0.0, 0.002002002002002002]\n",
            "Node 499: [1.1434555051652675, 0, 0, 0.001, 0.002, 0.27531645569620256, 0.0, 0.251, 0.0, 0.003003003003003003]\n",
            "Node 500: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.748, 0.0, 0.002002002002002002]\n",
            "Node 501: [1.659487310406044, 0, 0, 0.001, 0.002, 0.3439373750832778, 0.0, 0.252, 0.0, 0.003003003003003003]\n",
            "Node 502: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.749, 0.0, 0.002002002002002002]\n",
            "Node 503: [0.8211443776200574, 0, 0, 0.001, 0.002, 0.2324561403508772, 0.0, 0.253, 0.0, 0.003003003003003003]\n",
            "Node 504: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.75, 0.0, 0.002002002002002002]\n",
            "Node 505: [1.7358900776868385, 0, 0, 0.001, 0.002, 0.35409726848767487, 0.0, 0.254, 0.0, 0.003003003003003003]\n",
            "Node 506: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.751, 0.0, 0.002002002002002002]\n",
            "Node 507: [1.161825569429502, 0, 0, 0.001, 0.002, 0.2777592715967133, 0.0, 0.255, 0.0, 0.003003003003003003]\n",
            "Node 508: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.752, 0.0, 0.002002002002002002]\n",
            "Node 509: [1.6290097037858366, 0, 0, 0.001, 0.002, 0.3398845214301577, 0.0, 0.256, 0.0, 0.003003003003003003]\n",
            "Node 510: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.753, 0.0, 0.002002002002002002]\n",
            "Node 511: [1.7642801770042924, 0, 0, 0.001, 0.002, 0.35787252942482795, 0.0, 0.257, 0.0, 0.003003003003003003]\n",
            "Node 512: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.754, 0.0, 0.002002002002002002]\n",
            "Node 513: [0.13226696771125365, 0, 0, 0.001, 0.002, 0.1408505440817233, 0.0, 0.258, 0.0, 0.003003003003003003]\n",
            "Node 514: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.755, 0.0, 0.002002002002002002]\n",
            "Node 515: [0.32056012641966, 0, 0, 0.001, 0.002, 0.16588940706195868, 0.0, 0.259, 0.0, 0.003003003003003003]\n",
            "Node 516: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.756, 0.0, 0.002002002002002002]\n",
            "Node 517: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.26, 0.0, 0.003003003003003003]\n",
            "Node 518: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.757, 0.0, 0.002002002002002002]\n",
            "Node 519: [0.028726605494657675, 0, 0, 0.001, 0.002, 0.1270819453697535, 0.0, 0.261, 0.0, 0.003003003003003003]\n",
            "Node 520: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.758, 0.0, 0.002002002002002002]\n",
            "Node 521: [1.3363411799397324, 0, 0, 0.001, 0.002, 0.30096602265156563, 0.0, 0.262, 0.0, 0.003003003003003003]\n",
            "Node 522: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.759, 0.0, 0.002002002002002002]\n",
            "Node 523: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.263, 0.0, 0.003003003003003003]\n",
            "Node 524: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.76, 0.0, 0.002002002002002002]\n",
            "Node 525: [1.0683052422661252, 0, 0, 0.001, 0.002, 0.26532311792138574, 0.0, 0.264, 0.0, 0.003003003003003003]\n",
            "Node 526: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.761, 0.0, 0.002002002002002002]\n",
            "Node 527: [1.5388293883068656, 0, 0, 0.001, 0.002, 0.32789251610037745, 0.0, 0.265, 0.0, 0.003003003003003003]\n",
            "Node 528: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.762, 0.0, 0.002002002002002002]\n",
            "Node 529: [0.547263419498739, 0, 0, 0.001, 0.002, 0.19603597601598932, 0.0, 0.266, 0.0, 0.003003003003003003]\n",
            "Node 530: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.763, 0.0, 0.002002002002002002]\n",
            "Node 531: [0.7756367184200212, 0, 0, 0.001, 0.002, 0.22640461914279367, 0.0, 0.267, 0.0, 0.003003003003003003]\n",
            "Node 532: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.764, 0.0, 0.002002002002002002]\n",
            "Node 533: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.268, 0.0, 0.003003003003003003]\n",
            "Node 534: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.765, 0.0, 0.002002002002002002]\n",
            "Node 535: [1.378926328915913, 0, 0, 0.001, 0.002, 0.30662891405729514, 0.0, 0.269, 0.0, 0.003003003003003003]\n",
            "Node 536: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.766, 0.0, 0.002002002002002002]\n",
            "Node 537: [0.8219793805411589, 0, 0, 0.001, 0.002, 0.23256717743726402, 0.0, 0.27, 0.0, 0.003003003003003003]\n",
            "Node 538: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.767, 0.0, 0.002002002002002002]\n",
            "Node 539: [0.578993530500599, 0, 0, 0.001, 0.002, 0.20025538529868972, 0.0, 0.271, 0.0, 0.003003003003003003]\n",
            "Node 540: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.768, 0.0, 0.002002002002002002]\n",
            "Node 541: [1.0916853240569693, 0, 0, 0.001, 0.002, 0.2684321563402176, 0.0, 0.272, 0.0, 0.003003003003003003]\n",
            "Node 542: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.769, 0.0, 0.002002002002002002]\n",
            "Node 543: [0.684621400019949, 0, 0, 0.001, 0.002, 0.21430157672662667, 0.0, 0.273, 0.0, 0.003003003003003003]\n",
            "Node 544: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.77, 0.0, 0.002002002002002002]\n",
            "Node 545: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.274, 0.0, 0.003003003003003003]\n",
            "Node 546: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.771, 0.0, 0.002002002002002002]\n",
            "Node 547: [0.5067657778253124, 0, 0, 0.001, 0.002, 0.19065067732622695, 0.0, 0.275, 0.0, 0.003003003003003003]\n",
            "Node 548: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.772, 0.0, 0.002002002002002002]\n",
            "Node 549: [0.3088700855242378, 0, 0, 0.001, 0.002, 0.16433488785254272, 0.0, 0.276, 0.0, 0.003003003003003003]\n",
            "Node 550: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.773, 0.0, 0.002002002002002002]\n",
            "Node 551: [0.9125771974806804, 0, 0, 0.001, 0.002, 0.24461470131023758, 0.0, 0.277, 0.0, 0.003003003003003003]\n",
            "Node 552: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.774, 0.0, 0.002002002002002002]\n",
            "Node 553: [0.599033600607037, 0, 0, 0.001, 0.002, 0.20292027537197424, 0.0, 0.278, 0.0, 0.003003003003003003]\n",
            "Node 554: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.775, 0.0, 0.002002002002002002]\n",
            "Node 555: [1.0340701225009605, 0, 0, 0.001, 0.002, 0.26077059737952474, 0.0, 0.279, 0.0, 0.003003003003003003]\n",
            "Node 556: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.776, 0.0, 0.002002002002002002]\n",
            "Node 557: [0.8662345353595428, 0, 0, 0.001, 0.002, 0.23845214301576725, 0.0, 0.28, 0.0, 0.003003003003003003]\n",
            "Node 558: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.777, 0.0, 0.002002002002002002]\n",
            "Node 559: [1.6912174214079043, 0, 0, 0.001, 0.002, 0.34815678436597824, 0.0, 0.281, 0.0, 0.003003003003003003]\n",
            "Node 560: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.778, 0.0, 0.002002002002002002]\n",
            "Node 561: [0.4516555850326081, 0, 0, 0.001, 0.002, 0.18332222962469466, 0.0, 0.282, 0.0, 0.003003003003003003]\n",
            "Node 562: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.779, 0.0, 0.002002002002002002]\n",
            "Node 563: [1.512109294831615, 0, 0, 0.001, 0.002, 0.3243393293359982, 0.0, 0.283, 0.0, 0.003003003003003003]\n",
            "Node 564: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.78, 0.0, 0.002002002002002002]\n",
            "Node 565: [0.9902324691431273, 0, 0, 0.001, 0.002, 0.25494115034421494, 0.0, 0.284, 0.0, 0.003003003003003003]\n",
            "Node 566: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.781, 0.0, 0.002002002002002002]\n",
            "Node 567: [-0.036821123811816396, 0, 0, 0.001, 0.002, 0.11836553408838552, 0.0, 0.285, 0.0, 0.003003003003003003]\n",
            "Node 568: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.782, 0.0, 0.002002002002002002]\n",
            "Node 569: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.286, 0.0, 0.003003003003003003]\n",
            "Node 570: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.783, 0.0, 0.002002002002002002]\n",
            "Node 571: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.287, 0.0, 0.003003003003003003]\n",
            "Node 572: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.784, 0.0, 0.002002002002002002]\n",
            "Node 573: [1.164330578192807, 0, 0, 0.001, 0.002, 0.2780923828558739, 0.0, 0.288, 0.0, 0.003003003003003003]\n",
            "Node 574: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.785, 0.0, 0.002002002002002002]\n",
            "Node 575: [0.07256425885249053, 0, 0, 0.001, 0.002, 0.13291139240506328, 0.0, 0.289, 0.0, 0.003003003003003003]\n",
            "Node 576: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.786, 0.0, 0.002002002002002002]\n",
            "Node 577: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.29, 0.0, 0.003003003003003003]\n",
            "Node 578: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.787, 0.0, 0.002002002002002002]\n",
            "Node 579: [1.6469622665895203, 0, 0, 0.001, 0.002, 0.34227181878747504, 0.0, 0.291, 0.0, 0.003003003003003003]\n",
            "Node 580: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.788, 0.0, 0.002002002002002002]\n",
            "Node 581: [1.3083685820828297, 0, 0, 0.001, 0.002, 0.297246280257606, 0.0, 0.292, 0.0, 0.003003003003003003]\n",
            "Node 582: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.789, 0.0, 0.002002002002002002]\n",
            "Node 583: [0.989397466222026, 0, 0, 0.001, 0.002, 0.2548301132578281, 0.0, 0.293, 0.0, 0.003003003003003003]\n",
            "Node 584: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.79, 0.0, 0.002002002002002002]\n",
            "Node 585: [0.12266443411858546, 0, 0, 0.001, 0.002, 0.1395736175882745, 0.0, 0.294, 0.0, 0.003003003003003003]\n",
            "Node 586: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.791, 0.0, 0.002002002002002002]\n",
            "Node 587: [1.1776906249304322, 0, 0, 0.001, 0.002, 0.2798689762380635, 0.0, 0.295, 0.0, 0.003003003003003003]\n",
            "Node 588: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.792, 0.0, 0.002002002002002002]\n",
            "Node 589: [-0.020121065389784847, 0, 0, 0.001, 0.002, 0.12058627581612258, 0.0, 0.296, 0.0, 0.003003003003003003]\n",
            "Node 590: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.793, 0.0, 0.002002002002002002]\n",
            "Node 591: [1.0503526794624412, 0, 0, 0.001, 0.002, 0.2629358205640684, 0.0, 0.297, 0.0, 0.003003003003003003]\n",
            "Node 592: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.794, 0.0, 0.002002002002002002]\n",
            "Node 593: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.298, 0.0, 0.003003003003003003]\n",
            "Node 594: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.795, 0.0, 0.002002002002002002]\n",
            "Node 595: [0.3113750942875426, 0, 0, 0.001, 0.002, 0.1646679991117033, 0.0, 0.299, 0.0, 0.003003003003003003]\n",
            "Node 596: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.796, 0.0, 0.002002002002002002]\n",
            "Node 597: [0.9831349443137639, 0, 0, 0.001, 0.002, 0.25399733510992667, 0.0, 0.3, 0.0, 0.003003003003003003]\n",
            "Node 598: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.797, 0.0, 0.002002002002002002]\n",
            "Node 599: [0.8591370105301792, 0, 0, 0.001, 0.002, 0.237508327781479, 0.0, 0.301, 0.0, 0.003003003003003003]\n",
            "Node 600: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.798, 0.0, 0.002002002002002002]\n",
            "Node 601: [0.6645813299135112, 0, 0, 0.001, 0.002, 0.2116366866533422, 0.0, 0.302, 0.0, 0.003003003003003003]\n",
            "Node 602: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.799, 0.0, 0.002002002002002002]\n",
            "Node 603: [1.3204761244388026, 0, 0, 0.001, 0.002, 0.2988563180102154, 0.0, 0.303, 0.0, 0.003003003003003003]\n",
            "Node 604: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.8, 0.0, 0.002002002002002002]\n",
            "Node 605: [0.8996346522036058, 0, 0, 0.001, 0.002, 0.24289362647124133, 0.0, 0.304, 0.0, 0.003003003003003003]\n",
            "Node 606: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.801, 0.0, 0.002002002002002002]\n",
            "Node 607: [1.1108903912423058, 0, 0, 0.001, 0.002, 0.2709860093271152, 0.0, 0.305, 0.0, 0.003003003003003003]\n",
            "Node 608: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.802, 0.0, 0.002002002002002002]\n",
            "Node 609: [0.47670567266565556, 0, 0, 0.001, 0.002, 0.18665334221630023, 0.0, 0.306, 0.0, 0.003003003003003003]\n",
            "Node 610: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.803, 0.0, 0.002002002002002002]\n",
            "Node 611: [0.5698084983684817, 0, 0, 0.001, 0.002, 0.19903397734843434, 0.0, 0.307, 0.0, 0.003003003003003003]\n",
            "Node 612: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.804, 0.0, 0.002002002002002002]\n",
            "Node 613: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.308, 0.0, 0.003003003003003003]\n",
            "Node 614: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.805, 0.0, 0.002002002002002002]\n",
            "Node 615: [0.740149094273204, 0, 0, 0.001, 0.002, 0.2216855429713524, 0.0, 0.309, 0.0, 0.003003003003003003]\n",
            "Node 616: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.806, 0.0, 0.002002002002002002]\n",
            "Node 617: [0.8077843308824322, 0, 0, 0.001, 0.002, 0.23067954696868756, 0.0, 0.31, 0.0, 0.003003003003003003]\n",
            "Node 618: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.807, 0.0, 0.002002002002002002]\n",
            "Node 619: [0.3886128644894389, 0, 0, 0.001, 0.002, 0.17493892960248722, 0.0, 0.311, 0.0, 0.003003003003003003]\n",
            "Node 620: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.808, 0.0, 0.002002002002002002]\n",
            "Node 621: [0.5664684866840753, 0, 0, 0.001, 0.002, 0.19858982900288696, 0.0, 0.312, 0.0, 0.003003003003003003]\n",
            "Node 622: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.809, 0.0, 0.002002002002002002]\n",
            "Node 623: [0.5718960056712358, 0, 0, 0.001, 0.002, 0.1993115700644015, 0.0, 0.313, 0.0, 0.003003003003003003]\n",
            "Node 624: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.81, 0.0, 0.002002002002002002]\n",
            "Node 625: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.314, 0.0, 0.003003003003003003]\n",
            "Node 626: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.811, 0.0, 0.002002002002002002]\n",
            "Node 627: [1.100452854728536, 0, 0, 0.001, 0.002, 0.2695980457472795, 0.0, 0.315, 0.0, 0.003003003003003003]\n",
            "Node 628: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 0.0, 0.812, 0.0, 0.002002002002002002]\n",
            "Node 629: [1.0336526210404096, 0, 0, 0.001, 0.002, 0.2607150788363313, 0.0, 0.316, 0.0, 0.003003003003003003]\n",
            "Node 630: [-0.915244196810679, 0, 0, 0.001, 0.001, 0.0015545192094159443, 0.0, 0.813, 0.0, 0.002002002002002002]\n",
            "Node 631: [1.573899510993132, 0, 0, 0.001, 0.002, 0.3325560737286254, 0.0, 0.317, 0.0, 0.003003003003003003]\n",
            "Node 632: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.814, 0.0, 0.002002002002002002]\n",
            "Node 633: [0.3652327826985945, 0, 0, 0.001, 0.002, 0.17182989118365533, 0.0, 0.318, 0.0, 0.003003003003003003]\n",
            "Node 634: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.815, 0.0, 0.002002002002002002]\n",
            "Node 635: [1.5872595577307578, 0, 0, 0.001, 0.002, 0.334332667110815, 0.0, 0.319, 0.0, 0.003003003003003003]\n",
            "Node 636: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.816, 0.0, 0.002002002002002002]\n",
            "Node 637: [0.34394020821050414, 0, 0, 0.001, 0.002, 0.16899844548079057, 0.0, 0.32, 0.0, 0.003003003003003003]\n",
            "Node 638: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.817, 0.0, 0.002002002002002002]\n",
            "Node 639: [0.4925707281665854, 0, 0, 0.001, 0.002, 0.1887630468576504, 0.0, 0.321, 0.0, 0.003003003003003003]\n",
            "Node 640: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.818, 0.0, 0.002002002002002002]\n",
            "Node 641: [1.1029578634918409, 0, 0, 0.001, 0.002, 0.2699311570064401, 0.0, 0.322, 0.0, 0.003003003003003003]\n",
            "Node 642: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.819, 0.0, 0.002002002002002002]\n",
            "Node 643: [0.5050957719831093, 0, 0, 0.001, 0.002, 0.19042860315345325, 0.0, 0.323, 0.0, 0.003003003003003003]\n",
            "Node 644: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.82, 0.0, 0.002002002002002002]\n",
            "Node 645: [0.039581643468978134, 0, 0, 0.001, 0.002, 0.12852542749278256, 0.0, 0.324, 0.0, 0.003003003003003003]\n",
            "Node 646: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.821, 0.0, 0.002002002002002002]\n",
            "Node 647: [1.221945779748816, 0, 0, 0.001, 0.002, 0.2857539418165667, 0.0, 0.325, 0.0, 0.003003003003003003]\n",
            "Node 648: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.822, 0.0, 0.002002002002002002]\n",
            "Node 649: [0.12391693850023773, 0, 0, 0.001, 0.002, 0.13974017321785473, 0.0, 0.326, 0.0, 0.003003003003003003]\n",
            "Node 650: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.823, 0.0, 0.002002002002002002]\n",
            "Node 651: [1.0111075421706668, 0, 0, 0.001, 0.002, 0.2577170775038863, 0.0, 0.327, 0.0, 0.003003003003003003]\n",
            "Node 652: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.824, 0.0, 0.002002002002002002]\n",
            "Node 653: [0.11974192389472993, 0, 0, 0.001, 0.002, 0.13918498778592048, 0.0, 0.328, 0.0, 0.003003003003003003]\n",
            "Node 654: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.825, 0.0, 0.002002002002002002]\n",
            "Node 655: [1.357633754427823, 0, 0, 0.001, 0.002, 0.3037974683544304, 0.0, 0.329, 0.0, 0.003003003003003003]\n",
            "Node 656: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.826, 0.0, 0.002002002002002002]\n",
            "Node 657: [0.35521274764537564, 0, 0, 0.001, 0.002, 0.1704974461470131, 0.0, 0.33, 0.0, 0.003003003003003003]\n",
            "Node 658: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.827, 0.0, 0.002002002002002002]\n",
            "Node 659: [0.9785424282477052, 0, 0, 0.001, 0.002, 0.253386631134799, 0.0, 0.331, 0.0, 0.003003003003003003]\n",
            "Node 660: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.828, 0.0, 0.002002002002002002]\n",
            "Node 661: [1.219858272446062, 0, 0, 0.001, 0.002, 0.2854763491005996, 0.0, 0.332, 0.0, 0.003003003003003003]\n",
            "Node 662: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.829, 0.0, 0.002002002002002002]\n",
            "Node 663: [0.9372097836531772, 0, 0, 0.001, 0.002, 0.24789029535864981, 0.0, 0.333, 0.0, 0.003003003003003003]\n",
            "Node 664: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.83, 0.0, 0.002002002002002002]\n",
            "Node 665: [0.45499559671701434, 0, 0, 0.001, 0.002, 0.18376637797024203, 0.0, 0.334, 0.0, 0.003003003003003003]\n",
            "Node 666: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.831, 0.0, 0.002002002002002002]\n",
            "Node 667: [0.23789483723060348, 0, 0, 0.001, 0.002, 0.1548967355096602, 0.0, 0.335, 0.0, 0.003003003003003003]\n",
            "Node 668: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.832, 0.0, 0.002002002002002002]\n",
            "Node 669: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.336, 0.0, 0.003003003003003003]\n",
            "Node 670: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.833, 0.0, 0.002002002002002002]\n",
            "Node 671: [0.6245011897006353, 0, 0, 0.001, 0.002, 0.20630690650677325, 0.0, 0.337, 0.0, 0.003003003003003003]\n",
            "Node 672: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.834, 0.0, 0.002002002002002002]\n",
            "Node 673: [-0.03264610920630858, 0, 0, 0.001, 0.002, 0.11892071952031977, 0.0, 0.338, 0.0, 0.003003003003003003]\n",
            "Node 674: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.835, 0.0, 0.002002002002002002]\n",
            "Node 675: [1.0098550377890145, 0, 0, 0.001, 0.002, 0.257550521874306, 0.0, 0.339, 0.0, 0.003003003003003003]\n",
            "Node 676: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.836, 0.0, 0.002002002002002002]\n",
            "Node 677: [1.6528072870372315, 0, 0, 0.001, 0.002, 0.343049078392183, 0.0, 0.34, 0.0, 0.003003003003003003]\n",
            "Node 678: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.837, 0.0, 0.002002002002002002]\n",
            "Node 679: [1.5000017524756424, 0, 0, 0.001, 0.002, 0.3227292915833888, 0.0, 0.341, 0.0, 0.003003003003003003]\n",
            "Node 680: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.838, 0.0, 0.002002002002002002]\n",
            "Node 681: [0.44163554997938903, 0, 0, 0.001, 0.002, 0.18198978458805237, 0.0, 0.342, 0.0, 0.003003003003003003]\n",
            "Node 682: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.839, 0.0, 0.002002002002002002]\n",
            "Node 683: [0.4733656609812493, 0, 0, 0.001, 0.002, 0.18620919387075283, 0.0, 0.343, 0.0, 0.003003003003003003]\n",
            "Node 684: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.84, 0.0, 0.002002002002002002]\n",
            "Node 685: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.344, 0.0, 0.003003003003003003]\n",
            "Node 686: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.841, 0.0, 0.002002002002002002]\n",
            "Node 687: [0.39612789077935306, 0, 0, 0.001, 0.002, 0.1759382633799689, 0.0, 0.345, 0.0, 0.003003003003003003]\n",
            "Node 688: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.842, 0.0, 0.002002002002002002]\n",
            "Node 689: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.346, 0.0, 0.003003003003003003]\n",
            "Node 690: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.843, 0.0, 0.002002002002002002]\n",
            "Node 691: [0.9029746638880124, 0, 0, 0.001, 0.002, 0.2433377748167888, 0.0, 0.347, 0.0, 0.003003003003003003]\n",
            "Node 692: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.844, 0.0, 0.002002002002002002]\n",
            "Node 693: [0.36565028415914536, 0, 0, 0.001, 0.002, 0.17188540972684876, 0.0, 0.348, 0.0, 0.003003003003003003]\n",
            "Node 694: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.845, 0.0, 0.002002002002002002]\n",
            "Node 695: [1.5396643912279675, 0, 0, 0.001, 0.002, 0.3280035531867644, 0.0, 0.349, 0.0, 0.003003003003003003]\n",
            "Node 696: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.846, 0.0, 0.002002002002002002]\n",
            "Node 697: [0.8745845645705587, 0, 0, 0.001, 0.002, 0.2395625138796358, 0.0, 0.35, 0.0, 0.003003003003003003]\n",
            "Node 698: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.847, 0.0, 0.002002002002002002]\n",
            "Node 699: [0.7209440270878679, 0, 0, 0.001, 0.002, 0.21913168998445479, 0.0, 0.351, 0.0, 0.003003003003003003]\n",
            "Node 700: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.848, 0.0, 0.002002002002002002]\n",
            "Node 701: [0.007851532467118165, 0, 0, 0.001, 0.002, 0.12430601821008216, 0.0, 0.352, 0.0, 0.003003003003003003]\n",
            "Node 702: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.849, 0.0, 0.002002002002002002]\n",
            "Node 703: [1.3755863172315068, 0, 0, 0.001, 0.002, 0.30618476571174774, 0.0, 0.353, 0.0, 0.003003003003003003]\n",
            "Node 704: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.85, 0.0, 0.002002002002002002]\n",
            "Node 705: [0.45290808941426053, 0, 0, 0.001, 0.002, 0.18348878525427492, 0.0, 0.354, 0.0, 0.003003003003003003]\n",
            "Node 706: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.851, 0.0, 0.002002002002002002]\n",
            "Node 707: [0.7518391351686261, 0, 0, 0.001, 0.002, 0.22324006218076836, 0.0, 0.355, 0.0, 0.003003003003003003]\n",
            "Node 708: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.852, 0.0, 0.002002002002002002]\n",
            "Node 709: [1.6369422315363016, 0, 0, 0.001, 0.002, 0.3409393737508328, 0.0, 0.356, 0.0, 0.003003003003003003]\n",
            "Node 710: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.853, 0.0, 0.002002002002002002]\n",
            "Node 711: [0.36189277101418826, 0, 0, 0.001, 0.002, 0.17138574283810792, 0.0, 0.357, 0.0, 0.003003003003003003]\n",
            "Node 712: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.854, 0.0, 0.002002002002002002]\n",
            "Node 713: [1.6056296219949924, 0, 0, 0.001, 0.002, 0.33677548301132576, 0.0, 0.358, 0.0, 0.003003003003003003]\n",
            "Node 714: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 0.0, 0.855, 0.0, 0.002002002002002002]\n",
            "Node 715: [0.9935724808275336, 0, 0, 0.001, 0.002, 0.25538529868976234, 0.0, 0.359, 0.0, 0.003003003003003003]\n",
            "Node 716: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.856, 0.0, 0.002002002002002002]\n",
            "Node 717: [1.4027239121673083, 0, 0, 0.001, 0.002, 0.3097934710193205, 0.0, 0.36, 0.0, 0.003003003003003003]\n",
            "Node 718: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.857, 0.0, 0.002002002002002002]\n",
            "Node 719: [1.4603391137233173, 0, 0, 0.001, 0.002, 0.3174550299800133, 0.0, 0.361, 0.0, 0.003003003003003003]\n",
            "Node 720: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.858, 0.0, 0.002002002002002002]\n",
            "Node 721: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 0.0, 0.362, 0.0, 0.003003003003003003]\n",
            "Node 722: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.859, 0.0, 0.002002002002002002]\n",
            "Node 723: [0.2282923036379353, 0, 0, 0.001, 0.002, 0.1536198090162114, 0.0, 0.363, 0.0, 0.003003003003003003]\n",
            "Node 724: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 0.0, 0.86, 0.0, 0.002002002002002002]\n",
            "Node 725: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 0.0, 0.364, 0.0, 0.003003003003003003]\n",
            "Node 726: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.861, 0.0, 0.002002002002002002]\n",
            "Node 727: [0.9777074253266038, 0, 0, 0.001, 0.002, 0.25327559404841216, 0.0, 0.365, 0.0, 0.003003003003003003]\n",
            "Node 728: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.862, 0.0, 0.002002002002002002]\n",
            "Node 729: [0.5046782705225585, 0, 0, 0.001, 0.002, 0.19037308461025984, 0.0, 0.366, 0.0, 0.003003003003003003]\n",
            "Node 730: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 0.0, 0.863, 0.0, 0.002002002002002002]\n",
            "Node 731: [0.925102241297204, 0, 0, 0.001, 0.002, 0.2462802576060404, 0.0, 0.367, 0.0, 0.003003003003003003]\n",
            "Node 732: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.864, 0.0, 0.002002002002002002]\n",
            "Node 733: [1.5751520153747844, 0, 0, 0.001, 0.002, 0.3327226293582056, 0.0, 0.368, 0.0, 0.003003003003003003]\n",
            "Node 734: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.865, 0.0, 0.002002002002002002]\n",
            "Node 735: [3.959085355119796, 0, 0, 0.0, 0.132, 0.6497335109926716, 0.0, 0.003, 0.0, 0.13213213213213212]\n",
            "Node 736: [1.0428376531725267, 0, 0, 0.001, 0.002, 0.2619364867865867, 0.0, 0.369, 0.0, 0.003003003003003003]\n",
            "Node 737: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.866, 0.0, 0.002002002002002002]\n",
            "Node 738: [0.6457937641887255, 0, 0, 0.001, 0.002, 0.209138352209638, 0.0, 0.37, 0.0, 0.003003003003003003]\n",
            "Node 739: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.867, 0.0, 0.002002002002002002]\n",
            "Node 740: [1.0361576298037143, 0, 0, 0.001, 0.002, 0.2610481900954919, 0.0, 0.371, 0.0, 0.003003003003003003]\n",
            "Node 741: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.868, 0.0, 0.002002002002002002]\n",
            "Node 742: [0.32682264832792174, 0, 0, 0.001, 0.002, 0.16672218520986007, 0.0, 0.372, 0.0, 0.003003003003003003]\n",
            "Node 743: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.869, 0.0, 0.002002002002002002]\n",
            "Node 744: [0.6182386677923735, 0, 0, 0.001, 0.002, 0.20547412835887185, 0.0, 0.373, 0.0, 0.003003003003003003]\n",
            "Node 745: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.87, 0.0, 0.002002002002002002]\n",
            "Node 746: [0.24791487228382253, 0, 0, 0.001, 0.002, 0.15622918054630247, 0.0, 0.374, 0.0, 0.003003003003003003]\n",
            "Node 747: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.871, 0.0, 0.002002002002002002]\n",
            "Node 748: [1.7116749929748927, 0, 0, 0.001, 0.002, 0.3508771929824561, 0.0, 0.375, 0.0, 0.003003003003003003]\n",
            "Node 749: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.872, 0.0, 0.002002002002002002]\n",
            "Node 750: [0.10888688592040931, 0, 0, 0.001, 0.002, 0.1377415056628914, 0.0, 0.376, 0.0, 0.003003003003003003]\n",
            "Node 751: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.873, 0.0, 0.002002002002002002]\n",
            "Node 752: [-0.012188537639319782, 0, 0, 0.001, 0.002, 0.12164112813679767, 0.0, 0.377, 0.0, 0.003003003003003003]\n",
            "Node 753: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.874, 0.0, 0.002002002002002002]\n",
            "Node 754: [0.49507573692989026, 0, 0, 0.001, 0.002, 0.189096158116811, 0.0, 0.378, 0.0, 0.003003003003003003]\n",
            "Node 755: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.875, 0.0, 0.002002002002002002]\n",
            "Node 756: [1.5250518401086897, 0, 0, 0.001, 0.002, 0.32606040417499443, 0.0, 0.379, 0.0, 0.003003003003003003]\n",
            "Node 757: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.876, 0.0, 0.002002002002002002]\n",
            "Node 758: [1.0378276356459175, 0, 0, 0.001, 0.002, 0.26127026426826555, 0.0, 0.38, 0.0, 0.003003003003003003]\n",
            "Node 759: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.877, 0.0, 0.002002002002002002]\n",
            "Node 760: [0.22453479049297817, 0, 0, 0.001, 0.002, 0.15312014212747055, 0.0, 0.381, 0.0, 0.003003003003003003]\n",
            "Node 761: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.878, 0.0, 0.002002002002002002]\n",
            "Node 762: [0.30260756361597596, 0, 0, 0.001, 0.002, 0.16350210970464132, 0.0, 0.382, 0.0, 0.003003003003003003]\n",
            "Node 763: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.879, 0.0, 0.002002002002002002]\n",
            "Node 764: [0.7985992987503149, 0, 0, 0.001, 0.002, 0.22945813901843218, 0.0, 0.383, 0.0, 0.003003003003003003]\n",
            "Node 765: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.88, 0.0, 0.002002002002002002]\n",
            "Node 766: [1.576822021216988, 0, 0, 0.001, 0.002, 0.3329447035309793, 0.0, 0.384, 0.0, 0.003003003003003003]\n",
            "Node 767: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.881, 0.0, 0.002002002002002002]\n",
            "Node 768: [1.7254525411730688, 0, 0, 0.001, 0.002, 0.3527093049078392, 0.0, 0.385, 0.0, 0.003003003003003003]\n",
            "Node 769: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.882, 0.0, 0.002002002002002002]\n",
            "Node 770: [0.8541269930035699, 0, 0, 0.001, 0.002, 0.23684210526315788, 0.0, 0.386, 0.0, 0.003003003003003003]\n",
            "Node 771: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.883, 0.0, 0.002002002002002002]\n",
            "Node 772: [0.6675038401373667, 0, 0, 0.001, 0.002, 0.2120253164556962, 0.0, 0.387, 0.0, 0.003003003003003003]\n",
            "Node 773: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.884, 0.0, 0.002002002002002002]\n",
            "Node 774: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.388, 0.0, 0.003003003003003003]\n",
            "Node 775: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.885, 0.0, 0.002002002002002002]\n",
            "Node 776: [1.281230987147028, 0, 0, 0.001, 0.002, 0.2936375749500333, 0.0, 0.389, 0.0, 0.003003003003003003]\n",
            "Node 777: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.886, 0.0, 0.002002002002002002]\n",
            "Node 778: [0.7334690709043915, 0, 0, 0.001, 0.002, 0.2207972462802576, 0.0, 0.39, 0.0, 0.003003003003003003]\n",
            "Node 779: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.887, 0.0, 0.002002002002002002]\n",
            "Node 780: [0.8816820893999219, 0, 0, 0.001, 0.002, 0.240506329113924, 0.0, 0.391, 0.0, 0.003003003003003003]\n",
            "Node 781: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.888, 0.0, 0.002002002002002002]\n",
            "Node 782: [1.0812477875431996, 0, 0, 0.001, 0.002, 0.26704419276038194, 0.0, 0.392, 0.0, 0.003003003003003003]\n",
            "Node 783: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.889, 0.0, 0.002002002002002002]\n",
            "Node 784: [0.6829513941777459, 0, 0, 0.001, 0.002, 0.21407950255385297, 0.0, 0.393, 0.0, 0.003003003003003003]\n",
            "Node 785: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.89, 0.0, 0.002002002002002002]\n",
            "Node 786: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 0.0, 0.394, 0.0, 0.003003003003003003]\n",
            "Node 787: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.891, 0.0, 0.002002002002002002]\n",
            "Node 788: [1.3709938011654481, 0, 0, 0.001, 0.002, 0.30557406173662005, 0.0, 0.395, 0.0, 0.003003003003003003]\n",
            "Node 789: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.892, 0.0, 0.002002002002002002]\n",
            "Node 790: [1.60437711761334, 0, 0, 0.001, 0.002, 0.33660892738174547, 0.0, 0.396, 0.0, 0.003003003003003003]\n",
            "Node 791: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.893, 0.0, 0.002002002002002002]\n",
            "Node 792: [0.23079731240124013, 0, 0, 0.001, 0.002, 0.15395292027537197, 0.0, 0.397, 0.0, 0.003003003003003003]\n",
            "Node 793: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.894, 0.0, 0.002002002002002002]\n",
            "Node 794: [0.3639802783169421, 0, 0, 0.001, 0.002, 0.17166333555407504, 0.0, 0.398, 0.0, 0.003003003003003003]\n",
            "Node 795: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.895, 0.0, 0.002002002002002002]\n",
            "Node 796: [1.6857899024207441, 0, 0, 0.001, 0.002, 0.3474350433044637, 0.0, 0.399, 0.0, 0.003003003003003003]\n",
            "Node 797: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.896, 0.0, 0.002002002002002002]\n",
            "Node 798: [0.6487162744125811, 0, 0, 0.001, 0.002, 0.209526982011992, 0.0, 0.4, 0.0, 0.003003003003003003]\n",
            "Node 799: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.897, 0.0, 0.002002002002002002]\n",
            "Node 800: [0.015784060217583083, 0, 0, 0.001, 0.002, 0.12536087053075726, 0.0, 0.401, 0.0, 0.003003003003003003]\n",
            "Node 801: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.898, 0.0, 0.002002002002002002]\n",
            "Node 802: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.402, 0.0, 0.003003003003003003]\n",
            "Node 803: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.899, 0.0, 0.002002002002002002]\n",
            "Node 804: [0.2792274818251318, 0, 0, 0.001, 0.002, 0.16039307128580946, 0.0, 0.403, 0.0, 0.003003003003003003]\n",
            "Node 805: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.9, 0.0, 0.002002002002002002]\n",
            "Node 806: [0.31930762203800755, 0, 0, 0.001, 0.002, 0.1657228514323784, 0.0, 0.404, 0.0, 0.003003003003003003]\n",
            "Node 807: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.901, 0.0, 0.002002002002002002]\n",
            "Node 808: [1.6123096453638048, 0, 0, 0.001, 0.002, 0.33766377970242056, 0.0, 0.405, 0.0, 0.003003003003003003]\n",
            "Node 809: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.902, 0.0, 0.002002002002002002]\n",
            "Node 810: [0.621161178016229, 0, 0, 0.001, 0.002, 0.20586275816122587, 0.0, 0.406, 0.0, 0.003003003003003003]\n",
            "Node 811: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.903, 0.0, 0.002002002002002002]\n",
            "Node 812: [0.9280247515210596, 0, 0, 0.001, 0.002, 0.24666888740839438, 0.0, 0.407, 0.0, 0.003003003003003003]\n",
            "Node 813: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.904, 0.0, 0.002002002002002002]\n",
            "Node 814: [0.9397147924164817, 0, 0, 0.001, 0.002, 0.24822340661781034, 0.0, 0.408, 0.0, 0.003003003003003003]\n",
            "Node 815: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.905, 0.0, 0.002002002002002002]\n",
            "Node 816: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.409, 0.0, 0.003003003003003003]\n",
            "Node 817: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.906, 0.0, 0.002002002002002002]\n",
            "Node 818: [1.570977000769277, 0, 0, 0.001, 0.002, 0.3321674439262714, 0.0, 0.41, 0.0, 0.003003003003003003]\n",
            "Node 819: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.907, 0.0, 0.002002002002002002]\n",
            "Node 820: [1.1989831994185225, 0, 0, 0.001, 0.002, 0.28270042194092826, 0.0, 0.411, 0.0, 0.003003003003003003]\n",
            "Node 821: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.908, 0.0, 0.002002002002002002]\n",
            "Node 822: [1.1117253941634075, 0, 0, 0.001, 0.002, 0.27109704641350213, 0.0, 0.412, 0.0, 0.003003003003003003]\n",
            "Node 823: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.909, 0.0, 0.002002002002002002]\n",
            "Node 824: [0.9121596960201297, 0, 0, 0.001, 0.002, 0.2445591827670442, 0.0, 0.413, 0.0, 0.003003003003003003]\n",
            "Node 825: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.91, 0.0, 0.002002002002002002]\n",
            "Node 826: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 0.0, 0.414, 0.0, 0.003003003003003003]\n",
            "Node 827: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.911, 0.0, 0.002002002002002002]\n",
            "Node 828: [1.1985656979579717, 0, 0, 0.001, 0.002, 0.2826449033977348, 0.0, 0.415, 0.0, 0.003003003003003003]\n",
            "Node 829: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.912, 0.0, 0.002002002002002002]\n",
            "Node 830: [0.4929882296271364, 0, 0, 0.001, 0.002, 0.18881856540084388, 0.0, 0.416, 0.0, 0.003003003003003003]\n",
            "Node 831: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.913, 0.0, 0.002002002002002002]\n",
            "Node 832: [0.9626773727467753, 0, 0, 0.001, 0.002, 0.2512769264934488, 0.0, 0.417, 0.0, 0.003003003003003003]\n",
            "Node 833: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.914, 0.0, 0.002002002002002002]\n",
            "Node 834: [0.6203261750951273, 0, 0, 0.001, 0.002, 0.20575172107483897, 0.0, 0.418, 0.0, 0.003003003003003003]\n",
            "Node 835: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.915, 0.0, 0.002002002002002002]\n",
            "Node 836: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 0.0, 0.419, 0.0, 0.003003003003003003]\n",
            "Node 837: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.916, 0.0, 0.002002002002002002]\n",
            "Node 838: [0.09552683918278401, 0, 0, 0.001, 0.002, 0.13596491228070176, 0.0, 0.42, 0.0, 0.003003003003003003]\n",
            "Node 839: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.917, 0.0, 0.002002002002002002]\n",
            "Node 840: [1.2315483133414842, 0, 0, 0.001, 0.002, 0.2870308683100155, 0.0, 0.421, 0.0, 0.003003003003003003]\n",
            "Node 841: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.918, 0.0, 0.002002002002002002]\n",
            "Node 842: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.422, 0.0, 0.003003003003003003]\n",
            "Node 843: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.919, 0.0, 0.002002002002002002]\n",
            "Node 844: [0.7272065489961297, 0, 0, 0.001, 0.002, 0.2199644681323562, 0.0, 0.423, 0.0, 0.003003003003003003]\n",
            "Node 845: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.92, 0.0, 0.002002002002002002]\n",
            "Node 846: [1.1209104262955247, 0, 0, 0.001, 0.002, 0.2723184543637575, 0.0, 0.424, 0.0, 0.003003003003003003]\n",
            "Node 847: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.921, 0.0, 0.002002002002002002]\n",
            "Node 848: [1.6895474155657009, 0, 0, 0.001, 0.002, 0.3479347101932045, 0.0, 0.425, 0.0, 0.003003003003003003]\n",
            "Node 849: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.922, 0.0, 0.002002002002002002]\n",
            "Node 850: [0.5134458011941249, 0, 0, 0.001, 0.002, 0.19153897401732176, 0.0, 0.426, 0.0, 0.003003003003003003]\n",
            "Node 851: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.923, 0.0, 0.002002002002002002]\n",
            "Node 852: [0.20741723061039577, 0, 0, 0.001, 0.002, 0.15084388185654007, 0.0, 0.427, 0.0, 0.003003003003003003]\n",
            "Node 853: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.924, 0.0, 0.002002002002002002]\n",
            "Node 854: [1.2833184944497822, 0, 0, 0.001, 0.002, 0.2939151676660004, 0.0, 0.428, 0.0, 0.003003003003003003]\n",
            "Node 855: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.925, 0.0, 0.002002002002002002]\n",
            "Node 856: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 0.0, 0.429, 0.0, 0.003003003003003003]\n",
            "Node 857: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.926, 0.0, 0.002002002002002002]\n",
            "Node 858: [0.7990168002108655, 0, 0, 0.001, 0.002, 0.22951365756162556, 0.0, 0.43, 0.0, 0.003003003003003003]\n",
            "Node 859: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.927, 0.0, 0.002002002002002002]\n",
            "Node 860: [1.4941567320279312, 0, 0, 0.001, 0.002, 0.3219520319786809, 0.0, 0.431, 0.0, 0.003003003003003003]\n",
            "Node 861: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.928, 0.0, 0.002002002002002002]\n",
            "Node 862: [1.3914513727324365, 0, 0, 0.001, 0.002, 0.3082944703530979, 0.0, 0.432, 0.0, 0.003003003003003003]\n",
            "Node 863: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.929, 0.0, 0.002002002002002002]\n",
            "Node 864: [1.1676705898772133, 0, 0, 0.001, 0.002, 0.27853653120142124, 0.0, 0.433, 0.0, 0.003003003003003003]\n",
            "Node 865: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.93, 0.0, 0.002002002002002002]\n",
            "Node 866: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.434, 0.0, 0.003003003003003003]\n",
            "Node 867: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.931, 0.0, 0.002002002002002002]\n",
            "Node 868: [0.04876667560109562, 0, 0, 0.001, 0.002, 0.12974683544303797, 0.0, 0.435, 0.0, 0.003003003003003003]\n",
            "Node 869: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.932, 0.0, 0.002002002002002002]\n",
            "Node 870: [1.5041767670811501, 0, 0, 0.001, 0.002, 0.3232844770153231, 0.0, 0.436, 0.0, 0.003003003003003003]\n",
            "Node 871: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.933, 0.0, 0.002002002002002002]\n",
            "Node 872: [1.6248346891803285, 0, 0, 0.001, 0.002, 0.33932933599822335, 0.0, 0.437, 0.0, 0.003003003003003003]\n",
            "Node 873: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.934, 0.0, 0.002002002002002002]\n",
            "Node 874: [0.8537094915430191, 0, 0, 0.001, 0.002, 0.2367865867199645, 0.0, 0.438, 0.0, 0.003003003003003003]\n",
            "Node 875: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.935, 0.0, 0.002002002002002002]\n",
            "Node 876: [0.8729145587283552, 0, 0, 0.001, 0.002, 0.23934043970686206, 0.0, 0.439, 0.0, 0.003003003003003003]\n",
            "Node 877: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.936, 0.0, 0.002002002002002002]\n",
            "Node 878: [1.5772395226775384, 0, 0, 0.001, 0.002, 0.33300022207417274, 0.0, 0.44, 0.0, 0.003003003003003003]\n",
            "Node 879: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.937, 0.0, 0.002002002002002002]\n",
            "Node 880: [1.1626605723506038, 0, 0, 0.001, 0.002, 0.27787030868310014, 0.0, 0.441, 0.0, 0.003003003003003003]\n",
            "Node 881: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.938, 0.0, 0.002002002002002002]\n",
            "Node 882: [0.5443409092748834, 0, 0, 0.001, 0.002, 0.19564734621363536, 0.0, 0.442, 0.0, 0.003003003003003003]\n",
            "Node 883: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.939, 0.0, 0.002002002002002002]\n",
            "Node 884: [1.5567819511105498, 0, 0, 0.001, 0.002, 0.33027981345769486, 0.0, 0.443, 0.0, 0.003003003003003003]\n",
            "Node 885: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.94, 0.0, 0.002002002002002002]\n",
            "Node 886: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.444, 0.0, 0.003003003003003003]\n",
            "Node 887: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.941, 0.0, 0.002002002002002002]\n",
            "Node 888: [0.17693962399018806, 0, 0, 0.001, 0.002, 0.14679102820341994, 0.0, 0.445, 0.0, 0.003003003003003003]\n",
            "Node 889: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.942, 0.0, 0.002002002002002002]\n",
            "Node 890: [0.555195947249204, 0, 0, 0.001, 0.002, 0.19709082833666441, 0.0, 0.446, 0.0, 0.003003003003003003]\n",
            "Node 891: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.943, 0.0, 0.002002002002002002]\n",
            "Node 892: [0.8169693630145495, 0, 0, 0.001, 0.002, 0.23190095491894291, 0.0, 0.447, 0.0, 0.003003003003003003]\n",
            "Node 893: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.944, 0.0, 0.002002002002002002]\n",
            "Node 894: [0.15564704950209785, 0, 0, 0.001, 0.002, 0.14395958250055516, 0.0, 0.448, 0.0, 0.003003003003003003]\n",
            "Node 895: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.945, 0.0, 0.002002002002002002]\n",
            "Node 896: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.449, 0.0, 0.003003003003003003]\n",
            "Node 897: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.946, 0.0, 0.002002002002002002]\n",
            "Node 898: [0.8921196259136916, 0, 0, 0.001, 0.002, 0.24189429269375967, 0.0, 0.45, 0.0, 0.003003003003003003]\n",
            "Node 899: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.947, 0.0, 0.002002002002002002]\n",
            "Node 900: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.451, 0.0, 0.003003003003003003]\n",
            "Node 901: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.948, 0.0, 0.002002002002002002]\n",
            "Node 902: [0.05795170773321296, 0, 0, 0.001, 0.002, 0.13096824339329335, 0.0, 0.452, 0.0, 0.003003003003003003]\n",
            "Node 903: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.949, 0.0, 0.002002002002002002]\n",
            "Node 904: [1.1835356453781434, 0, 0, 0.001, 0.002, 0.2806462358427715, 0.0, 0.453, 0.0, 0.003003003003003003]\n",
            "Node 905: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.95, 0.0, 0.002002002002002002]\n",
            "Node 906: [1.3530412383617638, 0, 0, 0.001, 0.002, 0.30318676437930264, 0.0, 0.454, 0.0, 0.003003003003003003]\n",
            "Node 907: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.951, 0.0, 0.002002002002002002]\n",
            "Node 908: [-0.03306361066685929, 0, 0, 0.001, 0.002, 0.11886520097712634, 0.0, 0.455, 0.0, 0.003003003003003003]\n",
            "Node 909: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.952, 0.0, 0.002002002002002002]\n",
            "Node 910: [0.9188397193889423, 0, 0, 0.001, 0.002, 0.245447479458139, 0.0, 0.456, 0.0, 0.003003003003003003]\n",
            "Node 911: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.953, 0.0, 0.002002002002002002]\n",
            "Node 912: [1.5087692831472088, 0, 0, 0.001, 0.002, 0.32389518099045084, 0.0, 0.457, 0.0, 0.003003003003003003]\n",
            "Node 913: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.954, 0.0, 0.002002002002002002]\n",
            "Node 914: [1.7605226638593352, 0, 0, 0.001, 0.002, 0.357372862536087, 0.0, 0.458, 0.0, 0.003003003003003003]\n",
            "Node 915: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.955, 0.0, 0.002002002002002002]\n",
            "Node 916: [0.11514940782867125, 0, 0, 0.001, 0.002, 0.1385742838107928, 0.0, 0.459, 0.0, 0.003003003003003003]\n",
            "Node 917: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.956, 0.0, 0.002002002002002002]\n",
            "Node 918: [0.9726974077999941, 0, 0, 0.001, 0.002, 0.252609371530091, 0.0, 0.46, 0.0, 0.003003003003003003]\n",
            "Node 919: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.957, 0.0, 0.002002002002002002]\n",
            "Node 920: [0.3869428586472357, 0, 0, 0.001, 0.002, 0.17471685542971352, 0.0, 0.461, 0.0, 0.003003003003003003]\n",
            "Node 921: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.958, 0.0, 0.002002002002002002]\n",
            "Node 922: [0.7915017739209513, 0, 0, 0.001, 0.002, 0.22851432378414388, 0.0, 0.462, 0.0, 0.003003003003003003]\n",
            "Node 923: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.959, 0.0, 0.002002002002002002]\n",
            "Node 924: [1.0065150261046083, 0, 0, 0.001, 0.002, 0.25710637352875854, 0.0, 0.463, 0.0, 0.003003003003003003]\n",
            "Node 925: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.96, 0.0, 0.002002002002002002]\n",
            "Node 926: [1.4586691078811138, 0, 0, 0.001, 0.002, 0.3172329558072396, 0.0, 0.464, 0.0, 0.003003003003003003]\n",
            "Node 927: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.961, 0.0, 0.002002002002002002]\n",
            "Node 928: [1.7546776434116242, 0, 0, 0.001, 0.002, 0.35659560293137904, 0.0, 0.465, 0.0, 0.003003003003003003]\n",
            "Node 929: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.962, 0.0, 0.002002002002002002]\n",
            "Node 930: [0.750169129326423, 0, 0, 0.001, 0.002, 0.22301798800799466, 0.0, 0.466, 0.0, 0.003003003003003003]\n",
            "Node 931: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.963, 0.0, 0.002002002002002002]\n",
            "Node 932: [0.4842206989555698, 0, 0, 0.001, 0.002, 0.18765267599378194, 0.0, 0.467, 0.0, 0.003003003003003003]\n",
            "Node 933: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.964, 0.0, 0.002002002002002002]\n",
            "Node 934: [0.1548120465809963, 0, 0, 0.001, 0.002, 0.1438485454141683, 0.0, 0.468, 0.0, 0.003003003003003003]\n",
            "Node 935: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.965, 0.0, 0.002002002002002002]\n",
            "Node 936: [0.8854396025448791, 0, 0, 0.001, 0.002, 0.24100599600266487, 0.0, 0.469, 0.0, 0.003003003003003003]\n",
            "Node 937: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.966, 0.0, 0.002002002002002002]\n",
            "Node 938: [0.7180215168640124, 0, 0, 0.001, 0.002, 0.21874306018210082, 0.0, 0.47, 0.0, 0.003003003003003003]\n",
            "Node 939: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.967, 0.0, 0.002002002002002002]\n",
            "Node 940: [0.24165235037556057, 0, 0, 0.001, 0.002, 0.15539640239840105, 0.0, 0.471, 0.0, 0.003003003003003003]\n",
            "Node 941: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.968, 0.0, 0.002002002002002002]\n",
            "Node 942: [1.173933111785475, 0, 0, 0.001, 0.002, 0.27936930934932264, 0.0, 0.472, 0.0, 0.003003003003003003]\n",
            "Node 943: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.969, 0.0, 0.002002002002002002]\n",
            "Node 944: [0.9488998245485991, 0, 0, 0.001, 0.002, 0.24944481456806572, 0.0, 0.473, 0.0, 0.003003003003003003]\n",
            "Node 945: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.97, 0.0, 0.002002002002002002]\n",
            "Node 946: [0.8190568703173033, 0, 0, 0.001, 0.002, 0.23217854763491003, 0.0, 0.474, 0.0, 0.003003003003003003]\n",
            "Node 947: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.971, 0.0, 0.002002002002002002]\n",
            "Node 948: [0.7898317680787482, 0, 0, 0.001, 0.002, 0.22829224961137018, 0.0, 0.475, 0.0, 0.003003003003003003]\n",
            "Node 949: [-0.8910291120987331, 0, 0, 0.001, 0.001, 0.0047745947146346866, 0.0, 0.972, 0.0, 0.002002002002002002]\n",
            "Node 950: [0.8649820309778903, 0, 0, 0.001, 0.002, 0.23828558738618696, 0.0, 0.476, 0.0, 0.003003003003003003]\n",
            "Node 951: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.973, 0.0, 0.002002002002002002]\n",
            "Node 952: [0.2879950124966983, 0, 0, 0.001, 0.002, 0.16155896069287137, 0.0, 0.477, 0.0, 0.003003003003003003]\n",
            "Node 953: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.974, 0.0, 0.002002002002002002]\n",
            "Node 954: [1.6394472402996065, 0, 0, 0.001, 0.002, 0.3412724850099933, 0.0, 0.478, 0.0, 0.003003003003003003]\n",
            "Node 955: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.975, 0.0, 0.002002002002002002]\n",
            "Node 956: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.479, 0.0, 0.003003003003003003]\n",
            "Node 957: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.976, 0.0, 0.002002002002002002]\n",
            "Node 958: [0.7305465606805359, 0, 0, 0.001, 0.002, 0.2204086164779036, 0.0, 0.48, 0.0, 0.003003003003003003]\n",
            "Node 959: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.977, 0.0, 0.002002002002002002]\n",
            "Node 960: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.481, 0.0, 0.003003003003003003]\n",
            "Node 961: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.978, 0.0, 0.002002002002002002]\n",
            "Node 962: [1.4261039939581521, 0, 0, 0.001, 0.002, 0.3129025094381523, 0.0, 0.482, 0.0, 0.003003003003003003]\n",
            "Node 963: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.979, 0.0, 0.002002002002002002]\n",
            "Node 964: [1.0420026502514255, 0, 0, 0.001, 0.002, 0.26182544970019983, 0.0, 0.483, 0.0, 0.003003003003003003]\n",
            "Node 965: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.98, 0.0, 0.002002002002002002]\n",
            "Node 966: [1.4945742334884817, 0, 0, 0.001, 0.002, 0.32200755052187424, 0.0, 0.484, 0.0, 0.003003003003003003]\n",
            "Node 967: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.981, 0.0, 0.002002002002002002]\n",
            "Node 968: [1.1968956921157687, 0, 0, 0.001, 0.002, 0.2824228292249611, 0.0, 0.485, 0.0, 0.003003003003003003]\n",
            "Node 969: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.982, 0.0, 0.002002002002002002]\n",
            "Node 970: [0.6420362510437685, 0, 0, 0.001, 0.002, 0.2086386853208972, 0.0, 0.486, 0.0, 0.003003003003003003]\n",
            "Node 971: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.983, 0.0, 0.002002002002002002]\n",
            "Node 972: [1.0929378284386218, 0, 0, 0.001, 0.002, 0.2685987119697979, 0.0, 0.487, 0.0, 0.003003003003003003]\n",
            "Node 973: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.984, 0.0, 0.002002002002002002]\n",
            "Node 974: [0.5777410261189468, 0, 0, 0.001, 0.002, 0.20008882966910949, 0.0, 0.488, 0.0, 0.003003003003003003]\n",
            "Node 975: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.985, 0.0, 0.002002002002002002]\n",
            "Node 976: [0.9096546872568249, 0, 0, 0.001, 0.002, 0.2442260715078836, 0.0, 0.489, 0.0, 0.003003003003003003]\n",
            "Node 977: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.986, 0.0, 0.002002002002002002]\n",
            "Node 978: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.49, 0.0, 0.003003003003003003]\n",
            "Node 979: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.987, 0.0, 0.002002002002002002]\n",
            "Node 980: [1.5501019277417374, 0, 0, 0.001, 0.002, 0.32939151676660006, 0.0, 0.491, 0.0, 0.003003003003003003]\n",
            "Node 981: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.988, 0.0, 0.002002002002002002]\n",
            "Node 982: [1.3730813084682019, 0, 0, 0.001, 0.002, 0.30585165445258716, 0.0, 0.492, 0.0, 0.003003003003003003]\n",
            "Node 983: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.989, 0.0, 0.002002002002002002]\n",
            "Node 984: [1.1672530884166625, 0, 0, 0.001, 0.002, 0.27848101265822783, 0.0, 0.493, 0.0, 0.003003003003003003]\n",
            "Node 985: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.99, 0.0, 0.002002002002002002]\n",
            "Node 986: [0.7238665373117235, 0, 0, 0.001, 0.002, 0.2195203197868088, 0.0, 0.494, 0.0, 0.003003003003003003]\n",
            "Node 987: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.991, 0.0, 0.002002002002002002]\n",
            "Node 988: [0.6583188080052493, 0, 0, 0.001, 0.002, 0.2108039085054408, 0.0, 0.495, 0.0, 0.003003003003003003]\n",
            "Node 989: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.992, 0.0, 0.002002002002002002]\n",
            "Node 990: [1.5033417641600486, 0, 0, 0.001, 0.002, 0.32317343992893627, 0.0, 0.496, 0.0, 0.003003003003003003]\n",
            "Node 991: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.993, 0.0, 0.002002002002002002]\n",
            "Node 992: [0.7493341264053216, 0, 0, 0.001, 0.002, 0.2229069509216078, 0.0, 0.497, 0.0, 0.003003003003003003]\n",
            "Node 993: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.994, 0.0, 0.002002002002002002]\n",
            "Node 994: [0.30427756945817913, 0, 0, 0.001, 0.002, 0.16372418387741505, 0.0, 0.498, 0.0, 0.003003003003003003]\n",
            "Node 995: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.995, 0.0, 0.002002002002002002]\n",
            "Node 996: [0.9313647632054661, 0, 0, 0.001, 0.002, 0.2471130357539418, 0.0, 0.499, 0.0, 0.003003003003003003]\n",
            "Node 997: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.996, 0.0, 0.002002002002002002]\n",
            "Node 998: [1.2887460134369424, 0, 0, 0.001, 0.002, 0.29463690872751497, 0.0, 0.5, 0.0, 0.003003003003003003]\n",
            "Node 999: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.998, 0.0, 0.002002002002002002]\n",
            "Using device: cpu\n",
            "Using device: cpu\n",
            "Unique SLA Adherence Values: tensor([1.])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 0, Loss: 1.0000, Time Loss: 0.1379, SLA Loss: 0.7608, Priority Loss: 0.4708\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 10, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.7362, Priority Loss: 0.4697\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 20, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.6832, Priority Loss: 0.4676\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 30, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.5798, Priority Loss: 0.4633\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 40, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.3116, Priority Loss: 0.4483\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 50, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.1340, Priority Loss: 0.4297\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 60, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0675, Priority Loss: 0.4130\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 70, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0349, Priority Loss: 0.4074\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 80, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0192, Priority Loss: 0.4072\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 90, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0098, Priority Loss: 0.4071\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 100, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.0051, Priority Loss: 0.4070\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 110, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0027, Priority Loss: 0.4070\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 120, Loss: 1.0000, Time Loss: 0.1212, SLA Loss: 0.0015, Priority Loss: 0.4070\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 130, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0008, Priority Loss: 0.4070\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 140, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0005, Priority Loss: 0.4069\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 150, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.0003, Priority Loss: 0.4069\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 160, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.0002, Priority Loss: 0.4069\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 170, Loss: 1.0000, Time Loss: 0.1202, SLA Loss: 0.0001, Priority Loss: 0.4068\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 180, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0001, Priority Loss: 0.4068\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 190, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0000, Priority Loss: 0.4067\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 200, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0000, Priority Loss: 0.4067\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 210, Loss: 1.0000, Time Loss: 0.1201, SLA Loss: 0.0000, Priority Loss: 0.4067\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 220, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0000, Priority Loss: 0.4066\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 230, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0000, Priority Loss: 0.4066\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 240, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0000, Priority Loss: 0.4065\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 250, Loss: 1.0000, Time Loss: 0.1200, SLA Loss: 0.0000, Priority Loss: 0.4065\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 260, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4065\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 270, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4064\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 280, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4064\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 290, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4064\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 300, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4064\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 310, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4063\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 320, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4063\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 330, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4063\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 340, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4063\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 350, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 360, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 370, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 380, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 390, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4062\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 400, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 410, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 420, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 430, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 440, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 450, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 460, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 470, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 480, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Epoch 490, Loss: 1.0000, Time Loss: 0.1199, SLA Loss: 0.0000, Priority Loss: 0.4061\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Loss history saved to ./embedding_model_data/loss_history.npy\n",
            "Model, task embeddings, and graph embedding saved to ./embedding_model_data\n",
            "Model training complete. Saved at ./embedding_model_data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trained model\n",
        "embedding_model_save_path = \"./embedding_model_data\"\n",
        "model = TaskEmbeddingModel(input_dim=10, num_gnn_layers=1, num_transformer_layers=1).to(device)  # Adjust input_dim if needed\n",
        "model.load_state_dict(torch.load(os.path.join(embedding_model_save_path, \"trained_model.pth\"), map_location=device))\n",
        "model.eval()\n",
        "print(\"Trained model loaded successfully.\")\n",
        "\n",
        "# Load saved data\n",
        "node_features = torch.tensor(np.load(os.path.join(embedding_model_save_path, \"node_features.npy\")), dtype=torch.float).to(device)\n",
        "edge_index = torch.tensor(np.load(os.path.join(embedding_model_save_path, \"edge_index.npy\")), dtype=torch.long).to(device)\n",
        "edge_attr = torch.tensor(np.load(os.path.join(embedding_model_save_path, \"edge_attr.npy\")), dtype=torch.float).to(device)\n",
        "# Load saved task embeddings and graph embedding\n",
        "task_embeddings = np.load(os.path.join(embedding_model_save_path, \"task_embeddings.npy\"))\n",
        "graph_embedding = np.load(os.path.join(embedding_model_save_path, \"graph_embedding.npy\"))\n",
        "\n",
        "print(\"Loaded saved other data successfully.\")\n",
        "\n",
        "# -------------------------------- #\n",
        "# 🔍 Visualization Functions #\n",
        "# -------------------------------- #\n",
        "\n",
        "## **Graph Attention Visualization**\n",
        "def plot_attention_scores(attn_weights):\n",
        "    attn_values = attn_weights.mean(dim=1).cpu().numpy()  # Take the mean over heads\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(len(attn_values)), np.sort(attn_values), marker='o', linestyle='-', color='b')\n",
        "\n",
        "    plt.xlabel(\"Edge Index (Sorted)\")\n",
        "    plt.ylabel(\"Attention Score\")\n",
        "    plt.title(\"Attention Scores Across Edges\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Ensure attn_weights is updated before calling plot_attention_scores()\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    _, _ = model(node_features.to(device), edge_index.to(device), edge_attr.to(device),\n",
        "                 torch.zeros(node_features.size(0), dtype=torch.long).to(device))\n",
        "\n",
        "# Now attn_weights should not be None\n",
        "if model.transformer_layers[0].attn_weights is not None:\n",
        "    plot_attention_scores(model.transformer_layers[0].attn_weights)\n",
        "else:\n",
        "    print(\"Attention weights were not updated. Check compute_attention().\")\n",
        "\n",
        "\n",
        "\n",
        "## **LSTM Execution Time Predictions**\n",
        "def plot_execution_predictions(exec_times, true_exec_times):\n",
        "    \"\"\"Plots predicted vs. true execution times with better visibility.\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.scatter(range(len(exec_times)), exec_times, marker='o', color='b', label=\"Predicted Execution Times\", alpha=0.5)\n",
        "    plt.plot(range(len(true_exec_times)), true_exec_times, color='orange', label=\"True Execution Times\", linewidth=1.5)\n",
        "\n",
        "    plt.xlabel(\"Task Index\")\n",
        "    plt.ylabel(\"Execution Time\")\n",
        "    plt.title(\"LSTM Prediction of Execution Times\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_execution_predictions(exec_time_pred, execution_times.cpu().numpy())\n",
        "\n",
        "\n",
        "# Load loss history\n",
        "loss_history = np.load(os.path.join(embedding_model_save_path, \"loss_history.npy\"), allow_pickle=True).item()\n",
        "\n",
        "# Print final loss values\n",
        "print(\"\\n📉 Final Loss Values:\")\n",
        "print(f\"Execution Time Loss: {loss_history['loss_time'][-1]:.4f}\")\n",
        "print(f\"SLA Loss: {loss_history['loss_sla'][-1]:.4f}\")\n",
        "print(f\"Priority Loss: {loss_history['loss_priority'][-1]:.4f}\")\n",
        "\n",
        "# Print loss values at every 50 epochs\n",
        "print(\"\\n📊 Loss Progress Over Training:\")\n",
        "for epoch in range(0, len(loss_history[\"total_loss\"]), 50):\n",
        "    print(f\"Time Loss: {loss_history['loss_time'][epoch]:.4f} | \"\n",
        "          f\"SLA Loss: {loss_history['loss_sla'][epoch]:.4f} | \"\n",
        "          f\"Priority Loss: {loss_history['loss_priority'][epoch]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CyweYxIl30sa",
        "outputId": "01f2decc-8739-4b8b-84db-45041bbe4348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Trained model loaded successfully.\n",
            "Loaded saved other data successfully.\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 10])\n",
            "Q shape: torch.Size([1000, 4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-9c125d2087a6>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(embedding_model_save_path, \"trained_model.pth\"), map_location=device))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Final Loss Values:\n",
            "Execution Time Loss: 0.1199\n",
            "SLA Loss: 0.0000\n",
            "Priority Loss: 0.4061\n",
            "\n",
            "📊 Loss Progress Over Training:\n",
            "Time Loss: 0.1379 | SLA Loss: 0.7608 | Priority Loss: 0.4708\n",
            "Time Loss: 0.1199 | SLA Loss: 0.1340 | Priority Loss: 0.4297\n",
            "Time Loss: 0.1202 | SLA Loss: 0.0051 | Priority Loss: 0.4070\n",
            "Time Loss: 0.1202 | SLA Loss: 0.0003 | Priority Loss: 0.4069\n",
            "Time Loss: 0.1201 | SLA Loss: 0.0000 | Priority Loss: 0.4067\n",
            "Time Loss: 0.1200 | SLA Loss: 0.0000 | Priority Loss: 0.4065\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4064\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4062\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n",
            "Time Loss: 0.1199 | SLA Loss: 0.0000 | Priority Loss: 0.4061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL SCHEDULER"
      ],
      "metadata": {
        "id": "sJt_umFNLNVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
      ],
      "metadata": {
        "id": "F4HJtzhdLRS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_rewards(rewards, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(rewards, label='Reward per Episode', color='blue')\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FDpode2mLURb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skfuzzy import control as ctrl\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import skfuzzy as fuzz\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------- Tier-1: Task Placement (Fuzzy + Neural Network) ---------------------- #\n",
        "class Tier1SchedulerEnv(gym.Env):\n",
        "    def __init__(self, task_embeddings):\n",
        "        super(Tier1SchedulerEnv, self).__init__()\n",
        "        self.task_embeddings = task_embeddings\n",
        "        self.num_tasks = task_embeddings.shape[0]\n",
        "        self.current_task = 0\n",
        "\n",
        "        # Define fuzzy variables and membership functions\n",
        "        self.execution_time = ctrl.Antecedent(np.arange(0, 1.5, 0.01), 'execution_time')\n",
        "        self.sla_adherence = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'sla_adherence')\n",
        "        self.energy_usage = ctrl.Consequent(np.arange(0, 2, 0.01), 'energy_usage')\n",
        "\n",
        "        # Use automatic membership functions (poor, average, good)\n",
        "        self.execution_time.automf(5)\n",
        "        self.sla_adherence.automf(5)\n",
        "        self.energy_usage.automf(5)\n",
        "\n",
        "        # Define fuzzy rules with correct labels\n",
        "        rule1 = ctrl.Rule(self.execution_time['good'] & self.sla_adherence['good'], self.energy_usage['poor'])\n",
        "        rule2 = ctrl.Rule(self.execution_time['average'] & self.sla_adherence['average'], self.energy_usage['average'])\n",
        "        rule3 = ctrl.Rule(self.execution_time['poor'] & self.sla_adherence['poor'], self.energy_usage['good'])\n",
        "\n",
        "        self.energy_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
        "        self.energy_sim = ctrl.ControlSystemSimulation(self.energy_ctrl)\n",
        "\n",
        "        # State and action spaces\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(task_embeddings.shape[1],), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)  # {0: Cloud, 1: Edge, 2: Hybrid}\n",
        "\n",
        "        # Neural network-based reward function\n",
        "        self.reward_net = nn.Sequential(\n",
        "          nn.Linear(task_embeddings.shape[1] + 3, 128),  # Added SLA & energy\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, 1)\n",
        "      ).to(device)\n",
        "\n",
        "    def step(self, action):\n",
        "        task_embedding = self.task_embeddings[self.current_task]\n",
        "        execution_time = task_embedding[-3].item()\n",
        "        sla_adherence = task_embedding[-2].item()\n",
        "\n",
        "        # Apply fuzzy logic for energy estimation\n",
        "        self.energy_sim.input['execution_time'] = np.clip(execution_time, 0, 1.5)\n",
        "        self.energy_sim.input['sla_adherence'] = np.clip(sla_adherence, 0, 1)\n",
        "\n",
        "        try:\n",
        "            self.energy_sim.compute()\n",
        "            energy_usage = self.energy_sim.output.get('energy_usage', execution_time * 1.0)  # Default fallback\n",
        "        except:\n",
        "            energy_usage = execution_time * 1.0  # Safe fallback\n",
        "\n",
        "        # Adjust energy usage based on action type\n",
        "        energy_usage *= (1.2 if action == 0 else 0.8 if action == 1 else 0.9) # Cloud, Edge, Hybrid\n",
        "\n",
        "        # Compute reward with neural network\n",
        "        task_embedding_tensor = torch.tensor(task_embedding, dtype=torch.float).to(device)\n",
        "        action_tensor = torch.tensor([action], dtype=torch.float).to(device)\n",
        "        sla_tensor = torch.tensor([sla_adherence], dtype=torch.float).to(device)\n",
        "        energy_tensor = torch.tensor([energy_usage], dtype=torch.float).to(device)\n",
        "\n",
        "        reward_input = torch.cat([task_embedding_tensor, action_tensor, sla_tensor, energy_tensor])\n",
        "\n",
        "        reward = self.reward_net(reward_input).item() - energy_usage\n",
        "\n",
        "        predicted_reward = self.reward_net(reward_input).item()\n",
        "\n",
        "        # Apply weights to balance SLA, execution time, and energy usage\n",
        "        reward = (\n",
        "            1.5 * predicted_reward  # Make RewardNet's output more significant\n",
        "            + 2.0 * sla_adherence  # Encourage SLA adherence\n",
        "            - 0.8 * execution_time  # Penalize long execution times\n",
        "            - 0.5 * energy_usage  # Penalize excessive energy usage\n",
        "        )\n",
        "\n",
        "\n",
        "        # Proceed to the next task\n",
        "        self.current_task += 1\n",
        "        done = self.current_task >= self.num_tasks\n",
        "        return task_embedding, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_task = 0\n",
        "        return self.task_embeddings[self.current_task]\n",
        "\n",
        "\n",
        "# ---------------------- Tier-2: Resource Allocation (Fuzzy + Linear Regression) ---------------------- #\n",
        "class Tier2SchedulerEnv(gym.Env):\n",
        "    def __init__(self, task_embeddings, server_loads):\n",
        "        super(Tier2SchedulerEnv, self).__init__()\n",
        "        self.task_embeddings = task_embeddings\n",
        "        self.num_tasks = task_embeddings.shape[0]\n",
        "        self.num_servers = len(server_loads)\n",
        "        self.server_loads = server_loads\n",
        "        self.current_task = 0\n",
        "        # Neural network-based reward function\n",
        "        self.reward_net = nn.Sequential(\n",
        "            nn.Linear(task_embeddings.shape[1] + 2, 128),  # Remove server_loads length\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        ).to(device)\n",
        "\n",
        "\n",
        "        # Define fuzzy variables for server load and execution time\n",
        "        self.server_load_fuzzy = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'server_load')\n",
        "        self.execution_time_fuzzy = ctrl.Antecedent(np.arange(0, 1.6, 0.01), 'execution_time')\n",
        "        self.adjusted_resource_use = ctrl.Consequent(np.arange(0, 1.6, 0.01), 'adjusted_resource_use')\n",
        "\n",
        "        # Use correct automatic membership function names\n",
        "        self.server_load_fuzzy.automf(3)\n",
        "        self.execution_time_fuzzy.automf(3)\n",
        "        self.adjusted_resource_use.automf(3)\n",
        "\n",
        "        # Define fuzzy rules with correct labels\n",
        "        resource_rule1 = ctrl.Rule(self.server_load_fuzzy['poor'] & self.execution_time_fuzzy['poor'], self.adjusted_resource_use['poor'])\n",
        "        resource_rule2 = ctrl.Rule(self.server_load_fuzzy['average'] | self.execution_time_fuzzy['average'], self.adjusted_resource_use['average'])\n",
        "        resource_rule3 = ctrl.Rule(self.server_load_fuzzy['good'] | self.execution_time_fuzzy['good'], self.adjusted_resource_use['good'])\n",
        "\n",
        "        self.resource_ctrl = ctrl.ControlSystem([resource_rule1, resource_rule2, resource_rule3])\n",
        "        self.resource_sim = ctrl.ControlSystemSimulation(self.resource_ctrl)\n",
        "\n",
        "        # State and action spaces\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(task_embeddings.shape[1] + self.num_servers,), dtype=np.float32)\n",
        "        self.action_space = spaces.MultiDiscrete([self.num_servers, 3])  # (server_id, execution_strategy)\n",
        "\n",
        "        # Linear Regression model for rule weighting\n",
        "        self.rule_weights = LinearRegression()\n",
        "        self.rule_weights.fit(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([0.2, 0.5, 0.7, 1.0]))\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "      server_id, execution_strategy = action\n",
        "      task_embedding = self.task_embeddings[self.current_task]\n",
        "      server_load = self.server_loads[server_id]\n",
        "      execution_time = task_embedding[-3].item()\n",
        "\n",
        "      normalized_server_load = server_load / max(self.server_loads)\n",
        "      normalized_execution_time = execution_time / 1.5  # Normalize execution time\n",
        "\n",
        "      predicted_weights = np.clip(\n",
        "          self.rule_weights.predict([[normalized_server_load, normalized_execution_time]]),\n",
        "          0, 1\n",
        "      )\n",
        "\n",
        "      # Apply fuzzy logic for resource use adjustment\n",
        "      self.resource_sim.input['server_load'] = np.clip(server_load, 0, 1)\n",
        "      self.resource_sim.input['execution_time'] = np.clip(execution_time, 0, 1.5)\n",
        "      self.resource_sim.compute()\n",
        "      resource_usage_multiplier = self.resource_sim.output['adjusted_resource_use']\n",
        "\n",
        "      adjusted_time = execution_time * (0.8 if execution_strategy == 0 else 1.1 if execution_strategy == 1 else 1.3) * resource_usage_multiplier\n",
        "      adjusted_energy = execution_time * (1.5 if execution_strategy == 0 else 1.0 if execution_strategy == 1 else 0.8) * resource_usage_multiplier\n",
        "\n",
        "      # Convert inputs to tensors\n",
        "      task_embedding_tensor = torch.tensor(task_embedding, dtype=torch.float32).to(device)\n",
        "      server_load_tensor = torch.tensor([server_load], dtype=torch.float32).to(device)\n",
        "      execution_strategy_tensor = torch.tensor([execution_strategy], dtype=torch.float32).to(device)\n",
        "\n",
        "      # Combine all inputs into a single tensor\n",
        "      reward_input = torch.cat([task_embedding_tensor, server_load_tensor, execution_strategy_tensor])\n",
        "\n",
        "      # Compute reward using the neural network\n",
        "      predicted_reward = self.reward_net(reward_input).item()\n",
        "\n",
        "      # Adjust final reward calculation\n",
        "      reward = (\n",
        "          1.5 * predicted_reward  # Make RewardNet's output more significant\n",
        "          + 3.0 * task_embedding[-2].item()  # Encourage SLA adherence\n",
        "          - 0.5 * execution_time  # Penalize long execution times\n",
        "          - 1.0 * server_load  # Penalize overloaded servers\n",
        "      )\n",
        "\n",
        "      self.server_loads[server_id] += min(0.1, 1.0 - self.server_loads[server_id])\n",
        "\n",
        "      self.current_task += 1\n",
        "      done = self.current_task >= self.num_tasks\n",
        "      return np.concatenate([task_embedding, self.server_loads]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_task = 0\n",
        "        return np.concatenate([self.task_embeddings[self.current_task], self.server_loads])\n"
      ],
      "metadata": {
        "id": "D7wIDOsv4Lit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Tier-1 and Tier-2 environments\n",
        "tier1_env = Tier1SchedulerEnv(task_embeddings)\n",
        "\n",
        "\n",
        "# Wrap environments for Stable-Baselines3\n",
        "tier1_env = DummyVecEnv([lambda: tier1_env])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aijMNLXSKUEZ",
        "outputId": "4d0c7d38-fe53-4ab9-d848-3bd9ec4e30cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tier2_env = Tier2SchedulerEnv(task_embeddings, np.random.rand(5))\n",
        "tier2_env = DummyVecEnv([lambda: tier2_env])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3pJBTiuKXdi",
        "outputId": "ee0b8aea-62bf-44b3-df07-63738746c250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Tier-1 Scheduler with improved reward function\n",
        "tier1_model = PPO(\"MlpPolicy\", tier1_env, verbose=1, tensorboard_log=\"./tier1_tensorboard/\")\n",
        "tier1_callback = EvalCallback(tier1_env, eval_freq=5000, callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=50, verbose=1))\n",
        "tier1_model.learn(total_timesteps=50000, callback=tier1_callback)\n",
        "tier1_model.save(\"tier1_scheduler\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1uPcUKfKZRb",
        "outputId": "b2a57a07-b52d-4fd0-9bf7-5cda5b1444f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to ./tier1_tensorboard/PPO_2\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 778  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 2    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 556         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012910368 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.62e+03    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00863    |\n",
            "|    value_loss           | 8e+03       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=5000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | -5.5e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 5000       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01123129 |\n",
            "|    clip_fraction        | 0.144      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.06      |\n",
            "|    explained_variance   | 5.96e-08   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.9e+03    |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00832   |\n",
            "|    value_loss           | 8.3e+03    |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 368  |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 16   |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 385         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013158693 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.68e+03    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00923    |\n",
            "|    value_loss           | 7.94e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | -5.5e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 10000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055008573 |\n",
            "|    clip_fraction        | 0.0724       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.986       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.51e+03     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00419     |\n",
            "|    value_loss           | 7.61e+03     |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 328   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 31    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019166756 |\n",
            "|    clip_fraction        | 0.3         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.895      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.46e+03    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0147     |\n",
            "|    value_loss           | 7.3e+03     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009452922 |\n",
            "|    clip_fraction        | 0.0286      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.825      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.15e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00163    |\n",
            "|    value_loss           | 7.03e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | -5.5e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 15000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00569436 |\n",
            "|    clip_fraction        | 0.0366     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.803     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.15e+03   |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.00189   |\n",
            "|    value_loss           | 6.78e+03   |\n",
            "----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 334   |\n",
            "|    iterations      | 8     |\n",
            "|    time_elapsed    | 49    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 348         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010830236 |\n",
            "|    clip_fraction        | 0.0671      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.746      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.01e+03    |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00328    |\n",
            "|    value_loss           | 6.59e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -5.5e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005261241 |\n",
            "|    clip_fraction        | 0.0222      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.749      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.95e+03    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    value_loss           | 6.37e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 323   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 63    |\n",
            "|    total_timesteps | 20480 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 334          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017307459 |\n",
            "|    clip_fraction        | 0.00371      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.758       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.96e+03     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | 9.69e-05     |\n",
            "|    value_loss           | 6.22e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 71          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008101514 |\n",
            "|    clip_fraction        | 0.0331      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.76       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.85e+03    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00116    |\n",
            "|    value_loss           | 6.03e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -5.5e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 25000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010585809 |\n",
            "|    clip_fraction        | 0.0124      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.786      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.75e+03    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | 6.53e-05    |\n",
            "|    value_loss           | 5.89e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 325   |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 81    |\n",
            "|    total_timesteps | 26624 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 334         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003414363 |\n",
            "|    clip_fraction        | 0.0177      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.787      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.74e+03    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00067    |\n",
            "|    value_loss           | 5.78e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -5.5e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017164238 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.756      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.64e+03    |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00722    |\n",
            "|    value_loss           | 5.64e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 318   |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 96    |\n",
            "|    total_timesteps | 30720 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 326          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006447431 |\n",
            "|    clip_fraction        | 0.00752      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.747       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.53e+03     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000239    |\n",
            "|    value_loss           | 5.43e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 334         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 104         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012206169 |\n",
            "|    clip_fraction        | 0.0773      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.696      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.47e+03    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00367    |\n",
            "|    value_loss           | 5.27e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -5.5e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 35000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009883796 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.629      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.31e+03    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00413    |\n",
            "|    value_loss           | 5.08e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 323   |\n",
            "|    iterations      | 18    |\n",
            "|    time_elapsed    | 114   |\n",
            "|    total_timesteps | 36864 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 328          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066345884 |\n",
            "|    clip_fraction        | 0.0629       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.557       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.3e+03      |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00275     |\n",
            "|    value_loss           | 4.92e+03     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | -5.5e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 40000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051798113 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.508       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.15e+03     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.000493    |\n",
            "|    value_loss           | 4.74e+03     |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 319   |\n",
            "|    iterations      | 20    |\n",
            "|    time_elapsed    | 128   |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 323          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 132          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027122744 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.516       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.07e+03     |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | 0.000264     |\n",
            "|    value_loss           | 4.58e+03     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | -5.5e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 45000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050778193 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.494       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.99e+03     |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    value_loss           | 4.47e+03     |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 317   |\n",
            "|    iterations      | 22    |\n",
            "|    time_elapsed    | 141   |\n",
            "|    total_timesteps | 45056 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 321         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 146         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004009283 |\n",
            "|    clip_fraction        | 0.0133      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.433      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.89e+03    |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000488   |\n",
            "|    value_loss           | 4.33e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 327         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 150         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002141965 |\n",
            "|    clip_fraction        | 0.00947     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.443      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.87e+03    |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.000552   |\n",
            "|    value_loss           | 4.18e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=-5495.55 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+03        |\n",
            "|    mean_reward          | -5.5e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 50000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028697797 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.415       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.91e+03     |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.000657    |\n",
            "|    value_loss           | 4.07e+03     |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 319   |\n",
            "|    iterations      | 25    |\n",
            "|    time_elapsed    | 160   |\n",
            "|    total_timesteps | 51200 |\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_tensorboard_data(log_dir):\n",
        "    rewards = []\n",
        "    timesteps = []\n",
        "\n",
        "    ppo_runs = [f for f in os.listdir(log_dir) if f.startswith(\"PPO_\")]\n",
        "    for run in ppo_runs:\n",
        "        event_dir = os.path.join(log_dir, run)\n",
        "        for event_file in os.listdir(event_dir):\n",
        "            event_path = os.path.join(event_dir, event_file)\n",
        "            for event in tf.compat.v1.train.summary_iterator(event_path):\n",
        "                for value in event.summary.value:\n",
        "                    if \"rollout/ep_rew_mean\" in value.tag:\n",
        "                        rewards.append(value.simple_value)\n",
        "                        timesteps.append(event.step)\n",
        "\n",
        "    return np.array(timesteps), np.array(rewards)\n",
        "\n",
        "# Load TensorBoard data from PPO runs inside Tier-1 logs\n",
        "tier1_log_dir = \"./tier1_tensorboard/\"\n",
        "tier1_timesteps, tier1_rewards = load_tensorboard_data(tier1_log_dir)\n",
        "\n",
        "# Print results\n",
        "print(\"Tier-1 Training Progress Data:\")\n",
        "for t, r in zip(tier1_timesteps, tier1_rewards):\n",
        "    print(f\"Timestep: {t}, Reward: {r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKV1a7F4N8zv",
        "outputId": "9966eaf7-e820-4796-9c77-c64058602ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier-1 Training Progress Data:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Tier-2 Scheduler\n",
        "tier2_model = PPO(\"MlpPolicy\", tier2_env, verbose=1, tensorboard_log=\"./tier2_tensorboard/\")\n",
        "tier2_callback = EvalCallback(tier2_env, eval_freq=1000, callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=100, verbose=1))\n",
        "tier2_model.learn(total_timesteps=10000, callback=tier2_callback)\n",
        "tier2_model.save(\"tier2_scheduler\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYE7pearLeh4",
        "outputId": "47f2d0f2-17c6-4eff-f74f-a3da5f542871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to ./tier2_tensorboard/PPO_9\n",
            "Eval num_timesteps=1000, episode_reward=2.24 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 10       |\n",
            "|    mean_reward     | 2.24     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best mean reward!\n",
            "Eval num_timesteps=2000, episode_reward=2.24 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 10       |\n",
            "|    mean_reward     | 2.24     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2000     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 448  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 10          |\n",
            "|    mean_reward          | 2.53        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008410202 |\n",
            "|    clip_fraction        | 0.0632      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.7        |\n",
            "|    explained_variance   | 0.0161      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.138       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00516    |\n",
            "|    value_loss           | 0.608       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best mean reward!\n",
            "Eval num_timesteps=4000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 10       |\n",
            "|    mean_reward     | 2.53     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 4000     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 402  |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 10   |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 10          |\n",
            "|    mean_reward          | 2.53        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010857785 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.67       |\n",
            "|    explained_variance   | 0.728       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0862      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 0.185       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=6000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 10       |\n",
            "|    mean_reward     | 2.53     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6000     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 389  |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 15   |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 10          |\n",
            "|    mean_reward          | 2.53        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 7000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014444695 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.62       |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0211      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    value_loss           | 0.145       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=8000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 10       |\n",
            "|    mean_reward     | 2.53     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 8000     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 375  |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 21   |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 10          |\n",
            "|    mean_reward          | 2.53        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017757237 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.53       |\n",
            "|    explained_variance   | 0.846       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0135      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0188     |\n",
            "|    value_loss           | 0.11        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=10000, episode_reward=2.53 +/- 0.00\n",
            "Episode length: 10.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 10       |\n",
            "|    mean_reward     | 2.53     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 378   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 27    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(tier1_model, tier2_model, task_embeddings, server_loads, num_episodes=10):\n",
        "    tier1_rewards = []\n",
        "    tier2_rewards = []\n",
        "    tier1_energy_usage = []\n",
        "    tier2_energy_usage = []\n",
        "    tier1_sla_adherence = []\n",
        "    tier2_sla_adherence = []\n",
        "    tier1_execution_time = []\n",
        "    tier2_execution_time = []\n",
        "    tier2_server_loads = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset environments\n",
        "        obs1 = tier1_env.reset()\n",
        "        obs2 = tier2_env.reset()\n",
        "\n",
        "        episode_tier1_rewards = []\n",
        "        episode_tier2_rewards = []\n",
        "        episode_tier1_energy = []\n",
        "        episode_tier2_energy = []\n",
        "        episode_tier1_sla = []\n",
        "        episode_tier2_sla = []\n",
        "        episode_tier1_time = []\n",
        "        episode_tier2_time = []\n",
        "        episode_tier2_loads = []\n",
        "\n",
        "        for i in range(len(task_embeddings)):\n",
        "            # Tier1: Task Placement\n",
        "            action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "            obs1, reward1, done1, info1 = tier1_env.step(action1)\n",
        "            episode_tier1_rewards.append(reward1)\n",
        "            episode_tier1_energy.append(info1.get('energy_usage', 0))\n",
        "            episode_tier1_sla.append(info1.get('sla_adherence', 0))\n",
        "            episode_tier1_time.append(info1.get('execution_time', 0))\n",
        "\n",
        "            # Tier2: Resource Allocation\n",
        "            action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "            obs2, reward2, done2, info2 = tier2_env.step(action2)\n",
        "            episode_tier2_rewards.append(reward2)\n",
        "            episode_tier2_energy.append(info2.get('energy_usage', 0))\n",
        "            episode_tier2_sla.append(info2.get('sla_adherence', 0))\n",
        "            episode_tier2_time.append(info2.get('execution_time', 0))\n",
        "            episode_tier2_loads.append(np.mean(tier2_env.server_loads))\n",
        "\n",
        "            if done1 or done2:\n",
        "                break\n",
        "\n",
        "        # Store episode results\n",
        "        tier1_rewards.append(np.mean(episode_tier1_rewards))\n",
        "        tier2_rewards.append(np.mean(episode_tier2_rewards))\n",
        "        tier1_energy_usage.append(np.mean(episode_tier1_energy))\n",
        "        tier2_energy_usage.append(np.mean(episode_tier2_energy))\n",
        "        tier1_sla_adherence.append(np.mean(episode_tier1_sla))\n",
        "        tier2_sla_adherence.append(np.mean(episode_tier2_sla))\n",
        "        tier1_execution_time.append(np.mean(episode_tier1_time))\n",
        "        tier2_execution_time.append(np.mean(episode_tier2_time))\n",
        "        tier2_server_loads.append(np.mean(episode_tier2_loads))\n",
        "\n",
        "    # Print results\n",
        "    print(\"Tier1 Evaluation:\")\n",
        "    print(f\"  Average Reward: {np.mean(tier1_rewards):.4f}\")\n",
        "    print(f\"  Average Energy Usage: {np.mean(tier1_energy_usage):.4f}\")\n",
        "    print(f\"  Average SLA Adherence: {np.mean(tier1_sla_adherence):.4f}\")\n",
        "    print(f\"  Average Execution Time: {np.mean(tier1_execution_time):.4f}\")\n",
        "\n",
        "    print(\"Tier2 Evaluation:\")\n",
        "    print(f\"  Average Reward: {np.mean(tier2_rewards):.4f}\")\n",
        "    print(f\"  Average Energy Usage: {np.mean(tier2_energy_usage):.4f}\")\n",
        "    print(f\"  Average SLA Adherence: {np.mean(tier2_sla_adherence):.4f}\")\n",
        "    print(f\"  Average Execution Time: {np.mean(tier2_execution_time):.4f}\")\n",
        "    print(f\"  Average Server Load: {np.mean(tier2_server_loads):.4f}\")\n",
        "\n",
        "# Example usage\n",
        "task_embeddings = np.random.rand(10, 5)  # Simulated task embeddings\n",
        "server_loads = np.random.rand(5)  # Simulated server loads\n",
        "evaluate_models(tier1_model, tier2_model, task_embeddings, server_loads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2_B3yL1cMaaO",
        "outputId": "5d3ddb04-d7ca-484f-ee8a-b4ba38f1c5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error: Unexpected observation shape (1, 5) for Box environment, please use (32,) or (n_env, 32) for the observation shape.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-7494a79105a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mtask_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Simulated task embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mserver_loads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Simulated server loads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtier1_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtier2_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_loads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-127-7494a79105a7>\u001b[0m in \u001b[0;36mevaluate_models\u001b[0;34m(tier1_model, tier2_model, task_embeddings, server_loads, num_episodes)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Tier1: Task Placement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtier1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mobs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtier1_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mepisode_tier1_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \"\"\"\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    363\u001b[0m             )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mobs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;31m# Dict obs need to be handled separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mvectorized_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_vectorized_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0;31m# Add batch dimension if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/utils.py\u001b[0m in \u001b[0;36mis_vectorized_observation\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mspace_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vec_obs_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mis_vec_obs_func_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_vec_obs_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# for-else happens if no break is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/utils.py\u001b[0m in \u001b[0;36mis_vectorized_box_observation\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;34mf\"Error: Unexpected observation shape {observation.shape} for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Box environment, please use {observation_space.shape} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error: Unexpected observation shape (1, 5) for Box environment, please use (32,) or (n_env, 32) for the observation shape."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad observations to match the expected shape\n",
        "obs1 = np.pad(obs1, (0, 32 - len(obs1)), mode='constant')  # Pad to shape (32,)\n",
        "obs2 = np.pad(obs2, (0, 32 - len(obs2)), mode='constant')  # Pad to shape (32,)"
      ],
      "metadata": {
        "id": "EMZsSkbUU65l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tier1 Observation Shape:\", obs1.shape)\n",
        "print(\"Tier2 Observation Shape:\", obs2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u02HceSgbpM7",
        "outputId": "73474bc7-9eef-4cba-f476-2fa5c8e83154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier1 Observation Shape: (32, 63)\n",
            "Tier2 Observation Shape: (32, 68)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tier1 Observation Space:\", tier1_env.observation_space)\n",
        "print(\"Tier2 Observation Space:\", tier2_env.observation_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOoXXwybtuc",
        "outputId": "0bc4ccb7-fe30-4e8a-ac29-29f868882deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier1 Observation Space: Box(-inf, inf, (5,), float32)\n",
            "Tier2 Observation Space: Box(-inf, inf, (10,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nv0chViZbyL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}