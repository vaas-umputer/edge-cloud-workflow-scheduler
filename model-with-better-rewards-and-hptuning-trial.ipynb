{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlWZVQd0nsz6lBKV7QygyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaas-umputer/edge-cloud-workflow-scheduler/blob/main/model-with-better-rewards-and-hptuning-trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DEAP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r1W1ajj7McR",
        "outputId": "868112e4-f71d-4db7-987b-85bcd431544a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DEAP\n",
            "  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from DEAP) (1.26.4)\n",
            "Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: DEAP\n",
            "Successfully installed DEAP-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0huRBJXbFMz",
        "outputId": "17f3a744-4113-49ab-b4c8-75b02438cbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiTbhj2oxj8f",
        "outputId": "eec6f25c-fd6b-4d5b-d6d3-0fed15ecebb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cs0H_IOb-oo",
        "outputId": "3a4d7ca5-960d-48ce-9341-3b57762ae89f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.0\n",
            "    Uninstalling gymnasium-1.1.0:\n",
            "      Successfully uninstalled gymnasium-1.1.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LTnFH3Vl2BR",
        "outputId": "e745cd33-802f-48e9-8bce-a5e153349f95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch_geometric networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ShXK79icGQJ",
        "outputId": "3f506678-2d0b-491c-999f-b89e9f330338"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOnzFK3kcK1G",
        "outputId": "39eabf66-8b4c-48b6-a74e-c4dbec75b87c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.2+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_cluster -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RTGQY8tcMwI",
        "outputId": "b359826f-3c3c-45d5-869f-deae01b57855"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_cluster) (1.26.4)\n",
            "Installing collected packages: torch_cluster\n",
            "Successfully installed torch_cluster-1.6.3+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ5fLtK_cOn3",
        "outputId": "f26c1c18-499d-49b0-873c-0274f684b659"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_spline_conv\n",
            "Successfully installed torch_spline_conv-1.2.2+pt25cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv9x_yIApfkB",
        "outputId": "e15a3c7c-5fb6-4343-d946-13b3aaa3b761"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/920.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/920.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.4/920.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m911.4/920.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ7D8AtRcRfk",
        "outputId": "8e899098-7b1c-4f4a-bd54-1ae8e2dc24bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing, GATConv, global_mean_pool\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import json\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "import os\n",
        "\n",
        "\n",
        "# ---------------------- LOAD DAG & EXTRACT FEATURES ---------------------- #\n",
        "def load_dag(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        dag_data = json.load(f)\n",
        "\n",
        "    cybershake_dag = nx.DiGraph()\n",
        "    for node, attributes in dag_data[\"nodes\"].items():\n",
        "        cybershake_dag.add_node(node, **attributes)\n",
        "    for parent, child, attributes in dag_data[\"edges\"]:\n",
        "        cybershake_dag.add_edge(parent, child, **attributes)\n",
        "    return cybershake_dag\n",
        "\n",
        "\n",
        "def compute_feature_stats(workflow_dag):\n",
        "    execution_times, input_sizes, output_sizes, sla_deadlines, critical_paths = [], [], [], [], []\n",
        "\n",
        "    for node in workflow_dag.nodes():\n",
        "        node_data = workflow_dag.nodes[node]\n",
        "        execution_times.append(node_data.get(\"runtime\", 1.0))\n",
        "        input_sizes.append(sum(f.get(\"size\", 0) for f in node_data.get(\"input_files\", []) if f is not None))\n",
        "        output_sizes.append(sum(f.get(\"size\", 0) for f in node_data.get(\"output_files\", []) if f is not None))\n",
        "        sla_deadlines.append(node_data.get(\"sla_deadline\", execution_times[-1] * 1.5))\n",
        "        try:\n",
        "            critical_paths.append(\n",
        "                max(len(path) for path in nx.all_simple_paths(workflow_dag, list(workflow_dag.nodes())[0], node))\n",
        "                if nx.has_path(workflow_dag, list(workflow_dag.nodes())[0], node) else 0)\n",
        "        except nx.NetworkXNoPath:\n",
        "            critical_paths.append(0)\n",
        "\n",
        "    stats = lambda x: {\"min\": np.min(x), \"max\": np.max(x), \"mean\": np.mean(x), \"std\": np.std(x)}\n",
        "    return {\n",
        "        \"execution_time\": stats(execution_times),\n",
        "        \"input_size\": stats(input_sizes),\n",
        "        \"output_size\": stats(output_sizes),\n",
        "        \"sla_deadline\": stats(sla_deadlines),\n",
        "        \"critical_path\": stats(critical_paths)\n",
        "    }\n",
        "\n",
        "\n",
        "def normalize(value, stats, method=\"minmax\"):\n",
        "    if method == \"minmax\":\n",
        "        return (value - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"]) if stats[\"max\"] > stats[\"min\"] else 0\n",
        "    elif method == \"zscore\":\n",
        "        return (value - stats[\"mean\"]) / stats[\"std\"] if stats[\"std\"] > 0 else 0\n",
        "    else:\n",
        "        raise ValueError(\"Invalid normalization method.\")\n",
        "\n",
        "\n",
        "def prepare_workflow_dag(workflow_dag):\n",
        "    feature_stats = compute_feature_stats(workflow_dag)\n",
        "    node_id_to_idx = {node_id: idx for idx, node_id in enumerate(workflow_dag.nodes())}\n",
        "    edges = [(node_id_to_idx[u], node_id_to_idx[v]) for u, v in workflow_dag.edges()]\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Adjacency matrix for DAG\n",
        "    num_nodes = workflow_dag.number_of_nodes()\n",
        "    adjacency_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float)\n",
        "    for u, v in edges:\n",
        "        adjacency_matrix[u, v] = 1\n",
        "\n",
        "    # Topological order for positional encoding\n",
        "    topo_order = list(nx.topological_sort(workflow_dag))\n",
        "    node_features_list, edge_attr, execution_times, sla_adherences, task_priorities = [], [], [], [], []  # Corrected var name\n",
        "\n",
        "    # Compute shortest path to each node\n",
        "    shortest_path_lengths = {}\n",
        "    for node in workflow_dag.nodes():\n",
        "        try:\n",
        "            shortest_path_lengths[node] = nx.shortest_path_length(workflow_dag, source=topo_order[0], target=node)\n",
        "        except nx.NetworkXNoPath:\n",
        "            shortest_path_lengths[node] = 0\n",
        "\n",
        "    # Compute degree centrality\n",
        "    degree_centrality = nx.degree_centrality(workflow_dag)\n",
        "\n",
        "    for node in workflow_dag.nodes():\n",
        "        node_data = workflow_dag.nodes[node]\n",
        "        execution_time = node_data.get(\"runtime\", 1.0)\n",
        "        input_size = sum(f.get(\"size\", 0) for f in node_data.get(\"input_files\", []) if f is not None)\n",
        "        output_size = sum(f.get(\"size\", 0) for f in node_data.get(\"output_files\", []) if f is not None)\n",
        "        in_degree = workflow_dag.in_degree(node)\n",
        "        out_degree = workflow_dag.out_degree(node)\n",
        "        sla_deadline = node_data.get(\"sla_deadline\", execution_time * 1.5)\n",
        "        try:\n",
        "            critical_path = max(len(path) for path in\n",
        "                                nx.all_simple_paths(workflow_dag, topo_order[0], node)) if topo_order and nx.has_path(\n",
        "                workflow_dag, topo_order[0], node) else 0\n",
        "        except nx.NetworkXNoPath:\n",
        "            critical_path = 0\n",
        "\n",
        "        topo_rank = topo_order.index(node) / len(topo_order)\n",
        "\n",
        "        # Positional Encodings\n",
        "        shortest_path = shortest_path_lengths[node] / max(1, num_nodes)\n",
        "        node_degree = degree_centrality[node]\n",
        "\n",
        "        node_features = [  # Corrected local variable\n",
        "            normalize(execution_time, feature_stats[\"execution_time\"], \"zscore\"),\n",
        "            normalize(input_size, feature_stats[\"input_size\"], \"minmax\"),\n",
        "            normalize(output_size, feature_stats[\"output_size\"], \"minmax\"),\n",
        "            in_degree / max(1, workflow_dag.number_of_nodes()),\n",
        "            out_degree / max(1, workflow_dag.number_of_nodes()),\n",
        "            normalize(sla_deadline, feature_stats[\"sla_deadline\"], \"minmax\"),\n",
        "            normalize(critical_path, feature_stats[\"critical_path\"], \"minmax\"),\n",
        "            topo_rank,\n",
        "            shortest_path,  # Shortest Path\n",
        "            node_degree  # Degree\n",
        "        ]\n",
        "\n",
        "        node_features_list.append(node_features) # Corrected append\n",
        "\n",
        "        sla_adherence = 1 if execution_time <= sla_deadline else 0\n",
        "        task_priority = 1 / (execution_time + critical_path + 1e-6)\n",
        "        execution_times.append(normalize(execution_time, feature_stats[\"execution_time\"], \"zscore\"))\n",
        "        sla_adherences.append(sla_adherence)\n",
        "        task_priorities.append(task_priority)\n",
        "\n",
        "    for u, v in workflow_dag.edges():\n",
        "        u_idx, v_idx = node_id_to_idx[u], node_id_to_idx[v]\n",
        "        u_features, v_features = node_features_list[u_idx], node_features_list[v_idx]  # accessing features using new list\n",
        "        edge_attr.append([\n",
        "            abs(u_features[0] - v_features[0]),  # Execution time diff\n",
        "            abs(u_features[1] - v_features[1]),  # Input size diff\n",
        "            abs(u_features[2] - v_features[2]),  # Output size diff\n",
        "            abs(u_features[5] - v_features[5])  # SLA diff\n",
        "        ])\n",
        "\n",
        "    node_features_tensor = torch.tensor(node_features_list, dtype=torch.float) # Creating node features tensor\n",
        "    return (\n",
        "        node_features_tensor,\n",
        "        edge_index,\n",
        "        torch.tensor(edge_attr, dtype=torch.float),\n",
        "        adjacency_matrix,\n",
        "        torch.tensor(execution_times, dtype=torch.float).unsqueeze(1),\n",
        "        torch.tensor(sla_adherences, dtype=torch.float).unsqueeze(1),\n",
        "        torch.tensor(task_priorities, dtype=torch.float).unsqueeze(1),\n",
        "        node_features_list  # Passing the node feature list too for initial printing\n",
        "    )"
      ],
      "metadata": {
        "id": "-hPB7XfGjSXd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- MODEL DEFINITION ---------------------- #\n",
        "class CustomGraphTransformerLayer(MessagePassing):\n",
        "    def __init__(self, in_features, out_features, heads=4, dropout=0.1, edge_dim=4):\n",
        "        super().__init__(aggr='add', node_dim=0)\n",
        "        self.heads = heads\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = out_features // heads\n",
        "\n",
        "        self.W_Q = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_K = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_V = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(edge_dim, heads * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(heads * 8, heads)\n",
        "        )\n",
        "        self.out_proj = nn.Linear(out_features, out_features)\n",
        "        self.gate = nn.Linear(out_features, out_features)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        Q = self.W_Q(x).view(-1, self.heads, self.head_dim)\n",
        "        K = self.W_K(x).view(-1, self.heads, self.head_dim)\n",
        "        V = self.W_V(x).view(-1, self.heads, self.head_dim)\n",
        "\n",
        "        alpha = self.compute_attention(Q, K, edge_index, edge_attr)\n",
        "        out = self.propagate(edge_index, x=V, alpha=alpha)\n",
        "        out = out.view(-1, self.heads * self.head_dim)\n",
        "        gate = torch.sigmoid(self.gate(out))\n",
        "        return self.out_proj(out * gate)\n",
        "\n",
        "    def compute_attention(self, Q, K, edge_index, edge_attr):\n",
        "        q_i, k_j = Q[edge_index[0]], K[edge_index[1]]\n",
        "        edge_weight = self.edge_mlp(edge_attr)\n",
        "        attn_scores = (q_i * k_j).sum(dim=-1) + edge_weight\n",
        "        return torch.softmax(F.leaky_relu(attn_scores), dim=0)\n",
        "\n",
        "    def message(self, x_j, alpha):\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "\n",
        "class TaskEmbeddingModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, heads=4, embedding_dim=32, lstm_hidden=32, lstm_layers=2,\n",
        "                 edge_dim=4, num_gnn_layers=2, num_transformer_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_transformer_layers = num_transformer_layers\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "\n",
        "        # Alternating Transformer and GNN layers\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            CustomGraphTransformerLayer(input_dim if i == 0 else hidden_dim, hidden_dim, heads=heads,\n",
        "                                        edge_dim=edge_dim)\n",
        "            for i in range(num_transformer_layers)])\n",
        "\n",
        "        self.gnn_layers = nn.ModuleList([\n",
        "            GATConv(hidden_dim if i == 0 else embedding_dim, embedding_dim, heads=1)  # Using GATConv\n",
        "            for i in range(num_gnn_layers)])\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden, lstm_layers, batch_first=True)\n",
        "        self.fc_time = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_sla = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_priority = nn.Linear(lstm_hidden, 1)\n",
        "\n",
        "        # Learnable task weights for dynamic loss\n",
        "        self.log_sigma_time = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_sla = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_priority = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        # Alternate Transformer and GNN layers\n",
        "        for i in range(max(self.num_transformer_layers, self.num_gnn_layers)):\n",
        "            if i < self.num_transformer_layers:\n",
        "                x = F.relu(self.transformer_layers[i](x, edge_index, edge_attr))\n",
        "            if i < self.num_gnn_layers:\n",
        "                x = F.relu(self.gnn_layers[i](x, edge_index))  # Pass edge_index to GATConv\n",
        "\n",
        "        # Graph-level read-out using global mean pooling\n",
        "        graph_embedding = global_mean_pool(x, batch)\n",
        "\n",
        "        lstm_input = x.unsqueeze(0)\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_out = lstm_out.squeeze(0)\n",
        "\n",
        "        exec_time_pred = self.fc_time(lstm_out)\n",
        "        sla_pred = torch.sigmoid(self.fc_sla(lstm_out))\n",
        "        priority_pred = torch.sigmoid(self.fc_priority(lstm_out))\n",
        "        return torch.cat([x, exec_time_pred, sla_pred, priority_pred], dim=1), graph_embedding"
      ],
      "metadata": {
        "id": "TmENhng-jWwK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "knfJP-y54Ot7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trial cell\n",
        "# ---------------------- MODEL DEFINITION ---------------------- #\n",
        "class CustomGraphTransformerLayer(MessagePassing):\n",
        "    def __init__(self, in_features, out_features, heads=4, dropout=0.1, edge_dim=4):\n",
        "        super().__init__(aggr='add', node_dim=0)\n",
        "        self.heads = heads\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = out_features // heads\n",
        "\n",
        "        self.W_Q = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_K = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.W_V = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(edge_dim, heads * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(heads * 8, heads)\n",
        "        )\n",
        "        self.out_proj = nn.Linear(out_features, out_features)\n",
        "        self.gate = nn.Linear(out_features, out_features)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        print(f\"GraphTransformerLayer input x shape: {x.shape}\")\n",
        "        Q = self.W_Q(x).view(-1, self.heads, self.head_dim)\n",
        "        print(f\"Q shape: {Q.shape}\")\n",
        "        K = self.W_K(x).view(-1, self.heads, self.head_dim)\n",
        "        V = self.W_V(x).view(-1, self.heads, self.head_dim)\n",
        "\n",
        "        alpha = self.compute_attention(Q, K, edge_index, edge_attr)\n",
        "        out = self.propagate(edge_index, x=V, alpha=alpha)\n",
        "        out = out.view(-1, self.heads * self.head_dim)\n",
        "        gate = torch.sigmoid(self.gate(out))\n",
        "        return self.out_proj(out * gate)\n",
        "\n",
        "    def compute_attention(self, Q, K, edge_index, edge_attr):\n",
        "        q_i, k_j = Q[edge_index[0]], K[edge_index[1]]\n",
        "        edge_weight = self.edge_mlp(edge_attr)\n",
        "        attn_scores = (q_i * k_j).sum(dim=-1) + edge_weight\n",
        "        return torch.softmax(F.leaky_relu(attn_scores), dim=0)\n",
        "\n",
        "    def message(self, x_j, alpha):\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "\n",
        "class TaskEmbeddingModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, heads=4, embedding_dim=32, lstm_hidden=32, lstm_layers=2,\n",
        "                 edge_dim=4, num_gnn_layers=2, num_transformer_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_transformer_layers = num_transformer_layers\n",
        "        self.num_gnn_layers = num_gnn_layers\n",
        "\n",
        "        # Initial feature projection to match hidden_dim\n",
        "        self.initial_embedding = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Transformer Layers\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            CustomGraphTransformerLayer(hidden_dim, hidden_dim, heads=heads, edge_dim=edge_dim)\n",
        "            for _ in range(num_transformer_layers)\n",
        "        ])\n",
        "\n",
        "        # Reduce transformer output to match GNN input\n",
        "        self.feature_projection = nn.Linear(hidden_dim, embedding_dim)\n",
        "\n",
        "        # GNN Layers\n",
        "        self.gnn_layers = nn.ModuleList([\n",
        "            GATConv(embedding_dim if i == 0 else embedding_dim, embedding_dim, heads=1)\n",
        "            for i in range(num_gnn_layers)\n",
        "        ])\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden, lstm_layers, batch_first=True)\n",
        "        self.fc_time = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_sla = nn.Linear(lstm_hidden, 1)\n",
        "        self.fc_priority = nn.Linear(lstm_hidden, 1)\n",
        "\n",
        "        # Learnable task weights for dynamic loss\n",
        "        self.log_sigma_time = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_sla = nn.Parameter(torch.zeros(1))\n",
        "        self.log_sigma_priority = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        x = self.initial_embedding(x)  # Ensure correct input size\n",
        "        print(f\"Initial embedding output shape: {x.shape}\")\n",
        "\n",
        "        # Transformer Layers\n",
        "        for i in range(self.num_transformer_layers):\n",
        "            x = F.relu(self.transformer_layers[i](x, edge_index, edge_attr))\n",
        "            print(f\"Transformer layer {i} output shape: {x.shape}\")\n",
        "\n",
        "        # Feature projection before GNN\n",
        "        x = self.feature_projection(x)\n",
        "        print(f\"Feature projection output shape: {x.shape}\")\n",
        "\n",
        "        # GNN Layers\n",
        "        for i in range(self.num_gnn_layers):\n",
        "            x = F.relu(self.gnn_layers[i](x, edge_index))\n",
        "            print(f\"GNN layer {i} output shape: {x.shape}\")\n",
        "\n",
        "        # Graph-level read-out using global mean pooling\n",
        "        graph_embedding = global_mean_pool(x, batch)\n",
        "        print(f\"Global mean pool output shape: {graph_embedding.shape}\")\n",
        "\n",
        "        lstm_input = x.unsqueeze(0)\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_out = lstm_out.squeeze(0)\n",
        "\n",
        "        exec_time_pred = self.fc_time(lstm_out)\n",
        "        sla_pred = torch.sigmoid(self.fc_sla(lstm_out))\n",
        "        priority_pred = torch.sigmoid(self.fc_priority(lstm_out))\n",
        "\n",
        "        return torch.cat([x, exec_time_pred, sla_pred, priority_pred], dim=1), graph_embedding\n"
      ],
      "metadata": {
        "id": "5bQY5Hef4O7j"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- TRAINING ---------------------- #\n",
        "def train_embeddings(node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities, node_features_list,\n",
        "                     epochs=500, save_path=\"./model_data\"): # Added node_feature_list and save_path\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Ensure save directory exists\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    model = TaskEmbeddingModel(node_features.size(1), num_gnn_layers=1, num_transformer_layers=1).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scaler = GradScaler() if device.type == \"cuda\" else None\n",
        "\n",
        "    data = [node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities]\n",
        "    data = [x.to(device) for x in data]\n",
        "    node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities = data\n",
        "\n",
        "    criterion_time = nn.L1Loss()\n",
        "    criterion_sla = nn.BCELoss()\n",
        "    criterion_priority = nn.L1Loss()\n",
        "\n",
        "    # Create a batch vector for graph-level pooling (assuming single graph)\n",
        "    batch = torch.zeros(node_features.size(0), dtype=torch.long).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=device.type == \"cuda\"):\n",
        "            embeddings, graph_embedding = model(node_features, edge_index, edge_attr, batch) # Get graph embedding too\n",
        "            exec_time_pred = embeddings[:, -3].unsqueeze(1)\n",
        "            sla_pred = embeddings[:, -2].unsqueeze(1)\n",
        "            priority_pred = embeddings[:, -1].unsqueeze(1)\n",
        "\n",
        "            loss_time = criterion_time(exec_time_pred, execution_times)\n",
        "            loss_sla = criterion_sla(sla_pred, sla_adherences)\n",
        "            loss_priority = criterion_priority(priority_pred, task_priorities)\n",
        "\n",
        "            # Dynamic loss weighting\n",
        "            sigma_time = torch.exp(-model.log_sigma_time)\n",
        "            sigma_sla = torch.exp(-model.log_sigma_sla)\n",
        "            sigma_priority = torch.exp(-model.log_sigma_priority)\n",
        "\n",
        "            loss_time_weighted = 0.5 * sigma_time * loss_time + 0.5 * model.log_sigma_time\n",
        "            loss_sla_weighted = 0.3 * sigma_sla * loss_sla + 0.3 * model.log_sigma_sla\n",
        "            loss_priority_weighted = 0.2 * sigma_priority * loss_priority + 0.2 * model.log_sigma_priority\n",
        "\n",
        "            loss = loss_time_weighted + loss_sla_weighted + loss_priority_weighted\n",
        "\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch}, Loss: {loss.item():.4f}, Time Loss: {loss_time.item():.4f}, SLA Loss: {loss_sla.item():.4f}, Priority Loss: {loss_priority.item():.4f}\")\n",
        "\n",
        "    # Save model, embeddings, and graph embedding after training\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, \"model.pth\"))\n",
        "\n",
        "    # Detach and move to CPU before saving as numpy arrays\n",
        "    node_embeddings_cpu = embeddings[:, :-3].detach().cpu().numpy()\n",
        "    graph_embedding_cpu = graph_embedding.detach().cpu().numpy()\n",
        "\n",
        "    np.save(os.path.join(save_path, \"task_embeddings.npy\"), node_embeddings_cpu)\n",
        "    np.save(os.path.join(save_path, \"graph_embedding.npy\"), graph_embedding_cpu)\n",
        "\n",
        "    print(f\"Model, task embeddings, and graph embedding saved to {save_path}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "_V2FqxiLjcwQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skfuzzy import control as ctrl\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import skfuzzy as fuzz\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------- Tier-1: Task Placement (Fuzzy + Neural Network) ---------------------- #\n",
        "class Tier1SchedulerEnv(gym.Env):\n",
        "    def __init__(self, task_embeddings):\n",
        "        super(Tier1SchedulerEnv, self).__init__()\n",
        "        self.task_embeddings = task_embeddings\n",
        "        self.num_tasks = task_embeddings.shape[0]\n",
        "        self.current_task = 0\n",
        "\n",
        "        # Define fuzzy variables and membership functions\n",
        "        self.execution_time = ctrl.Antecedent(np.arange(0, 1.5, 0.01), 'execution_time')\n",
        "        self.sla_adherence = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'sla_adherence')\n",
        "        self.energy_usage = ctrl.Consequent(np.arange(0, 2, 0.01), 'energy_usage')\n",
        "\n",
        "        # Use automatic membership functions (poor, average, good)\n",
        "        self.execution_time.automf(5)\n",
        "        self.sla_adherence.automf(5)\n",
        "        self.energy_usage.automf(5)\n",
        "\n",
        "        # Define fuzzy rules with correct labels\n",
        "        rule1 = ctrl.Rule(self.execution_time['good'] & self.sla_adherence['good'], self.energy_usage['poor'])\n",
        "        rule2 = ctrl.Rule(self.execution_time['average'] & self.sla_adherence['average'], self.energy_usage['average'])\n",
        "        rule3 = ctrl.Rule(self.execution_time['poor'] & self.sla_adherence['poor'], self.energy_usage['good'])\n",
        "\n",
        "        self.energy_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
        "        self.energy_sim = ctrl.ControlSystemSimulation(self.energy_ctrl)\n",
        "\n",
        "        # State and action spaces\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(task_embeddings.shape[1],), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)  # {0: Cloud, 1: Edge, 2: Hybrid}\n",
        "\n",
        "        # Neural network-based reward function\n",
        "        self.reward_net = nn.Sequential(\n",
        "          nn.Linear(task_embeddings.shape[1] + 3, 128),  # Added SLA & energy\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, 1)\n",
        "      ).to(device)\n",
        "\n",
        "    def step(self, action):\n",
        "        task_embedding = self.task_embeddings[self.current_task]\n",
        "        execution_time = task_embedding[-3].item()\n",
        "        sla_adherence = task_embedding[-2].item()\n",
        "\n",
        "        # Apply fuzzy logic for energy estimation\n",
        "        self.energy_sim.input['execution_time'] = np.clip(execution_time, 0, 1.5)\n",
        "        self.energy_sim.input['sla_adherence'] = np.clip(sla_adherence, 0, 1)\n",
        "\n",
        "        try:\n",
        "            self.energy_sim.compute()\n",
        "            energy_usage = self.energy_sim.output.get('energy_usage', execution_time * 1.0)  # Default fallback\n",
        "        except:\n",
        "            energy_usage = execution_time * 1.0  # Safe fallback\n",
        "\n",
        "        # Adjust energy usage based on action type\n",
        "        energy_usage *= (1.2 if action == 0 else 0.8 if action == 1 else 0.9) # Cloud, Edge, Hybrid\n",
        "\n",
        "        # Compute reward with neural network\n",
        "        task_embedding_tensor = torch.tensor(task_embedding, dtype=torch.float).to(device)\n",
        "        action_tensor = torch.tensor([action], dtype=torch.float).to(device)\n",
        "        sla_tensor = torch.tensor([sla_adherence], dtype=torch.float).to(device)\n",
        "        energy_tensor = torch.tensor([energy_usage], dtype=torch.float).to(device)\n",
        "\n",
        "        reward_input = torch.cat([task_embedding_tensor, action_tensor, sla_tensor, energy_tensor])\n",
        "\n",
        "        reward = self.reward_net(reward_input).item() - energy_usage\n",
        "\n",
        "        predicted_reward = self.reward_net(reward_input).item()\n",
        "\n",
        "        # Apply weights to balance SLA, execution time, and energy usage\n",
        "        reward = (\n",
        "            1.5 * predicted_reward  # Make RewardNet's output more significant\n",
        "            + 2.0 * sla_adherence  # Encourage SLA adherence\n",
        "            - 0.8 * execution_time  # Penalize long execution times\n",
        "            - 0.5 * energy_usage  # Penalize excessive energy usage\n",
        "        )\n",
        "\n",
        "\n",
        "        # Proceed to the next task\n",
        "        self.current_task += 1\n",
        "        done = self.current_task >= self.num_tasks\n",
        "        return task_embedding, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_task = 0\n",
        "        return self.task_embeddings[self.current_task]\n",
        "\n",
        "\n",
        "# ---------------------- Tier-2: Resource Allocation (Fuzzy + Linear Regression) ---------------------- #\n",
        "class Tier2SchedulerEnv(gym.Env):\n",
        "    def __init__(self, task_embeddings, server_loads):\n",
        "        super(Tier2SchedulerEnv, self).__init__()\n",
        "        self.task_embeddings = task_embeddings\n",
        "        self.num_tasks = task_embeddings.shape[0]\n",
        "        self.num_servers = len(server_loads)\n",
        "        self.server_loads = server_loads\n",
        "        self.current_task = 0\n",
        "\n",
        "        # Define fuzzy variables for server load and execution time\n",
        "        self.server_load_fuzzy = ctrl.Antecedent(np.arange(0, 1.1, 0.01), 'server_load')\n",
        "        self.execution_time_fuzzy = ctrl.Antecedent(np.arange(0, 1.6, 0.01), 'execution_time')\n",
        "        self.adjusted_resource_use = ctrl.Consequent(np.arange(0, 1.6, 0.01), 'adjusted_resource_use')\n",
        "\n",
        "        # Use correct automatic membership function names\n",
        "        self.server_load_fuzzy.automf(3)\n",
        "        self.execution_time_fuzzy.automf(3)\n",
        "        self.adjusted_resource_use.automf(3)\n",
        "\n",
        "        # Define fuzzy rules with correct labels\n",
        "        resource_rule1 = ctrl.Rule(self.server_load_fuzzy['poor'] & self.execution_time_fuzzy['poor'], self.adjusted_resource_use['poor'])\n",
        "        resource_rule2 = ctrl.Rule(self.server_load_fuzzy['average'] | self.execution_time_fuzzy['average'], self.adjusted_resource_use['average'])\n",
        "        resource_rule3 = ctrl.Rule(self.server_load_fuzzy['good'] | self.execution_time_fuzzy['good'], self.adjusted_resource_use['good'])\n",
        "\n",
        "        self.resource_ctrl = ctrl.ControlSystem([resource_rule1, resource_rule2, resource_rule3])\n",
        "        self.resource_sim = ctrl.ControlSystemSimulation(self.resource_ctrl)\n",
        "\n",
        "        # State and action spaces\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(task_embeddings.shape[1] + self.num_servers,), dtype=np.float32)\n",
        "        self.action_space = spaces.MultiDiscrete([self.num_servers, 3])  # (server_id, execution_strategy)\n",
        "\n",
        "        # Linear Regression model for rule weighting\n",
        "        self.rule_weights = LinearRegression()\n",
        "        self.rule_weights.fit(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([0.2, 0.5, 0.7, 1.0]))\n",
        "\n",
        "    def step(self, action):\n",
        "        server_id, execution_strategy = action\n",
        "        task_embedding = self.task_embeddings[self.current_task]\n",
        "        server_load = self.server_loads[server_id]\n",
        "        execution_time = task_embedding[-3].item()\n",
        "\n",
        "        normalized_server_load = server_load / max(self.server_loads)\n",
        "        normalized_execution_time = execution_time / 1.5  # Normalize execution time\n",
        "\n",
        "        predicted_weights = np.clip(\n",
        "            self.rule_weights.predict([[normalized_server_load, normalized_execution_time]]),\n",
        "            0, 1\n",
        "        )\n",
        "\n",
        "        # Apply fuzzy logic for resource use adjustment\n",
        "        self.resource_sim.input['server_load'] = np.clip(server_load, 0, 1)\n",
        "        self.resource_sim.input['execution_time'] = np.clip(execution_time, 0, 1.5)\n",
        "        self.resource_sim.compute()\n",
        "        resource_usage_multiplier = self.resource_sim.output['adjusted_resource_use']\n",
        "\n",
        "        adjusted_time = execution_time * (0.8 if execution_strategy == 0 else 1.1 if execution_strategy == 1 else 1.3) * resource_usage_multiplier\n",
        "        adjusted_energy = execution_time * (1.5 if execution_strategy == 0 else 1.0 if execution_strategy == 1 else 0.8) * resource_usage_multiplier\n",
        "\n",
        "        reward = (\n",
        "          - adjusted_time  # Penalize execution time\n",
        "          - adjusted_energy  # Penalize high energy usage\n",
        "          + 3.0 * task_embedding[-2].item()  # Encourage SLA adherence\n",
        "          - 1.0 * server_load  # Penalize overloaded servers (Reduce weight)\n",
        "      )\n",
        "\n",
        "        self.server_loads[server_id] += min(0.1, 1.0 - self.server_loads[server_id])\n",
        "\n",
        "\n",
        "        self.current_task += 1\n",
        "        done = self.current_task >= self.num_tasks\n",
        "        return np.concatenate([task_embedding, self.server_loads]), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_task = 0\n",
        "        return np.concatenate([self.task_embeddings[self.current_task], self.server_loads])\n"
      ],
      "metadata": {
        "id": "j_f8JO8WjkDH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vy2-MbZxlziL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare data\n",
        "workflow_dag = load_dag(\"cybershake_dag.json\")\n",
        "(node_features, edge_index, edge_attr, adjacency_matrix, execution_times, sla_adherences,\n",
        "task_priorities, node_features_list) = prepare_workflow_dag(workflow_dag) # Get node feature list too\n",
        "# Print initial node features\n",
        "print(\"Initial Node Features:\")\n",
        "for i, features in enumerate(node_features_list):  # Print list before converting to tensor\n",
        "    print(f\"Node {i}: {features}\")\n",
        "# Train the GNN-based task embedding model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "embedding_model_save_path = \"./embedding_model_data\"\n",
        "model = train_embeddings(node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "                        task_priorities, node_features_list, save_path=embedding_model_save_path)\n",
        "\n",
        "# Generate task embeddings\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    task_embeddings, graph_embedding = model(node_features.to(device), edge_index.to(device), edge_attr.to(device), torch.zeros(node_features.size(0), dtype=torch.long).to(device)) # Get task embeddings\n",
        "    task_embeddings = task_embeddings[:, :-3].cpu().numpy()  # Move to CPU and convert to numpy\n",
        "\n",
        "\n",
        "\n",
        "  # Evaluate the pipeline\n",
        "  #evaluate_pipeline(workflow_dag, embedding_model_path=embedding_model_save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZUNG2EAeW5_",
        "outputId": "46224291-a63a-485d-a4bc-2479d43bde88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Node Features:\n",
            "Node 0: [-0.7908287615665436, 0, 0, 0.497, 0.0, 0.018099045081057072, 4.0, 0.999, 0.003, 0.4974974974974975]\n",
            "Node 1: [-0.5582804480397533, 0, 0, 0.497, 0.0, 0.0490228736397957, 3.0, 0.997, 0.002, 0.4974974974974975]\n",
            "Node 2: [3.1896301633246904, 0, 0, 0.0, 0.109, 0.5474128358871865, 1.0, 0.0, 0.0, 0.1091091091091091]\n",
            "Node 3: [0.8912846229925903, 0, 0, 0.001, 0.002, 0.24178325560737288, 2.0, 0.004, 0.001, 0.003003003003003003]\n",
            "Node 4: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.501, 0.002, 0.002002002002002002]\n",
            "Node 5: [0.14353950714612498, 0, 0, 0.001, 0.002, 0.1423495447479458, 2.0, 0.005, 0.001, 0.003003003003003003]\n",
            "Node 6: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.502, 0.002, 0.002002002002002002]\n",
            "Node 7: [0.4846382004161205, 0, 0, 0.001, 0.002, 0.18770819453697532, 2.0, 0.006, 0.001, 0.003003003003003003]\n",
            "Node 8: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 3.0, 0.503, 0.002, 0.002002002002002002]\n",
            "Node 9: [0.35354274180317236, 0, 0, 0.001, 0.002, 0.17027537197423936, 2.0, 0.007, 0.001, 0.003003003003003003]\n",
            "Node 10: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.504, 0.002, 0.002002002002002002]\n",
            "Node 11: [1.3893638654296827, 0, 0, 0.001, 0.002, 0.3080168776371308, 2.0, 0.008, 0.001, 0.003003003003003003]\n",
            "Node 12: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 3.0, 0.505, 0.002, 0.002002002002002002]\n",
            "Node 13: [0.15063703197548833, 0, 0, 0.001, 0.002, 0.14329335998223405, 2.0, 0.009, 0.001, 0.003003003003003003]\n",
            "Node 14: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.506, 0.002, 0.002002002002002002]\n",
            "Node 15: [1.0954428372019267, 0, 0, 0.001, 0.002, 0.2689318232289585, 2.0, 0.01, 0.001, 0.003003003003003003]\n",
            "Node 16: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.507, 0.002, 0.002002002002002002]\n",
            "Node 17: [1.1388629890992088, 0, 0, 0.001, 0.002, 0.2747057517210748, 2.0, 0.011, 0.001, 0.003003003003003003]\n",
            "Node 18: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.508, 0.002, 0.002002002002002002]\n",
            "Node 19: [0.049601678522197185, 0, 0, 0.001, 0.002, 0.12985787252942482, 2.0, 0.012, 0.001, 0.003003003003003003]\n",
            "Node 20: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.509, 0.002, 0.002002002002002002]\n",
            "Node 21: [1.7534251390299718, 0, 0, 0.001, 0.002, 0.3564290473017988, 2.0, 0.013, 0.001, 0.003003003003003003]\n",
            "Node 22: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 3.0, 0.51, 0.002, 0.002002002002002002]\n",
            "Node 23: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.014, 0.001, 0.003003003003003003]\n",
            "Node 24: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 3.0, 0.511, 0.002, 0.002002002002002002]\n",
            "Node 25: [1.3960438887984952, 0, 0, 0.001, 0.002, 0.3089051743282256, 2.0, 0.015, 0.001, 0.003003003003003003]\n",
            "Node 26: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 3.0, 0.512, 0.002, 0.002002002002002002]\n",
            "Node 27: [0.3218126308013124, 0, 0, 0.001, 0.002, 0.16605596269153894, 2.0, 0.016, 0.001, 0.003003003003003003]\n",
            "Node 28: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.513, 0.002, 0.002002002002002002]\n",
            "Node 29: [0.04459166099558766, 0, 0, 0.001, 0.002, 0.12919165001110372, 2.0, 0.017, 0.001, 0.003003003003003003]\n",
            "Node 30: [-0.9114866836657218, 0, 0, 0.001, 0.001, 0.0020541860981567843, 3.0, 0.514, 0.002, 0.002002002002002002]\n",
            "Node 31: [1.4048114194700623, 0, 0, 0.001, 0.002, 0.31007106373528753, 2.0, 0.018, 0.001, 0.003003003003003003]\n",
            "Node 32: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.515, 0.002, 0.002002002002002002]\n",
            "Node 33: [0.1147319063681204, 0, 0, 0.001, 0.002, 0.13851876526759938, 2.0, 0.019, 0.001, 0.003003003003003003]\n",
            "Node 34: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.516, 0.002, 0.002002002002002002]\n",
            "Node 35: [0.8019393104347211, 0, 0, 0.001, 0.002, 0.22990228736397955, 2.0, 0.02, 0.001, 0.003003003003003003]\n",
            "Node 36: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.517, 0.002, 0.002002002002002002]\n",
            "Node 37: [1.2231982841304683, 0, 0, 0.001, 0.002, 0.28592049744614695, 2.0, 0.021, 0.001, 0.003003003003003003]\n",
            "Node 38: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.518, 0.002, 0.002002002002002002]\n",
            "Node 39: [1.3689062938626941, 0, 0, 0.001, 0.002, 0.3052964690206529, 2.0, 0.022, 0.001, 0.003003003003003003]\n",
            "Node 40: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.519, 0.002, 0.002002002002002002]\n",
            "Node 41: [0.400302905384861, 0, 0, 0.001, 0.002, 0.17649344881190318, 2.0, 0.023, 0.001, 0.003003003003003003]\n",
            "Node 42: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.52, 0.002, 0.002002002002002002]\n",
            "Node 43: [0.08383679828736199, 0, 0, 0.001, 0.002, 0.1344103930712858, 2.0, 0.024, 0.001, 0.003003003003003003]\n",
            "Node 44: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.521, 0.002, 0.002002002002002002]\n",
            "Node 45: [0.125586944342441, 0, 0, 0.001, 0.002, 0.13996224739062846, 2.0, 0.025, 0.001, 0.003003003003003003]\n",
            "Node 46: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 3.0, 0.522, 0.002, 0.002002002002002002]\n",
            "Node 47: [0.9772899238660527, 0, 0, 0.001, 0.002, 0.2532200755052187, 2.0, 0.026, 0.001, 0.003003003003003003]\n",
            "Node 48: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.523, 0.002, 0.002002002002002002]\n",
            "Node 49: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 2.0, 0.027, 0.001, 0.003003003003003003]\n",
            "Node 50: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.524, 0.002, 0.002002002002002002]\n",
            "Node 51: [0.5209608274840392, 0, 0, 0.001, 0.002, 0.19253830779480344, 2.0, 0.028, 0.001, 0.003003003003003003]\n",
            "Node 52: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 3.0, 0.525, 0.002, 0.002002002002002002]\n",
            "Node 53: [1.0136125509339717, 0, 0, 0.001, 0.002, 0.25805018876304686, 2.0, 0.029, 0.001, 0.003003003003003003]\n",
            "Node 54: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.526, 0.002, 0.002002002002002002]\n",
            "Node 55: [0.155229548041547, 0, 0, 0.001, 0.002, 0.14390406395736174, 2.0, 0.03, 0.001, 0.003003003003003003]\n",
            "Node 56: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.527, 0.002, 0.002002002002002002]\n",
            "Node 57: [0.8908671215320395, 0, 0, 0.001, 0.002, 0.24172773706417944, 2.0, 0.031, 0.001, 0.003003003003003003]\n",
            "Node 58: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.528, 0.002, 0.002002002002002002]\n",
            "Node 59: [0.6219961809373304, 0, 0, 0.001, 0.002, 0.20597379524761267, 2.0, 0.032, 0.001, 0.003003003003003003]\n",
            "Node 60: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 3.0, 0.529, 0.002, 0.002002002002002002]\n",
            "Node 61: [1.7550951448721752, 0, 0, 0.001, 0.002, 0.3566511214745725, 2.0, 0.033, 0.001, 0.003003003003003003]\n",
            "Node 62: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.53, 0.002, 0.002002002002002002]\n",
            "Node 63: [0.6499687787942334, 0, 0, 0.001, 0.002, 0.20969353764157228, 2.0, 0.034, 0.001, 0.003003003003003003]\n",
            "Node 64: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 3.0, 0.531, 0.002, 0.002002002002002002]\n",
            "Node 65: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.035, 0.001, 0.003003003003003003]\n",
            "Node 66: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.532, 0.002, 0.002002002002002002]\n",
            "Node 67: [1.1150654058478138, 0, 0, 0.001, 0.002, 0.2715411947590495, 2.0, 0.036, 0.001, 0.003003003003003003]\n",
            "Node 68: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.533, 0.002, 0.002002002002002002]\n",
            "Node 69: [1.2227807826699175, 0, 0, 0.001, 0.002, 0.2858649789029536, 2.0, 0.037, 0.001, 0.003003003003003003]\n",
            "Node 70: [-0.8981266369280967, 0, 0, 0.001, 0.001, 0.0038307794803464344, 3.0, 0.534, 0.002, 0.002002002002002002]\n",
            "Node 71: [1.4110739413783238, 0, 0, 0.001, 0.002, 0.3109038418831889, 2.0, 0.038, 0.001, 0.003003003003003003]\n",
            "Node 72: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.535, 0.002, 0.002002002002002002]\n",
            "Node 73: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 2.0, 0.039, 0.001, 0.003003003003003003]\n",
            "Node 74: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.536, 0.002, 0.002002002002002002]\n",
            "Node 75: [0.3255701439462695, 0, 0, 0.001, 0.002, 0.1665556295802798, 2.0, 0.04, 0.001, 0.003003003003003003]\n",
            "Node 76: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.537, 0.002, 0.002002002002002002]\n",
            "Node 77: [1.4778741750664504, 0, 0, 0.001, 0.002, 0.3197868087941372, 2.0, 0.041, 0.001, 0.003003003003003003]\n",
            "Node 78: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.538, 0.002, 0.002002002002002002]\n",
            "Node 79: [1.4507365801306489, 0, 0, 0.001, 0.002, 0.3161781034865645, 2.0, 0.042, 0.001, 0.003003003003003003]\n",
            "Node 80: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.539, 0.002, 0.002002002002002002]\n",
            "Node 81: [0.342270202368301, 0, 0, 0.001, 0.002, 0.16877637130801684, 2.0, 0.043, 0.001, 0.003003003003003003]\n",
            "Node 82: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.54, 0.002, 0.002002002002002002]\n",
            "Node 83: [1.2732984593965633, 0, 0, 0.001, 0.002, 0.2925827226293582, 2.0, 0.044, 0.001, 0.003003003003003003]\n",
            "Node 84: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.541, 0.002, 0.002002002002002002]\n",
            "Node 85: [0.27630497160127626, 0, 0, 0.001, 0.002, 0.16000444148345547, 2.0, 0.045, 0.001, 0.003003003003003003]\n",
            "Node 86: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.542, 0.002, 0.002002002002002002]\n",
            "Node 87: [0.9877274603798225, 0, 0, 0.001, 0.002, 0.25460803908505436, 2.0, 0.046, 0.001, 0.003003003003003003]\n",
            "Node 88: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.543, 0.002, 0.002002002002002002]\n",
            "Node 89: [1.1271729482037867, 0, 0, 0.001, 0.002, 0.2731512325116589, 2.0, 0.047, 0.001, 0.003003003003003003]\n",
            "Node 90: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 3.0, 0.544, 0.002, 0.002002002002002002]\n",
            "Node 91: [0.6140636531868655, 0, 0, 0.001, 0.002, 0.20491894292693758, 2.0, 0.048, 0.001, 0.003003003003003003]\n",
            "Node 92: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 3.0, 0.545, 0.002, 0.002002002002002002]\n",
            "Node 93: [0.03164911571851322, 0, 0, 0.001, 0.002, 0.12747057517210747, 2.0, 0.049, 0.001, 0.003003003003003003]\n",
            "Node 94: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 3.0, 0.546, 0.002, 0.002002002002002002]\n",
            "Node 95: [1.1547280446001387, 0, 0, 0.001, 0.002, 0.276815456362425, 2.0, 0.05, 0.001, 0.003003003003003003]\n",
            "Node 96: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 3.0, 0.547, 0.002, 0.002002002002002002]\n",
            "Node 97: [1.0754027670954884, 0, 0, 0.001, 0.002, 0.26626693315567396, 2.0, 0.051, 0.001, 0.003003003003003003]\n",
            "Node 98: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.548, 0.002, 0.002002002002002002]\n",
            "Node 99: [1.3167186112938454, 0, 0, 0.001, 0.002, 0.2983566511214746, 2.0, 0.052, 0.001, 0.003003003003003003]\n",
            "Node 100: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 3.0, 0.549, 0.002, 0.002002002002002002]\n",
            "Node 101: [1.3125435966883374, 0, 0, 0.001, 0.002, 0.2978014656895403, 2.0, 0.053, 0.001, 0.003003003003003003]\n",
            "Node 102: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 3.0, 0.55, 0.002, 0.002002002002002002]\n",
            "Node 103: [1.3405161945452402, 0, 0, 0.001, 0.002, 0.30152120808349986, 2.0, 0.054, 0.001, 0.003003003003003003]\n",
            "Node 104: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.551, 0.002, 0.002002002002002002]\n",
            "Node 105: [1.1605730650478496, 0, 0, 0.001, 0.002, 0.277592715967133, 2.0, 0.055, 0.001, 0.003003003003003003]\n",
            "Node 106: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.552, 0.002, 0.002002002002002002]\n",
            "Node 107: [0.2696249482324636, 0, 0, 0.001, 0.002, 0.15911614479236064, 2.0, 0.056, 0.001, 0.003003003003003003]\n",
            "Node 108: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.553, 0.002, 0.002002002002002002]\n",
            "Node 109: [0.6424537525043192, 0, 0, 0.001, 0.002, 0.2086942038640906, 2.0, 0.057, 0.001, 0.003003003003003003]\n",
            "Node 110: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.554, 0.002, 0.002002002002002002]\n",
            "Node 111: [1.7258700426336198, 0, 0, 0.001, 0.002, 0.35276482345103266, 2.0, 0.058, 0.001, 0.003003003003003003]\n",
            "Node 112: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 3.0, 0.555, 0.002, 0.002002002002002002]\n",
            "Node 113: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.059, 0.001, 0.003003003003003003]\n",
            "Node 114: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 3.0, 0.556, 0.002, 0.002002002002002002]\n",
            "Node 115: [1.7112574915143424, 0, 0, 0.001, 0.002, 0.3508216744392627, 2.0, 0.06, 0.001, 0.003003003003003003]\n",
            "Node 116: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.557, 0.002, 0.002002002002002002]\n",
            "Node 117: [0.4144979550435877, 0, 0, 0.001, 0.002, 0.17838107928047964, 2.0, 0.061, 0.001, 0.003003003003003003]\n",
            "Node 118: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.558, 0.002, 0.002002002002002002]\n",
            "Node 119: [1.3743338128498543, 0, 0, 0.001, 0.002, 0.3060182100821674, 2.0, 0.062, 0.001, 0.003003003003003003]\n",
            "Node 120: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 3.0, 0.559, 0.002, 0.002002002002002002]\n",
            "Node 121: [0.06630173694422874, 0, 0, 0.001, 0.002, 0.13207861425716186, 2.0, 0.063, 0.001, 0.003003003003003003]\n",
            "Node 122: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.56, 0.002, 0.002002002002002002]\n",
            "Node 123: [1.6966449403950643, 0, 0, 0.001, 0.002, 0.3488785254274928, 2.0, 0.064, 0.001, 0.003003003003003003]\n",
            "Node 124: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 3.0, 0.561, 0.002, 0.002002002002002002]\n",
            "Node 125: [1.3831013435214212, 0, 0, 0.001, 0.002, 0.3071840994892294, 2.0, 0.065, 0.001, 0.003003003003003003]\n",
            "Node 126: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 3.0, 0.562, 0.002, 0.002002002002002002]\n",
            "Node 127: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 2.0, 0.066, 0.001, 0.003003003003003003]\n",
            "Node 128: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 3.0, 0.563, 0.002, 0.002002002002002002]\n",
            "Node 129: [0.1869596590434071, 0, 0, 0.001, 0.002, 0.14812347324006217, 2.0, 0.067, 0.001, 0.003003003003003003]\n",
            "Node 130: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.564, 0.002, 0.002002002002002002]\n",
            "Node 131: [1.1133954000056105, 0, 0, 0.001, 0.002, 0.2713191205862758, 2.0, 0.068, 0.001, 0.003003003003003003]\n",
            "Node 132: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.565, 0.002, 0.002002002002002002]\n",
            "Node 133: [0.9468123172458452, 0, 0, 0.001, 0.002, 0.24916722185209858, 2.0, 0.069, 0.001, 0.003003003003003003]\n",
            "Node 134: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.566, 0.002, 0.002002002002002002]\n",
            "Node 135: [0.8507869813191636, 0, 0, 0.001, 0.002, 0.23639795691761048, 2.0, 0.07, 0.001, 0.003003003003003003]\n",
            "Node 136: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.567, 0.002, 0.002002002002002002]\n",
            "Node 137: [0.32306513518296465, 0, 0, 0.001, 0.002, 0.16622251832111923, 2.0, 0.071, 0.001, 0.003003003003003003]\n",
            "Node 138: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.568, 0.002, 0.002002002002002002]\n",
            "Node 139: [0.704243968665836, 0, 0, 0.001, 0.002, 0.2169109482567177, 2.0, 0.072, 0.001, 0.003003003003003003]\n",
            "Node 140: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 3.0, 0.569, 0.002, 0.002002002002002002]\n",
            "Node 141: [0.7660341848273532, 0, 0, 0.001, 0.002, 0.22512769264934487, 2.0, 0.073, 0.001, 0.003003003003003003]\n",
            "Node 142: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.57, 0.002, 0.002002002002002002]\n",
            "Node 143: [1.299601051411263, 0, 0, 0.001, 0.002, 0.2960803908505441, 2.0, 0.074, 0.001, 0.003003003003003003]\n",
            "Node 144: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.571, 0.002, 0.002002002002002002]\n",
            "Node 145: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 2.0, 0.075, 0.001, 0.003003003003003003]\n",
            "Node 146: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.572, 0.002, 0.002002002002002002]\n",
            "Node 147: [0.40907043605642734, 0, 0, 0.001, 0.002, 0.1776593382189651, 2.0, 0.076, 0.001, 0.003003003003003003]\n",
            "Node 148: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.573, 0.002, 0.002002002002002002]\n",
            "Node 149: [0.9910674720642291, 0, 0, 0.001, 0.002, 0.2550521874306018, 2.0, 0.077, 0.001, 0.003003003003003003]\n",
            "Node 150: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 3.0, 0.574, 0.002, 0.002002002002002002]\n",
            "Node 151: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 2.0, 0.078, 0.001, 0.003003003003003003]\n",
            "Node 152: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.575, 0.002, 0.002002002002002002]\n",
            "Node 153: [1.6640798264721026, 0, 0, 0.001, 0.002, 0.34454807905840545, 2.0, 0.079, 0.001, 0.003003003003003003]\n",
            "Node 154: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 3.0, 0.576, 0.002, 0.002002002002002002]\n",
            "Node 155: [1.2975135441085088, 0, 0, 0.001, 0.002, 0.29580279813457694, 2.0, 0.08, 0.001, 0.003003003003003003]\n",
            "Node 156: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.577, 0.002, 0.002002002002002002]\n",
            "Node 157: [0.9960774895908384, 0, 0, 0.001, 0.002, 0.2557184099489229, 2.0, 0.081, 0.001, 0.003003003003003003]\n",
            "Node 158: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.578, 0.002, 0.002002002002002002]\n",
            "Node 159: [0.14938452759383591, 0, 0, 0.001, 0.002, 0.14312680435265376, 2.0, 0.082, 0.001, 0.003003003003003003]\n",
            "Node 160: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.579, 0.002, 0.002002002002002002]\n",
            "Node 161: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.083, 0.001, 0.003003003003003003]\n",
            "Node 162: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.58, 0.002, 0.002002002002002002]\n",
            "Node 163: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 2.0, 0.084, 0.001, 0.003003003003003003]\n",
            "Node 164: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.581, 0.002, 0.002002002002002002]\n",
            "Node 165: [-0.012606039099870637, 0, 0, 0.001, 0.002, 0.12158560959360425, 2.0, 0.085, 0.001, 0.003003003003003003]\n",
            "Node 166: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.582, 0.002, 0.002002002002002002]\n",
            "Node 167: [0.5714785042106848, 0, 0, 0.001, 0.002, 0.19925605152120807, 2.0, 0.086, 0.001, 0.003003003003003003]\n",
            "Node 168: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 3.0, 0.583, 0.002, 0.002002002002002002]\n",
            "Node 169: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 2.0, 0.087, 0.001, 0.003003003003003003]\n",
            "Node 170: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.584, 0.002, 0.002002002002002002]\n",
            "Node 171: [0.020794077744192608, 0, 0, 0.001, 0.002, 0.1260270930490784, 2.0, 0.088, 0.001, 0.003003003003003003]\n",
            "Node 172: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.585, 0.002, 0.002002002002002002]\n",
            "Node 173: [0.6971464438364728, 0, 0, 0.001, 0.002, 0.21596713302242948, 2.0, 0.089, 0.001, 0.003003003003003003]\n",
            "Node 174: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.586, 0.002, 0.002002002002002002]\n",
            "Node 175: [1.3810138362186668, 0, 0, 0.001, 0.002, 0.30690650677326226, 2.0, 0.09, 0.001, 0.003003003003003003]\n",
            "Node 176: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 3.0, 0.587, 0.002, 0.002002002002002002]\n",
            "Node 177: [0.5840035480272087, 0, 0, 0.001, 0.002, 0.20092160781701088, 2.0, 0.091, 0.001, 0.003003003003003003]\n",
            "Node 178: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.588, 0.002, 0.002002002002002002]\n",
            "Node 179: [1.1935556804313623, 0, 0, 0.001, 0.002, 0.28197868087941375, 2.0, 0.092, 0.001, 0.003003003003003003]\n",
            "Node 180: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 3.0, 0.589, 0.002, 0.002002002002002002]\n",
            "Node 181: [0.2550123971131859, 0, 0, 0.001, 0.002, 0.1571729957805907, 2.0, 0.093, 0.001, 0.003003003003003003]\n",
            "Node 182: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.59, 0.002, 0.002002002002002002]\n",
            "Node 183: [1.3956263873379449, 0, 0, 0.001, 0.002, 0.30884965578503215, 2.0, 0.094, 0.001, 0.003003003003003003]\n",
            "Node 184: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 3.0, 0.591, 0.002, 0.002002002002002002]\n",
            "Node 185: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 2.0, 0.095, 0.001, 0.003003003003003003]\n",
            "Node 186: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 3.0, 0.592, 0.002, 0.002002002002002002]\n",
            "Node 187: [1.7145975031987486, 0, 0, 0.001, 0.002, 0.3512658227848101, 2.0, 0.096, 0.001, 0.003003003003003003]\n",
            "Node 188: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 3.0, 0.593, 0.002, 0.002002002002002002]\n",
            "Node 189: [1.6198246716537188, 0, 0, 0.001, 0.002, 0.33866311347990224, 2.0, 0.097, 0.001, 0.003003003003003003]\n",
            "Node 190: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.594, 0.002, 0.002002002002002002]\n",
            "Node 191: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 2.0, 0.098, 0.001, 0.003003003003003003]\n",
            "Node 192: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.595, 0.002, 0.002002002002002002]\n",
            "Node 193: [1.4916517232646265, 0, 0, 0.001, 0.002, 0.3216189207195203, 2.0, 0.099, 0.001, 0.003003003003003003]\n",
            "Node 194: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 3.0, 0.596, 0.002, 0.002002002002002002]\n",
            "Node 195: [0.8850221010843284, 0, 0, 0.001, 0.002, 0.24095047745947148, 2.0, 0.1, 0.001, 0.003003003003003003]\n",
            "Node 196: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.597, 0.002, 0.002002002002002002]\n",
            "Node 197: [0.24707986936272097, 0, 0, 0.001, 0.002, 0.15611814345991562, 2.0, 0.101, 0.001, 0.003003003003003003]\n",
            "Node 198: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.598, 0.002, 0.002002002002002002]\n",
            "Node 199: [0.2917525256416554, 0, 0, 0.001, 0.002, 0.16205862758161224, 2.0, 0.102, 0.001, 0.003003003003003003]\n",
            "Node 200: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 3.0, 0.599, 0.002, 0.002002002002002002]\n",
            "Node 201: [0.557283454551958, 0, 0, 0.001, 0.002, 0.19736842105263158, 2.0, 0.103, 0.001, 0.003003003003003003]\n",
            "Node 202: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 3.0, 0.6, 0.002, 0.002002002002002002]\n",
            "Node 203: [0.6925539277704141, 0, 0, 0.001, 0.002, 0.2153564290473018, 2.0, 0.104, 0.001, 0.003003003003003003]\n",
            "Node 204: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.601, 0.002, 0.002002002002002002]\n",
            "Node 205: [0.8637295265962379, 0, 0, 0.001, 0.002, 0.23811903175660667, 2.0, 0.105, 0.001, 0.003003003003003003]\n",
            "Node 206: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.602, 0.002, 0.002002002002002002]\n",
            "Node 207: [0.02496909234970057, 0, 0, 0.001, 0.002, 0.12658227848101267, 2.0, 0.106, 0.001, 0.003003003003003003]\n",
            "Node 208: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.603, 0.002, 0.002002002002002002]\n",
            "Node 209: [0.5510209326436962, 0, 0, 0.001, 0.002, 0.1965356429047302, 2.0, 0.107, 0.001, 0.003003003003003003]\n",
            "Node 210: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 3.0, 0.604, 0.002, 0.002002002002002002]\n",
            "Node 211: [0.6837863970988476, 0, 0, 0.001, 0.002, 0.21419053964023985, 2.0, 0.108, 0.001, 0.003003003003003003]\n",
            "Node 212: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 3.0, 0.605, 0.002, 0.002002002002002002]\n",
            "Node 213: [0.3456102140527074, 0, 0, 0.001, 0.002, 0.16922051965356427, 2.0, 0.109, 0.001, 0.003003003003003003]\n",
            "Node 214: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.606, 0.002, 0.002002002002002002]\n",
            "Node 215: [0.8424369521081477, 0, 0, 0.001, 0.002, 0.23528758605374192, 2.0, 0.11, 0.001, 0.003003003003003003]\n",
            "Node 216: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.607, 0.002, 0.002002002002002002]\n",
            "Node 217: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 2.0, 0.111, 0.001, 0.003003003003003003]\n",
            "Node 218: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.608, 0.002, 0.002002002002002002]\n",
            "Node 219: [1.673682360064771, 0, 0, 0.001, 0.002, 0.3458250055518543, 2.0, 0.112, 0.001, 0.003003003003003003]\n",
            "Node 220: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 3.0, 0.609, 0.002, 0.002002002002002002]\n",
            "Node 221: [6.593102069734732, 0, 0, 0.0, 0.125, 1.0, 0.0, 0.001, 0.0, 0.12512512512512514]\n",
            "Node 222: [0.9217622296127977, 0, 0, 0.001, 0.002, 0.245836109260493, 0.0, 0.113, 0.0, 0.003003003003003003]\n",
            "Node 223: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.61, 0.0, 0.002002002002002002]\n",
            "Node 224: [1.682032389275787, 0, 0, 0.001, 0.002, 0.34693537641572286, 0.0, 0.114, 0.0, 0.003003003003003003]\n",
            "Node 225: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.611, 0.0, 0.002002002002002002]\n",
            "Node 226: [0.6533087904786397, 0, 0, 0.001, 0.002, 0.21013768598711965, 0.0, 0.115, 0.0, 0.003003003003003003]\n",
            "Node 227: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.612, 0.0, 0.002002002002002002]\n",
            "Node 228: [1.2344708235653397, 0, 0, 0.001, 0.002, 0.28741949811236955, 0.0, 0.116, 0.0, 0.003003003003003003]\n",
            "Node 229: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.613, 0.0, 0.002002002002002002]\n",
            "Node 230: [0.8023568118952717, 0, 0, 0.001, 0.002, 0.22995780590717296, 0.0, 0.117, 0.0, 0.003003003003003003]\n",
            "Node 231: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.614, 0.0, 0.002002002002002002]\n",
            "Node 232: [1.7672026872281477, 0, 0, 0.001, 0.002, 0.3582611592271819, 0.0, 0.118, 0.0, 0.003003003003003003]\n",
            "Node 233: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.615, 0.0, 0.002002002002002002]\n",
            "Node 234: [0.9305297602843644, 0, 0, 0.001, 0.002, 0.24700199866755496, 0.0, 0.119, 0.0, 0.003003003003003003]\n",
            "Node 235: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.616, 0.0, 0.002002002002002002]\n",
            "Node 236: [0.6683388430584681, 0, 0, 0.001, 0.002, 0.21213635354208304, 0.0, 0.12, 0.0, 0.003003003003003003]\n",
            "Node 237: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.617, 0.0, 0.002002002002002002]\n",
            "Node 238: [1.5830845431252494, 0, 0, 0.001, 0.002, 0.3337774816788807, 0.0, 0.121, 0.0, 0.003003003003003003]\n",
            "Node 239: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.618, 0.0, 0.002002002002002002]\n",
            "Node 240: [0.9209272266916964, 0, 0, 0.001, 0.002, 0.24572507217410614, 0.0, 0.122, 0.0, 0.003003003003003003]\n",
            "Node 241: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.619, 0.0, 0.002002002002002002]\n",
            "Node 242: [1.1584855577450959, 0, 0, 0.001, 0.002, 0.27731512325116586, 0.0, 0.123, 0.0, 0.003003003003003003]\n",
            "Node 243: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.62, 0.0, 0.002002002002002002]\n",
            "Node 244: [0.3431052052894026, 0, 0, 0.001, 0.002, 0.16888740839440372, 0.0, 0.124, 0.0, 0.003003003003003003]\n",
            "Node 245: [-0.8851840916510221, 0, 0, 0.001, 0.001, 0.00555185431934266, 0.0, 0.621, 0.0, 0.002002002002002002]\n",
            "Node 246: [1.0006700056568971, 0, 0, 0.001, 0.002, 0.2563291139240506, 0.0, 0.125, 0.0, 0.003003003003003003]\n",
            "Node 247: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.622, 0.0, 0.002002002002002002]\n",
            "Node 248: [0.9923199764458815, 0, 0, 0.001, 0.002, 0.2552187430601821, 0.0, 0.126, 0.0, 0.003003003003003003]\n",
            "Node 249: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.623, 0.0, 0.002002002002002002]\n",
            "Node 250: [0.5393308917482741, 0, 0, 0.001, 0.002, 0.19498112369531423, 0.0, 0.127, 0.0, 0.003003003003003003]\n",
            "Node 251: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.624, 0.0, 0.002002002002002002]\n",
            "Node 252: [0.157317055344301, 0, 0, 0.001, 0.002, 0.14418165667332888, 0.0, 0.128, 0.0, 0.003003003003003003]\n",
            "Node 253: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.625, 0.0, 0.002002002002002002]\n",
            "Node 254: [0.8679045412017459, 0, 0, 0.001, 0.002, 0.23867421718854095, 0.0, 0.129, 0.0, 0.003003003003003003]\n",
            "Node 255: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.626, 0.0, 0.002002002002002002]\n",
            "Node 256: [0.781899240328283, 0, 0, 0.001, 0.002, 0.22723739729069506, 0.0, 0.13, 0.0, 0.003003003003003003]\n",
            "Node 257: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.627, 0.0, 0.002002002002002002]\n",
            "Node 258: [0.3940403834765989, 0, 0, 0.001, 0.002, 0.17566067066400176, 0.0, 0.131, 0.0, 0.003003003003003003]\n",
            "Node 259: [-0.9110691822051711, 0, 0, 0.001, 0.001, 0.002109704641350211, 0.0, 0.628, 0.0, 0.002002002002002002]\n",
            "Node 260: [1.2553458965928792, 0, 0, 0.001, 0.002, 0.29019542527204084, 0.0, 0.132, 0.0, 0.003003003003003003]\n",
            "Node 261: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.629, 0.0, 0.002002002002002002]\n",
            "Node 262: [0.10972188884151088, 0, 0, 0.001, 0.002, 0.13785254274927825, 0.0, 0.133, 0.0, 0.003003003003003003]\n",
            "Node 263: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.63, 0.0, 0.002002002002002002]\n",
            "Node 264: [0.08007928514240488, 0, 0, 0.001, 0.002, 0.13391072618254496, 0.0, 0.134, 0.0, 0.003003003003003003]\n",
            "Node 265: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.631, 0.0, 0.002002002002002002]\n",
            "Node 266: [-0.041413639877875066, 0, 0, 0.001, 0.002, 0.11775483011325782, 0.0, 0.135, 0.0, 0.003003003003003003]\n",
            "Node 267: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.632, 0.0, 0.002002002002002002]\n",
            "Node 268: [1.4795441809086534, 0, 0, 0.001, 0.002, 0.32000888296691093, 0.0, 0.136, 0.0, 0.003003003003003003]\n",
            "Node 269: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.633, 0.0, 0.002002002002002002]\n",
            "Node 270: [1.0716452539505317, 0, 0, 0.001, 0.002, 0.26576726626693314, 0.0, 0.137, 0.0, 0.003003003003003003]\n",
            "Node 271: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.634, 0.0, 0.002002002002002002]\n",
            "Node 272: [0.06170922087817007, 0, 0, 0.001, 0.002, 0.1314679102820342, 0.0, 0.138, 0.0, 0.003003003003003003]\n",
            "Node 273: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.635, 0.0, 0.002002002002002002]\n",
            "Node 274: [1.15013552853408, 0, 0, 0.001, 0.002, 0.2762047523872973, 0.0, 0.139, 0.0, 0.003003003003003003]\n",
            "Node 275: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.636, 0.0, 0.002002002002002002]\n",
            "Node 276: [1.637777234457403, 0, 0, 0.001, 0.002, 0.3410504108372196, 0.0, 0.14, 0.0, 0.003003003003003003]\n",
            "Node 277: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.637, 0.0, 0.002002002002002002]\n",
            "Node 278: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.141, 0.0, 0.003003003003003003]\n",
            "Node 279: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.638, 0.0, 0.002002002002002002]\n",
            "Node 280: [1.2524233863690237, 0, 0, 0.001, 0.002, 0.28980679546968685, 0.0, 0.142, 0.0, 0.003003003003003003]\n",
            "Node 281: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.639, 0.0, 0.002002002002002002]\n",
            "Node 282: [0.7906667709998496, 0, 0, 0.001, 0.002, 0.22840328669775703, 0.0, 0.143, 0.0, 0.003003003003003003]\n",
            "Node 283: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.64, 0.0, 0.002002002002002002]\n",
            "Node 284: [0.9013046580458093, 0, 0, 0.001, 0.002, 0.2431157006440151, 0.0, 0.144, 0.0, 0.003003003003003003]\n",
            "Node 285: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.641, 0.0, 0.002002002002002002]\n",
            "Node 286: [0.30761758114258553, 0, 0, 0.001, 0.002, 0.16416833222296245, 0.0, 0.145, 0.0, 0.003003003003003003]\n",
            "Node 287: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.642, 0.0, 0.002002002002002002]\n",
            "Node 288: [0.1685895947791723, 0, 0, 0.001, 0.002, 0.1456806573395514, 0.0, 0.146, 0.0, 0.003003003003003003]\n",
            "Node 289: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.643, 0.0, 0.002002002002002002]\n",
            "Node 290: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.147, 0.0, 0.003003003003003003]\n",
            "Node 291: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.644, 0.0, 0.002002002002002002]\n",
            "Node 292: [1.3501187281379086, 0, 0, 0.001, 0.002, 0.3027981345769487, 0.0, 0.148, 0.0, 0.003003003003003003]\n",
            "Node 293: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.645, 0.0, 0.002002002002002002]\n",
            "Node 294: [0.5172033143390822, 0, 0, 0.001, 0.002, 0.19203864090606262, 0.0, 0.149, 0.0, 0.003003003003003003]\n",
            "Node 295: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.646, 0.0, 0.002002002002002002]\n",
            "Node 296: [1.3325836667947755, 0, 0, 0.001, 0.002, 0.30046635576282477, 0.0, 0.15, 0.0, 0.003003003003003003]\n",
            "Node 297: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.647, 0.0, 0.002002002002002002]\n",
            "Node 298: [1.6720123542225676, 0, 0, 0.001, 0.002, 0.34560293137908055, 0.0, 0.151, 0.0, 0.003003003003003003]\n",
            "Node 299: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.648, 0.0, 0.002002002002002002]\n",
            "Node 300: [0.9326172675871185, 0, 0, 0.001, 0.002, 0.2472795913835221, 0.0, 0.152, 0.0, 0.003003003003003003]\n",
            "Node 301: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.649, 0.0, 0.002002002002002002]\n",
            "Node 302: [0.4128279492013846, 0, 0, 0.001, 0.002, 0.17815900510770596, 0.0, 0.153, 0.0, 0.003003003003003003]\n",
            "Node 303: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.65, 0.0, 0.002002002002002002]\n",
            "Node 304: [0.953492340614658, 0, 0, 0.001, 0.002, 0.2500555185431934, 0.0, 0.154, 0.0, 0.003003003003003003]\n",
            "Node 305: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.651, 0.0, 0.002002002002002002]\n",
            "Node 306: [0.3209776278802108, 0, 0, 0.001, 0.002, 0.16594492560515212, 0.0, 0.155, 0.0, 0.003003003003003003]\n",
            "Node 307: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.652, 0.0, 0.002002002002002002]\n",
            "Node 308: [1.1831181439175926, 0, 0, 0.001, 0.002, 0.2805907172995781, 0.0, 0.156, 0.0, 0.003003003003003003]\n",
            "Node 309: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.653, 0.0, 0.002002002002002002]\n",
            "Node 310: [0.3201426249591092, 0, 0, 0.001, 0.002, 0.16583388851876527, 0.0, 0.157, 0.0, 0.003003003003003003]\n",
            "Node 311: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.654, 0.0, 0.002002002002002002]\n",
            "Node 312: [1.0374101341853668, 0, 0, 0.001, 0.002, 0.2612147457250722, 0.0, 0.158, 0.0, 0.003003003003003003]\n",
            "Node 313: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.655, 0.0, 0.002002002002002002]\n",
            "Node 314: [1.7388125879106944, 0, 0, 0.001, 0.002, 0.35448589829002886, 0.0, 0.159, 0.0, 0.003003003003003003]\n",
            "Node 315: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.656, 0.0, 0.002002002002002002]\n",
            "Node 316: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 0.0, 0.16, 0.0, 0.003003003003003003]\n",
            "Node 317: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.657, 0.0, 0.002002002002002002]\n",
            "Node 318: [0.7514216337080755, 0, 0, 0.001, 0.002, 0.22318454363757492, 0.0, 0.161, 0.0, 0.003003003003003003]\n",
            "Node 319: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.658, 0.0, 0.002002002002002002]\n",
            "Node 320: [0.5915185743171228, 0, 0, 0.001, 0.002, 0.20192094159449256, 0.0, 0.162, 0.0, 0.003003003003003003]\n",
            "Node 321: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.659, 0.0, 0.002002002002002002]\n",
            "Node 322: [0.8942071332164457, 0, 0, 0.001, 0.002, 0.2421718854097268, 0.0, 0.163, 0.0, 0.003003003003003003]\n",
            "Node 323: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.66, 0.0, 0.002002002002002002]\n",
            "Node 324: [0.4032254156087163, 0, 0, 0.001, 0.002, 0.17688207861425712, 0.0, 0.164, 0.0, 0.003003003003003003]\n",
            "Node 325: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.661, 0.0, 0.002002002002002002]\n",
            "Node 326: [1.1438730066258183, 0, 0, 0.001, 0.002, 0.2753719742393959, 0.0, 0.165, 0.0, 0.003003003003003003]\n",
            "Node 327: [-0.8960391296253427, 0, 0, 0.001, 0.001, 0.004108372196313569, 0.0, 0.662, 0.0, 0.002002002002002002]\n",
            "Node 328: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.166, 0.0, 0.003003003003003003]\n",
            "Node 329: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.663, 0.0, 0.002002002002002002]\n",
            "Node 330: [1.4720291546187394, 0, 0, 0.001, 0.002, 0.31900954918942925, 0.0, 0.167, 0.0, 0.003003003003003003]\n",
            "Node 331: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.664, 0.0, 0.002002002002002002]\n",
            "Node 332: [1.5192068196609785, 0, 0, 0.001, 0.002, 0.3252831445702865, 0.0, 0.168, 0.0, 0.003003003003003003]\n",
            "Node 333: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.665, 0.0, 0.002002002002002002]\n",
            "Node 334: [0.0608742179570685, 0, 0, 0.001, 0.002, 0.13135687319564732, 0.0, 0.169, 0.0, 0.003003003003003003]\n",
            "Node 335: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.666, 0.0, 0.002002002002002002]\n",
            "Node 336: [0.34185270090775033, 0, 0, 0.001, 0.002, 0.16872085276482346, 0.0, 0.17, 0.0, 0.003003003003003003]\n",
            "Node 337: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.667, 0.0, 0.002002002002002002]\n",
            "Node 338: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.171, 0.0, 0.003003003003003003]\n",
            "Node 339: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.668, 0.0, 0.002002002002002002]\n",
            "Node 340: [0.5280583523134026, 0, 0, 0.001, 0.002, 0.19348212302909168, 0.0, 0.172, 0.0, 0.003003003003003003]\n",
            "Node 341: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.669, 0.0, 0.002002002002002002]\n",
            "Node 342: [0.4332855207683734, 0, 0, 0.001, 0.002, 0.1808794137241839, 0.0, 0.173, 0.0, 0.003003003003003003]\n",
            "Node 343: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.67, 0.0, 0.002002002002002002]\n",
            "Node 344: [1.698732447697818, 0, 0, 0.001, 0.002, 0.34915611814345987, 0.0, 0.174, 0.0, 0.003003003003003003]\n",
            "Node 345: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.671, 0.0, 0.002002002002002002]\n",
            "Node 346: [0.5577009560125088, 0, 0, 0.001, 0.002, 0.197423939595825, 0.0, 0.175, 0.0, 0.003003003003003003]\n",
            "Node 347: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.672, 0.0, 0.002002002002002002]\n",
            "Node 348: [1.54634441459678, 0, 0, 0.001, 0.002, 0.3288918498778592, 0.0, 0.176, 0.0, 0.003003003003003003]\n",
            "Node 349: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.673, 0.0, 0.002002002002002002]\n",
            "Node 350: [1.6256696921014298, 0, 0, 0.001, 0.002, 0.3394403730846102, 0.0, 0.177, 0.0, 0.003003003003003003]\n",
            "Node 351: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.674, 0.0, 0.002002002002002002]\n",
            "Node 352: [0.883352095242125, 0, 0, 0.001, 0.002, 0.24072840328669773, 0.0, 0.178, 0.0, 0.003003003003003003]\n",
            "Node 353: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.675, 0.0, 0.002002002002002002]\n",
            "Node 354: [1.5212943269637322, 0, 0, 0.001, 0.002, 0.32556073728625357, 0.0, 0.179, 0.0, 0.003003003003003003]\n",
            "Node 355: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.676, 0.0, 0.002002002002002002]\n",
            "Node 356: [0.8040268177374749, 0, 0, 0.001, 0.002, 0.2301798800799467, 0.0, 0.18, 0.0, 0.003003003003003003]\n",
            "Node 357: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.677, 0.0, 0.002002002002002002]\n",
            "Node 358: [-0.025131082916394373, 0, 0, 0.001, 0.002, 0.11992005329780143, 0.0, 0.181, 0.0, 0.003003003003003003]\n",
            "Node 359: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.678, 0.0, 0.002002002002002002]\n",
            "Node 360: [1.122580432137728, 0, 0, 0.001, 0.002, 0.2725405285365312, 0.0, 0.182, 0.0, 0.003003003003003003]\n",
            "Node 361: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.679, 0.0, 0.002002002002002002]\n",
            "Node 362: [1.7617751682409877, 0, 0, 0.001, 0.002, 0.35753941816566737, 0.0, 0.183, 0.0, 0.003003003003003003]\n",
            "Node 363: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.68, 0.0, 0.002002002002002002]\n",
            "Node 364: [0.5606234662363643, 0, 0, 0.001, 0.002, 0.19781256939817896, 0.0, 0.184, 0.0, 0.003003003003003003]\n",
            "Node 365: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.681, 0.0, 0.002002002002002002]\n",
            "Node 366: [0.2516723854287796, 0, 0, 0.001, 0.002, 0.15672884743504328, 0.0, 0.185, 0.0, 0.003003003003003003]\n",
            "Node 367: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.682, 0.0, 0.002002002002002002]\n",
            "Node 368: [0.3977978966215562, 0, 0, 0.001, 0.002, 0.1761603375527426, 0.0, 0.186, 0.0, 0.003003003003003003]\n",
            "Node 369: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.683, 0.0, 0.002002002002002002]\n",
            "Node 370: [1.7162675090409514, 0, 0, 0.001, 0.002, 0.35148789695758376, 0.0, 0.187, 0.0, 0.003003003003003003]\n",
            "Node 371: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.684, 0.0, 0.002002002002002002]\n",
            "Node 372: [0.16733709039752004, 0, 0, 0.001, 0.002, 0.14551410170997112, 0.0, 0.188, 0.0, 0.003003003003003003]\n",
            "Node 373: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.685, 0.0, 0.002002002002002002]\n",
            "Node 374: [0.5873435597116149, 0, 0, 0.001, 0.002, 0.2013657561625583, 0.0, 0.189, 0.0, 0.003003003003003003]\n",
            "Node 375: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.686, 0.0, 0.002002002002002002]\n",
            "Node 376: [0.44288805436104145, 0, 0, 0.001, 0.002, 0.18215634021763266, 0.0, 0.19, 0.0, 0.003003003003003003]\n",
            "Node 377: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.687, 0.0, 0.002002002002002002]\n",
            "Node 378: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.191, 0.0, 0.003003003003003003]\n",
            "Node 379: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.688, 0.0, 0.002002002002002002]\n",
            "Node 380: [0.5426709034326803, 0, 0, 0.001, 0.002, 0.19542527204086163, 0.0, 0.192, 0.0, 0.003003003003003003]\n",
            "Node 381: [-0.9227592231005933, 0, 0, 0.001, 0.001, 0.0005551854319342662, 0.0, 0.689, 0.0, 0.002002002002002002]\n",
            "Node 382: [0.016201561678133938, 0, 0, 0.001, 0.002, 0.1254163890739507, 0.0, 0.193, 0.0, 0.003003003003003003]\n",
            "Node 383: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.69, 0.0, 0.002002002002002002]\n",
            "Node 384: [0.3973803951610055, 0, 0, 0.001, 0.002, 0.1761048190095492, 0.0, 0.194, 0.0, 0.003003003003003003]\n",
            "Node 385: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.691, 0.0, 0.002002002002002002]\n",
            "Node 386: [1.6945574330923105, 0, 0, 0.001, 0.002, 0.34860093271152565, 0.0, 0.195, 0.0, 0.003003003003003003]\n",
            "Node 387: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.692, 0.0, 0.002002002002002002]\n",
            "Node 388: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 0.0, 0.196, 0.0, 0.003003003003003003]\n",
            "Node 389: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.693, 0.0, 0.002002002002002002]\n",
            "Node 390: [0.5506034311831453, 0, 0, 0.001, 0.002, 0.19648012436153672, 0.0, 0.197, 0.0, 0.003003003003003003]\n",
            "Node 391: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.694, 0.0, 0.002002002002002002]\n",
            "Node 392: [0.13143196479015196, 0, 0, 0.001, 0.002, 0.1407395069953364, 0.0, 0.198, 0.0, 0.003003003003003003]\n",
            "Node 393: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.695, 0.0, 0.002002002002002002]\n",
            "Node 394: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.199, 0.0, 0.003003003003003003]\n",
            "Node 395: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.696, 0.0, 0.002002002002002002]\n",
            "Node 396: [1.6766048702886263, 0, 0, 0.001, 0.002, 0.3462136353542083, 0.0, 0.2, 0.0, 0.003003003003003003]\n",
            "Node 397: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.697, 0.0, 0.002002002002002002]\n",
            "Node 398: [0.8453594623320032, 0, 0, 0.001, 0.002, 0.2356762158560959, 0.0, 0.201, 0.0, 0.003003003003003003]\n",
            "Node 399: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.698, 0.0, 0.002002002002002002]\n",
            "Node 400: [1.5835020445858004, 0, 0, 0.001, 0.002, 0.3338330002220741, 0.0, 0.202, 0.0, 0.003003003003003003]\n",
            "Node 401: [-0.8826790828877173, 0, 0, 0.001, 0.001, 0.005884965578503219, 0.0, 0.699, 0.0, 0.002002002002002002]\n",
            "Node 402: [0.8603895149118317, 0, 0, 0.001, 0.002, 0.23767488341105925, 0.0, 0.203, 0.0, 0.003003003003003003]\n",
            "Node 403: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.7, 0.0, 0.002002002002002002]\n",
            "Node 404: [1.540499394149069, 0, 0, 0.001, 0.002, 0.3281145902731512, 0.0, 0.204, 0.0, 0.003003003003003003]\n",
            "Node 405: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.701, 0.0, 0.002002002002002002]\n",
            "Node 406: [1.7229475324097638, 0, 0, 0.001, 0.002, 0.35237619364867867, 0.0, 0.205, 0.0, 0.003003003003003003]\n",
            "Node 407: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.702, 0.0, 0.002002002002002002]\n",
            "Node 408: [0.5188733201812853, 0, 0, 0.001, 0.002, 0.1922607150788363, 0.0, 0.206, 0.0, 0.003003003003003003]\n",
            "Node 409: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.703, 0.0, 0.002002002002002002]\n",
            "Node 410: [0.4245179900968068, 0, 0, 0.001, 0.002, 0.17971352431712193, 0.0, 0.207, 0.0, 0.003003003003003003]\n",
            "Node 411: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.704, 0.0, 0.002002002002002002]\n",
            "Node 412: [-0.015111047863175325, 0, 0, 0.001, 0.002, 0.1212524983344437, 0.0, 0.208, 0.0, 0.003003003003003003]\n",
            "Node 413: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.705, 0.0, 0.002002002002002002]\n",
            "Node 414: [-0.007178520112710406, 0, 0, 0.001, 0.002, 0.12230735065511879, 0.0, 0.209, 0.0, 0.003003003003003003]\n",
            "Node 415: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.706, 0.0, 0.002002002002002002]\n",
            "Node 416: [0.38777786156833716, 0, 0, 0.001, 0.002, 0.17482789251610037, 0.0, 0.21, 0.0, 0.003003003003003003]\n",
            "Node 417: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.707, 0.0, 0.002002002002002002]\n",
            "Node 418: [-0.03556861943016413, 0, 0, 0.001, 0.002, 0.11853208971796576, 0.0, 0.211, 0.0, 0.003003003003003003]\n",
            "Node 419: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.708, 0.0, 0.002002002002002002]\n",
            "Node 420: [1.7279575499363735, 0, 0, 0.001, 0.002, 0.3530424161669998, 0.0, 0.212, 0.0, 0.003003003003003003]\n",
            "Node 421: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.709, 0.0, 0.002002002002002002]\n",
            "Node 422: [0.2600224146397954, 0, 0, 0.001, 0.002, 0.15783921829891182, 0.0, 0.213, 0.0, 0.003003003003003003]\n",
            "Node 423: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.71, 0.0, 0.002002002002002002]\n",
            "Node 424: [0.7764717213411229, 0, 0, 0.001, 0.002, 0.22651565622918055, 0.0, 0.214, 0.0, 0.003003003003003003]\n",
            "Node 425: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.711, 0.0, 0.002002002002002002]\n",
            "Node 426: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 0.0, 0.215, 0.0, 0.003003003003003003]\n",
            "Node 427: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.712, 0.0, 0.002002002002002002]\n",
            "Node 428: [0.2537598927315335, 0, 0, 0.001, 0.002, 0.15700644015101042, 0.0, 0.216, 0.0, 0.003003003003003003]\n",
            "Node 429: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.713, 0.0, 0.002002002002002002]\n",
            "Node 430: [0.6144811546474163, 0, 0, 0.001, 0.002, 0.20497446147013101, 0.0, 0.217, 0.0, 0.003003003003003003]\n",
            "Node 431: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.714, 0.0, 0.002002002002002002]\n",
            "Node 432: [1.386858856666378, 0, 0, 0.001, 0.002, 0.30768376637797024, 0.0, 0.218, 0.0, 0.003003003003003003]\n",
            "Node 433: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.715, 0.0, 0.002002002002002002]\n",
            "Node 434: [0.9196747223100439, 0, 0, 0.001, 0.002, 0.24555851654452587, 0.0, 0.219, 0.0, 0.003003003003003003]\n",
            "Node 435: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.716, 0.0, 0.002002002002002002]\n",
            "Node 436: [0.45833560840142057, 0, 0, 0.001, 0.002, 0.18421052631578946, 0.0, 0.22, 0.0, 0.003003003003003003]\n",
            "Node 437: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.717, 0.0, 0.002002002002002002]\n",
            "Node 438: [1.4695241458554344, 0, 0, 0.001, 0.002, 0.31867643793026873, 0.0, 0.221, 0.0, 0.003003003003003003]\n",
            "Node 439: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.718, 0.0, 0.002002002002002002]\n",
            "Node 440: [0.8829345937815742, 0, 0, 0.001, 0.002, 0.2406728847435043, 0.0, 0.222, 0.0, 0.003003003003003003]\n",
            "Node 441: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.719, 0.0, 0.002002002002002002]\n",
            "Node 442: [0.21910727150581794, 0, 0, 0.001, 0.002, 0.152398401065956, 0.0, 0.223, 0.0, 0.003003003003003003]\n",
            "Node 443: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.72, 0.0, 0.002002002002002002]\n",
            "Node 444: [0.9701923990366895, 0, 0, 0.001, 0.002, 0.2522762602709305, 0.0, 0.224, 0.0, 0.003003003003003003]\n",
            "Node 445: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.721, 0.0, 0.002002002002002002]\n",
            "Node 446: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.225, 0.0, 0.003003003003003003]\n",
            "Node 447: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.722, 0.0, 0.002002002002002002]\n",
            "Node 448: [0.7672866892090056, 0, 0, 0.001, 0.002, 0.22529424827892516, 0.0, 0.226, 0.0, 0.003003003003003003]\n",
            "Node 449: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.723, 0.0, 0.002002002002002002]\n",
            "Node 450: [1.6386122373785044, 0, 0, 0.001, 0.002, 0.3411614479236065, 0.0, 0.227, 0.0, 0.003003003003003003]\n",
            "Node 451: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.724, 0.0, 0.002002002002002002]\n",
            "Node 452: [1.4937392305673802, 0, 0, 0.001, 0.002, 0.3218965134354874, 0.0, 0.228, 0.0, 0.003003003003003003]\n",
            "Node 453: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.725, 0.0, 0.002002002002002002]\n",
            "Node 454: [1.09210282551752, 0, 0, 0.001, 0.002, 0.268487674883411, 0.0, 0.229, 0.0, 0.003003003003003003]\n",
            "Node 455: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.726, 0.0, 0.002002002002002002]\n",
            "Node 456: [0.4165854623463416, 0, 0, 0.001, 0.002, 0.1786586719964468, 0.0, 0.23, 0.0, 0.003003003003003003]\n",
            "Node 457: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.727, 0.0, 0.002002002002002002]\n",
            "Node 458: [0.43412052368947485, 0, 0, 0.001, 0.002, 0.1809904508105707, 0.0, 0.231, 0.0, 0.003003003003003003]\n",
            "Node 459: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.728, 0.0, 0.002002002002002002]\n",
            "Node 460: [0.9518223347724546, 0, 0, 0.001, 0.002, 0.24983344437041966, 0.0, 0.232, 0.0, 0.003003003003003003]\n",
            "Node 461: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.729, 0.0, 0.002002002002002002]\n",
            "Node 462: [0.44622806604544774, 0, 0, 0.001, 0.002, 0.18260048856318006, 0.0, 0.233, 0.0, 0.003003003003003003]\n",
            "Node 463: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.73, 0.0, 0.002002002002002002]\n",
            "Node 464: [1.6949749345528615, 0, 0, 0.001, 0.002, 0.34865645125471906, 0.0, 0.234, 0.0, 0.003003003003003003]\n",
            "Node 465: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.731, 0.0, 0.002002002002002002]\n",
            "Node 466: [1.610222138061051, 0, 0, 0.001, 0.002, 0.33738618698645345, 0.0, 0.235, 0.0, 0.003003003003003003]\n",
            "Node 467: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.732, 0.0, 0.002002002002002002]\n",
            "Node 468: [1.0040100173413034, 0, 0, 0.001, 0.002, 0.256773262269598, 0.0, 0.236, 0.0, 0.003003003003003003]\n",
            "Node 469: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.733, 0.0, 0.002002002002002002]\n",
            "Node 470: [0.3080350826031362, 0, 0, 0.001, 0.002, 0.1642238507661559, 0.0, 0.237, 0.0, 0.003003003003003003]\n",
            "Node 471: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.734, 0.0, 0.002002002002002002]\n",
            "Node 472: [3.5207088215414664, 0, 0, 0.0, 0.131, 0.5914390406395736, 0.0, 0.002, 0.0, 0.13113113113113112]\n",
            "Node 473: [0.3898653688710913, 0, 0, 0.001, 0.002, 0.1751054852320675, 0.0, 0.238, 0.0, 0.003003003003003003]\n",
            "Node 474: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.735, 0.0, 0.002002002002002002]\n",
            "Node 475: [1.5317318634775021, 0, 0, 0.001, 0.002, 0.32694870086608924, 0.0, 0.239, 0.0, 0.003003003003003003]\n",
            "Node 476: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.736, 0.0, 0.002002002002002002]\n",
            "Node 477: [0.7397315928126532, 0, 0, 0.001, 0.002, 0.221630024428159, 0.0, 0.24, 0.0, 0.003003003003003003]\n",
            "Node 478: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.737, 0.0, 0.002002002002002002]\n",
            "Node 479: [0.17025960062137543, 0, 0, 0.001, 0.002, 0.1459027315123251, 0.0, 0.241, 0.0, 0.003003003003003003]\n",
            "Node 480: [-0.9035541559152569, 0, 0, 0.001, 0.001, 0.0031090384188318895, 0.0, 0.738, 0.0, 0.002002002002002002]\n",
            "Node 481: [0.5627109735391181, 0, 0, 0.001, 0.002, 0.1980901621141461, 0.0, 0.242, 0.0, 0.003003003003003003]\n",
            "Node 482: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.739, 0.0, 0.002002002002002002]\n",
            "Node 483: [-0.008848525954913531, 0, 0, 0.001, 0.002, 0.1220852764823451, 0.0, 0.243, 0.0, 0.003003003003003003]\n",
            "Node 484: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.74, 0.0, 0.002002002002002002]\n",
            "Node 485: [0.8061143250402291, 0, 0, 0.001, 0.002, 0.23045747279591383, 0.0, 0.244, 0.0, 0.003003003003003003]\n",
            "Node 486: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.741, 0.0, 0.002002002002002002]\n",
            "Node 487: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.245, 0.0, 0.003003003003003003]\n",
            "Node 488: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.742, 0.0, 0.002002002002002002]\n",
            "Node 489: [1.615649657048211, 0, 0, 0.001, 0.002, 0.338107928047968, 0.0, 0.246, 0.0, 0.003003003003003003]\n",
            "Node 490: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.743, 0.0, 0.002002002002002002]\n",
            "Node 491: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.247, 0.0, 0.003003003003003003]\n",
            "Node 492: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.744, 0.0, 0.002002002002002002]\n",
            "Node 493: [0.36940779730410245, 0, 0, 0.001, 0.002, 0.1723850766155896, 0.0, 0.248, 0.0, 0.003003003003003003]\n",
            "Node 494: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.745, 0.0, 0.002002002002002002]\n",
            "Node 495: [0.22536979341407973, 0, 0, 0.001, 0.002, 0.1532311792138574, 0.0, 0.249, 0.0, 0.003003003003003003]\n",
            "Node 496: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.746, 0.0, 0.002002002002002002]\n",
            "Node 497: [1.5713945022298272, 0, 0, 0.001, 0.002, 0.3322229624694648, 0.0, 0.25, 0.0, 0.003003003003003003]\n",
            "Node 498: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.747, 0.0, 0.002002002002002002]\n",
            "Node 499: [1.1434555051652675, 0, 0, 0.001, 0.002, 0.27531645569620256, 0.0, 0.251, 0.0, 0.003003003003003003]\n",
            "Node 500: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.748, 0.0, 0.002002002002002002]\n",
            "Node 501: [1.659487310406044, 0, 0, 0.001, 0.002, 0.3439373750832778, 0.0, 0.252, 0.0, 0.003003003003003003]\n",
            "Node 502: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.749, 0.0, 0.002002002002002002]\n",
            "Node 503: [0.8211443776200574, 0, 0, 0.001, 0.002, 0.2324561403508772, 0.0, 0.253, 0.0, 0.003003003003003003]\n",
            "Node 504: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.75, 0.0, 0.002002002002002002]\n",
            "Node 505: [1.7358900776868385, 0, 0, 0.001, 0.002, 0.35409726848767487, 0.0, 0.254, 0.0, 0.003003003003003003]\n",
            "Node 506: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.751, 0.0, 0.002002002002002002]\n",
            "Node 507: [1.161825569429502, 0, 0, 0.001, 0.002, 0.2777592715967133, 0.0, 0.255, 0.0, 0.003003003003003003]\n",
            "Node 508: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.752, 0.0, 0.002002002002002002]\n",
            "Node 509: [1.6290097037858366, 0, 0, 0.001, 0.002, 0.3398845214301577, 0.0, 0.256, 0.0, 0.003003003003003003]\n",
            "Node 510: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.753, 0.0, 0.002002002002002002]\n",
            "Node 511: [1.7642801770042924, 0, 0, 0.001, 0.002, 0.35787252942482795, 0.0, 0.257, 0.0, 0.003003003003003003]\n",
            "Node 512: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.754, 0.0, 0.002002002002002002]\n",
            "Node 513: [0.13226696771125365, 0, 0, 0.001, 0.002, 0.1408505440817233, 0.0, 0.258, 0.0, 0.003003003003003003]\n",
            "Node 514: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.755, 0.0, 0.002002002002002002]\n",
            "Node 515: [0.32056012641966, 0, 0, 0.001, 0.002, 0.16588940706195868, 0.0, 0.259, 0.0, 0.003003003003003003]\n",
            "Node 516: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.756, 0.0, 0.002002002002002002]\n",
            "Node 517: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.26, 0.0, 0.003003003003003003]\n",
            "Node 518: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.757, 0.0, 0.002002002002002002]\n",
            "Node 519: [0.028726605494657675, 0, 0, 0.001, 0.002, 0.1270819453697535, 0.0, 0.261, 0.0, 0.003003003003003003]\n",
            "Node 520: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.758, 0.0, 0.002002002002002002]\n",
            "Node 521: [1.3363411799397324, 0, 0, 0.001, 0.002, 0.30096602265156563, 0.0, 0.262, 0.0, 0.003003003003003003]\n",
            "Node 522: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.759, 0.0, 0.002002002002002002]\n",
            "Node 523: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.263, 0.0, 0.003003003003003003]\n",
            "Node 524: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.76, 0.0, 0.002002002002002002]\n",
            "Node 525: [1.0683052422661252, 0, 0, 0.001, 0.002, 0.26532311792138574, 0.0, 0.264, 0.0, 0.003003003003003003]\n",
            "Node 526: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.761, 0.0, 0.002002002002002002]\n",
            "Node 527: [1.5388293883068656, 0, 0, 0.001, 0.002, 0.32789251610037745, 0.0, 0.265, 0.0, 0.003003003003003003]\n",
            "Node 528: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.762, 0.0, 0.002002002002002002]\n",
            "Node 529: [0.547263419498739, 0, 0, 0.001, 0.002, 0.19603597601598932, 0.0, 0.266, 0.0, 0.003003003003003003]\n",
            "Node 530: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.763, 0.0, 0.002002002002002002]\n",
            "Node 531: [0.7756367184200212, 0, 0, 0.001, 0.002, 0.22640461914279367, 0.0, 0.267, 0.0, 0.003003003003003003]\n",
            "Node 532: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.764, 0.0, 0.002002002002002002]\n",
            "Node 533: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.268, 0.0, 0.003003003003003003]\n",
            "Node 534: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.765, 0.0, 0.002002002002002002]\n",
            "Node 535: [1.378926328915913, 0, 0, 0.001, 0.002, 0.30662891405729514, 0.0, 0.269, 0.0, 0.003003003003003003]\n",
            "Node 536: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.766, 0.0, 0.002002002002002002]\n",
            "Node 537: [0.8219793805411589, 0, 0, 0.001, 0.002, 0.23256717743726402, 0.0, 0.27, 0.0, 0.003003003003003003]\n",
            "Node 538: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.767, 0.0, 0.002002002002002002]\n",
            "Node 539: [0.578993530500599, 0, 0, 0.001, 0.002, 0.20025538529868972, 0.0, 0.271, 0.0, 0.003003003003003003]\n",
            "Node 540: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.768, 0.0, 0.002002002002002002]\n",
            "Node 541: [1.0916853240569693, 0, 0, 0.001, 0.002, 0.2684321563402176, 0.0, 0.272, 0.0, 0.003003003003003003]\n",
            "Node 542: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.769, 0.0, 0.002002002002002002]\n",
            "Node 543: [0.684621400019949, 0, 0, 0.001, 0.002, 0.21430157672662667, 0.0, 0.273, 0.0, 0.003003003003003003]\n",
            "Node 544: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.77, 0.0, 0.002002002002002002]\n",
            "Node 545: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.274, 0.0, 0.003003003003003003]\n",
            "Node 546: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.771, 0.0, 0.002002002002002002]\n",
            "Node 547: [0.5067657778253124, 0, 0, 0.001, 0.002, 0.19065067732622695, 0.0, 0.275, 0.0, 0.003003003003003003]\n",
            "Node 548: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.772, 0.0, 0.002002002002002002]\n",
            "Node 549: [0.3088700855242378, 0, 0, 0.001, 0.002, 0.16433488785254272, 0.0, 0.276, 0.0, 0.003003003003003003]\n",
            "Node 550: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.773, 0.0, 0.002002002002002002]\n",
            "Node 551: [0.9125771974806804, 0, 0, 0.001, 0.002, 0.24461470131023758, 0.0, 0.277, 0.0, 0.003003003003003003]\n",
            "Node 552: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.774, 0.0, 0.002002002002002002]\n",
            "Node 553: [0.599033600607037, 0, 0, 0.001, 0.002, 0.20292027537197424, 0.0, 0.278, 0.0, 0.003003003003003003]\n",
            "Node 554: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.775, 0.0, 0.002002002002002002]\n",
            "Node 555: [1.0340701225009605, 0, 0, 0.001, 0.002, 0.26077059737952474, 0.0, 0.279, 0.0, 0.003003003003003003]\n",
            "Node 556: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.776, 0.0, 0.002002002002002002]\n",
            "Node 557: [0.8662345353595428, 0, 0, 0.001, 0.002, 0.23845214301576725, 0.0, 0.28, 0.0, 0.003003003003003003]\n",
            "Node 558: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.777, 0.0, 0.002002002002002002]\n",
            "Node 559: [1.6912174214079043, 0, 0, 0.001, 0.002, 0.34815678436597824, 0.0, 0.281, 0.0, 0.003003003003003003]\n",
            "Node 560: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.778, 0.0, 0.002002002002002002]\n",
            "Node 561: [0.4516555850326081, 0, 0, 0.001, 0.002, 0.18332222962469466, 0.0, 0.282, 0.0, 0.003003003003003003]\n",
            "Node 562: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.779, 0.0, 0.002002002002002002]\n",
            "Node 563: [1.512109294831615, 0, 0, 0.001, 0.002, 0.3243393293359982, 0.0, 0.283, 0.0, 0.003003003003003003]\n",
            "Node 564: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.78, 0.0, 0.002002002002002002]\n",
            "Node 565: [0.9902324691431273, 0, 0, 0.001, 0.002, 0.25494115034421494, 0.0, 0.284, 0.0, 0.003003003003003003]\n",
            "Node 566: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.781, 0.0, 0.002002002002002002]\n",
            "Node 567: [-0.036821123811816396, 0, 0, 0.001, 0.002, 0.11836553408838552, 0.0, 0.285, 0.0, 0.003003003003003003]\n",
            "Node 568: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.782, 0.0, 0.002002002002002002]\n",
            "Node 569: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.286, 0.0, 0.003003003003003003]\n",
            "Node 570: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.783, 0.0, 0.002002002002002002]\n",
            "Node 571: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.287, 0.0, 0.003003003003003003]\n",
            "Node 572: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.784, 0.0, 0.002002002002002002]\n",
            "Node 573: [1.164330578192807, 0, 0, 0.001, 0.002, 0.2780923828558739, 0.0, 0.288, 0.0, 0.003003003003003003]\n",
            "Node 574: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.785, 0.0, 0.002002002002002002]\n",
            "Node 575: [0.07256425885249053, 0, 0, 0.001, 0.002, 0.13291139240506328, 0.0, 0.289, 0.0, 0.003003003003003003]\n",
            "Node 576: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.786, 0.0, 0.002002002002002002]\n",
            "Node 577: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.29, 0.0, 0.003003003003003003]\n",
            "Node 578: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.787, 0.0, 0.002002002002002002]\n",
            "Node 579: [1.6469622665895203, 0, 0, 0.001, 0.002, 0.34227181878747504, 0.0, 0.291, 0.0, 0.003003003003003003]\n",
            "Node 580: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.788, 0.0, 0.002002002002002002]\n",
            "Node 581: [1.3083685820828297, 0, 0, 0.001, 0.002, 0.297246280257606, 0.0, 0.292, 0.0, 0.003003003003003003]\n",
            "Node 582: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.789, 0.0, 0.002002002002002002]\n",
            "Node 583: [0.989397466222026, 0, 0, 0.001, 0.002, 0.2548301132578281, 0.0, 0.293, 0.0, 0.003003003003003003]\n",
            "Node 584: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.79, 0.0, 0.002002002002002002]\n",
            "Node 585: [0.12266443411858546, 0, 0, 0.001, 0.002, 0.1395736175882745, 0.0, 0.294, 0.0, 0.003003003003003003]\n",
            "Node 586: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.791, 0.0, 0.002002002002002002]\n",
            "Node 587: [1.1776906249304322, 0, 0, 0.001, 0.002, 0.2798689762380635, 0.0, 0.295, 0.0, 0.003003003003003003]\n",
            "Node 588: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.792, 0.0, 0.002002002002002002]\n",
            "Node 589: [-0.020121065389784847, 0, 0, 0.001, 0.002, 0.12058627581612258, 0.0, 0.296, 0.0, 0.003003003003003003]\n",
            "Node 590: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.793, 0.0, 0.002002002002002002]\n",
            "Node 591: [1.0503526794624412, 0, 0, 0.001, 0.002, 0.2629358205640684, 0.0, 0.297, 0.0, 0.003003003003003003]\n",
            "Node 592: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.794, 0.0, 0.002002002002002002]\n",
            "Node 593: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.298, 0.0, 0.003003003003003003]\n",
            "Node 594: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.795, 0.0, 0.002002002002002002]\n",
            "Node 595: [0.3113750942875426, 0, 0, 0.001, 0.002, 0.1646679991117033, 0.0, 0.299, 0.0, 0.003003003003003003]\n",
            "Node 596: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.796, 0.0, 0.002002002002002002]\n",
            "Node 597: [0.9831349443137639, 0, 0, 0.001, 0.002, 0.25399733510992667, 0.0, 0.3, 0.0, 0.003003003003003003]\n",
            "Node 598: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.797, 0.0, 0.002002002002002002]\n",
            "Node 599: [0.8591370105301792, 0, 0, 0.001, 0.002, 0.237508327781479, 0.0, 0.301, 0.0, 0.003003003003003003]\n",
            "Node 600: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.798, 0.0, 0.002002002002002002]\n",
            "Node 601: [0.6645813299135112, 0, 0, 0.001, 0.002, 0.2116366866533422, 0.0, 0.302, 0.0, 0.003003003003003003]\n",
            "Node 602: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.799, 0.0, 0.002002002002002002]\n",
            "Node 603: [1.3204761244388026, 0, 0, 0.001, 0.002, 0.2988563180102154, 0.0, 0.303, 0.0, 0.003003003003003003]\n",
            "Node 604: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.8, 0.0, 0.002002002002002002]\n",
            "Node 605: [0.8996346522036058, 0, 0, 0.001, 0.002, 0.24289362647124133, 0.0, 0.304, 0.0, 0.003003003003003003]\n",
            "Node 606: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.801, 0.0, 0.002002002002002002]\n",
            "Node 607: [1.1108903912423058, 0, 0, 0.001, 0.002, 0.2709860093271152, 0.0, 0.305, 0.0, 0.003003003003003003]\n",
            "Node 608: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.802, 0.0, 0.002002002002002002]\n",
            "Node 609: [0.47670567266565556, 0, 0, 0.001, 0.002, 0.18665334221630023, 0.0, 0.306, 0.0, 0.003003003003003003]\n",
            "Node 610: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.803, 0.0, 0.002002002002002002]\n",
            "Node 611: [0.5698084983684817, 0, 0, 0.001, 0.002, 0.19903397734843434, 0.0, 0.307, 0.0, 0.003003003003003003]\n",
            "Node 612: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.804, 0.0, 0.002002002002002002]\n",
            "Node 613: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.308, 0.0, 0.003003003003003003]\n",
            "Node 614: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.805, 0.0, 0.002002002002002002]\n",
            "Node 615: [0.740149094273204, 0, 0, 0.001, 0.002, 0.2216855429713524, 0.0, 0.309, 0.0, 0.003003003003003003]\n",
            "Node 616: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.806, 0.0, 0.002002002002002002]\n",
            "Node 617: [0.8077843308824322, 0, 0, 0.001, 0.002, 0.23067954696868756, 0.0, 0.31, 0.0, 0.003003003003003003]\n",
            "Node 618: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.807, 0.0, 0.002002002002002002]\n",
            "Node 619: [0.3886128644894389, 0, 0, 0.001, 0.002, 0.17493892960248722, 0.0, 0.311, 0.0, 0.003003003003003003]\n",
            "Node 620: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.808, 0.0, 0.002002002002002002]\n",
            "Node 621: [0.5664684866840753, 0, 0, 0.001, 0.002, 0.19858982900288696, 0.0, 0.312, 0.0, 0.003003003003003003]\n",
            "Node 622: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.809, 0.0, 0.002002002002002002]\n",
            "Node 623: [0.5718960056712358, 0, 0, 0.001, 0.002, 0.1993115700644015, 0.0, 0.313, 0.0, 0.003003003003003003]\n",
            "Node 624: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.81, 0.0, 0.002002002002002002]\n",
            "Node 625: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.314, 0.0, 0.003003003003003003]\n",
            "Node 626: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.811, 0.0, 0.002002002002002002]\n",
            "Node 627: [1.100452854728536, 0, 0, 0.001, 0.002, 0.2695980457472795, 0.0, 0.315, 0.0, 0.003003003003003003]\n",
            "Node 628: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 0.0, 0.812, 0.0, 0.002002002002002002]\n",
            "Node 629: [1.0336526210404096, 0, 0, 0.001, 0.002, 0.2607150788363313, 0.0, 0.316, 0.0, 0.003003003003003003]\n",
            "Node 630: [-0.915244196810679, 0, 0, 0.001, 0.001, 0.0015545192094159443, 0.0, 0.813, 0.0, 0.002002002002002002]\n",
            "Node 631: [1.573899510993132, 0, 0, 0.001, 0.002, 0.3325560737286254, 0.0, 0.317, 0.0, 0.003003003003003003]\n",
            "Node 632: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.814, 0.0, 0.002002002002002002]\n",
            "Node 633: [0.3652327826985945, 0, 0, 0.001, 0.002, 0.17182989118365533, 0.0, 0.318, 0.0, 0.003003003003003003]\n",
            "Node 634: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.815, 0.0, 0.002002002002002002]\n",
            "Node 635: [1.5872595577307578, 0, 0, 0.001, 0.002, 0.334332667110815, 0.0, 0.319, 0.0, 0.003003003003003003]\n",
            "Node 636: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.816, 0.0, 0.002002002002002002]\n",
            "Node 637: [0.34394020821050414, 0, 0, 0.001, 0.002, 0.16899844548079057, 0.0, 0.32, 0.0, 0.003003003003003003]\n",
            "Node 638: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.817, 0.0, 0.002002002002002002]\n",
            "Node 639: [0.4925707281665854, 0, 0, 0.001, 0.002, 0.1887630468576504, 0.0, 0.321, 0.0, 0.003003003003003003]\n",
            "Node 640: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.818, 0.0, 0.002002002002002002]\n",
            "Node 641: [1.1029578634918409, 0, 0, 0.001, 0.002, 0.2699311570064401, 0.0, 0.322, 0.0, 0.003003003003003003]\n",
            "Node 642: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.819, 0.0, 0.002002002002002002]\n",
            "Node 643: [0.5050957719831093, 0, 0, 0.001, 0.002, 0.19042860315345325, 0.0, 0.323, 0.0, 0.003003003003003003]\n",
            "Node 644: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.82, 0.0, 0.002002002002002002]\n",
            "Node 645: [0.039581643468978134, 0, 0, 0.001, 0.002, 0.12852542749278256, 0.0, 0.324, 0.0, 0.003003003003003003]\n",
            "Node 646: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.821, 0.0, 0.002002002002002002]\n",
            "Node 647: [1.221945779748816, 0, 0, 0.001, 0.002, 0.2857539418165667, 0.0, 0.325, 0.0, 0.003003003003003003]\n",
            "Node 648: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.822, 0.0, 0.002002002002002002]\n",
            "Node 649: [0.12391693850023773, 0, 0, 0.001, 0.002, 0.13974017321785473, 0.0, 0.326, 0.0, 0.003003003003003003]\n",
            "Node 650: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.823, 0.0, 0.002002002002002002]\n",
            "Node 651: [1.0111075421706668, 0, 0, 0.001, 0.002, 0.2577170775038863, 0.0, 0.327, 0.0, 0.003003003003003003]\n",
            "Node 652: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.824, 0.0, 0.002002002002002002]\n",
            "Node 653: [0.11974192389472993, 0, 0, 0.001, 0.002, 0.13918498778592048, 0.0, 0.328, 0.0, 0.003003003003003003]\n",
            "Node 654: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.825, 0.0, 0.002002002002002002]\n",
            "Node 655: [1.357633754427823, 0, 0, 0.001, 0.002, 0.3037974683544304, 0.0, 0.329, 0.0, 0.003003003003003003]\n",
            "Node 656: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.826, 0.0, 0.002002002002002002]\n",
            "Node 657: [0.35521274764537564, 0, 0, 0.001, 0.002, 0.1704974461470131, 0.0, 0.33, 0.0, 0.003003003003003003]\n",
            "Node 658: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.827, 0.0, 0.002002002002002002]\n",
            "Node 659: [0.9785424282477052, 0, 0, 0.001, 0.002, 0.253386631134799, 0.0, 0.331, 0.0, 0.003003003003003003]\n",
            "Node 660: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.828, 0.0, 0.002002002002002002]\n",
            "Node 661: [1.219858272446062, 0, 0, 0.001, 0.002, 0.2854763491005996, 0.0, 0.332, 0.0, 0.003003003003003003]\n",
            "Node 662: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.829, 0.0, 0.002002002002002002]\n",
            "Node 663: [0.9372097836531772, 0, 0, 0.001, 0.002, 0.24789029535864981, 0.0, 0.333, 0.0, 0.003003003003003003]\n",
            "Node 664: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.83, 0.0, 0.002002002002002002]\n",
            "Node 665: [0.45499559671701434, 0, 0, 0.001, 0.002, 0.18376637797024203, 0.0, 0.334, 0.0, 0.003003003003003003]\n",
            "Node 666: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.831, 0.0, 0.002002002002002002]\n",
            "Node 667: [0.23789483723060348, 0, 0, 0.001, 0.002, 0.1548967355096602, 0.0, 0.335, 0.0, 0.003003003003003003]\n",
            "Node 668: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.832, 0.0, 0.002002002002002002]\n",
            "Node 669: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.336, 0.0, 0.003003003003003003]\n",
            "Node 670: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.833, 0.0, 0.002002002002002002]\n",
            "Node 671: [0.6245011897006353, 0, 0, 0.001, 0.002, 0.20630690650677325, 0.0, 0.337, 0.0, 0.003003003003003003]\n",
            "Node 672: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.834, 0.0, 0.002002002002002002]\n",
            "Node 673: [-0.03264610920630858, 0, 0, 0.001, 0.002, 0.11892071952031977, 0.0, 0.338, 0.0, 0.003003003003003003]\n",
            "Node 674: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.835, 0.0, 0.002002002002002002]\n",
            "Node 675: [1.0098550377890145, 0, 0, 0.001, 0.002, 0.257550521874306, 0.0, 0.339, 0.0, 0.003003003003003003]\n",
            "Node 676: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.836, 0.0, 0.002002002002002002]\n",
            "Node 677: [1.6528072870372315, 0, 0, 0.001, 0.002, 0.343049078392183, 0.0, 0.34, 0.0, 0.003003003003003003]\n",
            "Node 678: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.837, 0.0, 0.002002002002002002]\n",
            "Node 679: [1.5000017524756424, 0, 0, 0.001, 0.002, 0.3227292915833888, 0.0, 0.341, 0.0, 0.003003003003003003]\n",
            "Node 680: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.838, 0.0, 0.002002002002002002]\n",
            "Node 681: [0.44163554997938903, 0, 0, 0.001, 0.002, 0.18198978458805237, 0.0, 0.342, 0.0, 0.003003003003003003]\n",
            "Node 682: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.839, 0.0, 0.002002002002002002]\n",
            "Node 683: [0.4733656609812493, 0, 0, 0.001, 0.002, 0.18620919387075283, 0.0, 0.343, 0.0, 0.003003003003003003]\n",
            "Node 684: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.84, 0.0, 0.002002002002002002]\n",
            "Node 685: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.344, 0.0, 0.003003003003003003]\n",
            "Node 686: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.841, 0.0, 0.002002002002002002]\n",
            "Node 687: [0.39612789077935306, 0, 0, 0.001, 0.002, 0.1759382633799689, 0.0, 0.345, 0.0, 0.003003003003003003]\n",
            "Node 688: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.842, 0.0, 0.002002002002002002]\n",
            "Node 689: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.346, 0.0, 0.003003003003003003]\n",
            "Node 690: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.843, 0.0, 0.002002002002002002]\n",
            "Node 691: [0.9029746638880124, 0, 0, 0.001, 0.002, 0.2433377748167888, 0.0, 0.347, 0.0, 0.003003003003003003]\n",
            "Node 692: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.844, 0.0, 0.002002002002002002]\n",
            "Node 693: [0.36565028415914536, 0, 0, 0.001, 0.002, 0.17188540972684876, 0.0, 0.348, 0.0, 0.003003003003003003]\n",
            "Node 694: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.845, 0.0, 0.002002002002002002]\n",
            "Node 695: [1.5396643912279675, 0, 0, 0.001, 0.002, 0.3280035531867644, 0.0, 0.349, 0.0, 0.003003003003003003]\n",
            "Node 696: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.846, 0.0, 0.002002002002002002]\n",
            "Node 697: [0.8745845645705587, 0, 0, 0.001, 0.002, 0.2395625138796358, 0.0, 0.35, 0.0, 0.003003003003003003]\n",
            "Node 698: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.847, 0.0, 0.002002002002002002]\n",
            "Node 699: [0.7209440270878679, 0, 0, 0.001, 0.002, 0.21913168998445479, 0.0, 0.351, 0.0, 0.003003003003003003]\n",
            "Node 700: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.848, 0.0, 0.002002002002002002]\n",
            "Node 701: [0.007851532467118165, 0, 0, 0.001, 0.002, 0.12430601821008216, 0.0, 0.352, 0.0, 0.003003003003003003]\n",
            "Node 702: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.849, 0.0, 0.002002002002002002]\n",
            "Node 703: [1.3755863172315068, 0, 0, 0.001, 0.002, 0.30618476571174774, 0.0, 0.353, 0.0, 0.003003003003003003]\n",
            "Node 704: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.85, 0.0, 0.002002002002002002]\n",
            "Node 705: [0.45290808941426053, 0, 0, 0.001, 0.002, 0.18348878525427492, 0.0, 0.354, 0.0, 0.003003003003003003]\n",
            "Node 706: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.851, 0.0, 0.002002002002002002]\n",
            "Node 707: [0.7518391351686261, 0, 0, 0.001, 0.002, 0.22324006218076836, 0.0, 0.355, 0.0, 0.003003003003003003]\n",
            "Node 708: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.852, 0.0, 0.002002002002002002]\n",
            "Node 709: [1.6369422315363016, 0, 0, 0.001, 0.002, 0.3409393737508328, 0.0, 0.356, 0.0, 0.003003003003003003]\n",
            "Node 710: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.853, 0.0, 0.002002002002002002]\n",
            "Node 711: [0.36189277101418826, 0, 0, 0.001, 0.002, 0.17138574283810792, 0.0, 0.357, 0.0, 0.003003003003003003]\n",
            "Node 712: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.854, 0.0, 0.002002002002002002]\n",
            "Node 713: [1.6056296219949924, 0, 0, 0.001, 0.002, 0.33677548301132576, 0.0, 0.358, 0.0, 0.003003003003003003]\n",
            "Node 714: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 0.0, 0.855, 0.0, 0.002002002002002002]\n",
            "Node 715: [0.9935724808275336, 0, 0, 0.001, 0.002, 0.25538529868976234, 0.0, 0.359, 0.0, 0.003003003003003003]\n",
            "Node 716: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.856, 0.0, 0.002002002002002002]\n",
            "Node 717: [1.4027239121673083, 0, 0, 0.001, 0.002, 0.3097934710193205, 0.0, 0.36, 0.0, 0.003003003003003003]\n",
            "Node 718: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.857, 0.0, 0.002002002002002002]\n",
            "Node 719: [1.4603391137233173, 0, 0, 0.001, 0.002, 0.3174550299800133, 0.0, 0.361, 0.0, 0.003003003003003003]\n",
            "Node 720: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.858, 0.0, 0.002002002002002002]\n",
            "Node 721: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 0.0, 0.362, 0.0, 0.003003003003003003]\n",
            "Node 722: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.859, 0.0, 0.002002002002002002]\n",
            "Node 723: [0.2282923036379353, 0, 0, 0.001, 0.002, 0.1536198090162114, 0.0, 0.363, 0.0, 0.003003003003003003]\n",
            "Node 724: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 0.0, 0.86, 0.0, 0.002002002002002002]\n",
            "Node 725: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 0.0, 0.364, 0.0, 0.003003003003003003]\n",
            "Node 726: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.861, 0.0, 0.002002002002002002]\n",
            "Node 727: [0.9777074253266038, 0, 0, 0.001, 0.002, 0.25327559404841216, 0.0, 0.365, 0.0, 0.003003003003003003]\n",
            "Node 728: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.862, 0.0, 0.002002002002002002]\n",
            "Node 729: [0.5046782705225585, 0, 0, 0.001, 0.002, 0.19037308461025984, 0.0, 0.366, 0.0, 0.003003003003003003]\n",
            "Node 730: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 0.0, 0.863, 0.0, 0.002002002002002002]\n",
            "Node 731: [0.925102241297204, 0, 0, 0.001, 0.002, 0.2462802576060404, 0.0, 0.367, 0.0, 0.003003003003003003]\n",
            "Node 732: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.864, 0.0, 0.002002002002002002]\n",
            "Node 733: [1.5751520153747844, 0, 0, 0.001, 0.002, 0.3327226293582056, 0.0, 0.368, 0.0, 0.003003003003003003]\n",
            "Node 734: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.865, 0.0, 0.002002002002002002]\n",
            "Node 735: [3.959085355119796, 0, 0, 0.0, 0.132, 0.6497335109926716, 0.0, 0.003, 0.0, 0.13213213213213212]\n",
            "Node 736: [1.0428376531725267, 0, 0, 0.001, 0.002, 0.2619364867865867, 0.0, 0.369, 0.0, 0.003003003003003003]\n",
            "Node 737: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.866, 0.0, 0.002002002002002002]\n",
            "Node 738: [0.6457937641887255, 0, 0, 0.001, 0.002, 0.209138352209638, 0.0, 0.37, 0.0, 0.003003003003003003]\n",
            "Node 739: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.867, 0.0, 0.002002002002002002]\n",
            "Node 740: [1.0361576298037143, 0, 0, 0.001, 0.002, 0.2610481900954919, 0.0, 0.371, 0.0, 0.003003003003003003]\n",
            "Node 741: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.868, 0.0, 0.002002002002002002]\n",
            "Node 742: [0.32682264832792174, 0, 0, 0.001, 0.002, 0.16672218520986007, 0.0, 0.372, 0.0, 0.003003003003003003]\n",
            "Node 743: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.869, 0.0, 0.002002002002002002]\n",
            "Node 744: [0.6182386677923735, 0, 0, 0.001, 0.002, 0.20547412835887185, 0.0, 0.373, 0.0, 0.003003003003003003]\n",
            "Node 745: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.87, 0.0, 0.002002002002002002]\n",
            "Node 746: [0.24791487228382253, 0, 0, 0.001, 0.002, 0.15622918054630247, 0.0, 0.374, 0.0, 0.003003003003003003]\n",
            "Node 747: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.871, 0.0, 0.002002002002002002]\n",
            "Node 748: [1.7116749929748927, 0, 0, 0.001, 0.002, 0.3508771929824561, 0.0, 0.375, 0.0, 0.003003003003003003]\n",
            "Node 749: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.872, 0.0, 0.002002002002002002]\n",
            "Node 750: [0.10888688592040931, 0, 0, 0.001, 0.002, 0.1377415056628914, 0.0, 0.376, 0.0, 0.003003003003003003]\n",
            "Node 751: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.873, 0.0, 0.002002002002002002]\n",
            "Node 752: [-0.012188537639319782, 0, 0, 0.001, 0.002, 0.12164112813679767, 0.0, 0.377, 0.0, 0.003003003003003003]\n",
            "Node 753: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.874, 0.0, 0.002002002002002002]\n",
            "Node 754: [0.49507573692989026, 0, 0, 0.001, 0.002, 0.189096158116811, 0.0, 0.378, 0.0, 0.003003003003003003]\n",
            "Node 755: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.875, 0.0, 0.002002002002002002]\n",
            "Node 756: [1.5250518401086897, 0, 0, 0.001, 0.002, 0.32606040417499443, 0.0, 0.379, 0.0, 0.003003003003003003]\n",
            "Node 757: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.876, 0.0, 0.002002002002002002]\n",
            "Node 758: [1.0378276356459175, 0, 0, 0.001, 0.002, 0.26127026426826555, 0.0, 0.38, 0.0, 0.003003003003003003]\n",
            "Node 759: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.877, 0.0, 0.002002002002002002]\n",
            "Node 760: [0.22453479049297817, 0, 0, 0.001, 0.002, 0.15312014212747055, 0.0, 0.381, 0.0, 0.003003003003003003]\n",
            "Node 761: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.878, 0.0, 0.002002002002002002]\n",
            "Node 762: [0.30260756361597596, 0, 0, 0.001, 0.002, 0.16350210970464132, 0.0, 0.382, 0.0, 0.003003003003003003]\n",
            "Node 763: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.879, 0.0, 0.002002002002002002]\n",
            "Node 764: [0.7985992987503149, 0, 0, 0.001, 0.002, 0.22945813901843218, 0.0, 0.383, 0.0, 0.003003003003003003]\n",
            "Node 765: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.88, 0.0, 0.002002002002002002]\n",
            "Node 766: [1.576822021216988, 0, 0, 0.001, 0.002, 0.3329447035309793, 0.0, 0.384, 0.0, 0.003003003003003003]\n",
            "Node 767: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.881, 0.0, 0.002002002002002002]\n",
            "Node 768: [1.7254525411730688, 0, 0, 0.001, 0.002, 0.3527093049078392, 0.0, 0.385, 0.0, 0.003003003003003003]\n",
            "Node 769: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.882, 0.0, 0.002002002002002002]\n",
            "Node 770: [0.8541269930035699, 0, 0, 0.001, 0.002, 0.23684210526315788, 0.0, 0.386, 0.0, 0.003003003003003003]\n",
            "Node 771: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.883, 0.0, 0.002002002002002002]\n",
            "Node 772: [0.6675038401373667, 0, 0, 0.001, 0.002, 0.2120253164556962, 0.0, 0.387, 0.0, 0.003003003003003003]\n",
            "Node 773: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.884, 0.0, 0.002002002002002002]\n",
            "Node 774: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.388, 0.0, 0.003003003003003003]\n",
            "Node 775: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.885, 0.0, 0.002002002002002002]\n",
            "Node 776: [1.281230987147028, 0, 0, 0.001, 0.002, 0.2936375749500333, 0.0, 0.389, 0.0, 0.003003003003003003]\n",
            "Node 777: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.886, 0.0, 0.002002002002002002]\n",
            "Node 778: [0.7334690709043915, 0, 0, 0.001, 0.002, 0.2207972462802576, 0.0, 0.39, 0.0, 0.003003003003003003]\n",
            "Node 779: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.887, 0.0, 0.002002002002002002]\n",
            "Node 780: [0.8816820893999219, 0, 0, 0.001, 0.002, 0.240506329113924, 0.0, 0.391, 0.0, 0.003003003003003003]\n",
            "Node 781: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.888, 0.0, 0.002002002002002002]\n",
            "Node 782: [1.0812477875431996, 0, 0, 0.001, 0.002, 0.26704419276038194, 0.0, 0.392, 0.0, 0.003003003003003003]\n",
            "Node 783: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.889, 0.0, 0.002002002002002002]\n",
            "Node 784: [0.6829513941777459, 0, 0, 0.001, 0.002, 0.21407950255385297, 0.0, 0.393, 0.0, 0.003003003003003003]\n",
            "Node 785: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.89, 0.0, 0.002002002002002002]\n",
            "Node 786: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 0.0, 0.394, 0.0, 0.003003003003003003]\n",
            "Node 787: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.891, 0.0, 0.002002002002002002]\n",
            "Node 788: [1.3709938011654481, 0, 0, 0.001, 0.002, 0.30557406173662005, 0.0, 0.395, 0.0, 0.003003003003003003]\n",
            "Node 789: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.892, 0.0, 0.002002002002002002]\n",
            "Node 790: [1.60437711761334, 0, 0, 0.001, 0.002, 0.33660892738174547, 0.0, 0.396, 0.0, 0.003003003003003003]\n",
            "Node 791: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.893, 0.0, 0.002002002002002002]\n",
            "Node 792: [0.23079731240124013, 0, 0, 0.001, 0.002, 0.15395292027537197, 0.0, 0.397, 0.0, 0.003003003003003003]\n",
            "Node 793: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.894, 0.0, 0.002002002002002002]\n",
            "Node 794: [0.3639802783169421, 0, 0, 0.001, 0.002, 0.17166333555407504, 0.0, 0.398, 0.0, 0.003003003003003003]\n",
            "Node 795: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.895, 0.0, 0.002002002002002002]\n",
            "Node 796: [1.6857899024207441, 0, 0, 0.001, 0.002, 0.3474350433044637, 0.0, 0.399, 0.0, 0.003003003003003003]\n",
            "Node 797: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.896, 0.0, 0.002002002002002002]\n",
            "Node 798: [0.6487162744125811, 0, 0, 0.001, 0.002, 0.209526982011992, 0.0, 0.4, 0.0, 0.003003003003003003]\n",
            "Node 799: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.897, 0.0, 0.002002002002002002]\n",
            "Node 800: [0.015784060217583083, 0, 0, 0.001, 0.002, 0.12536087053075726, 0.0, 0.401, 0.0, 0.003003003003003003]\n",
            "Node 801: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.898, 0.0, 0.002002002002002002]\n",
            "Node 802: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.402, 0.0, 0.003003003003003003]\n",
            "Node 803: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.899, 0.0, 0.002002002002002002]\n",
            "Node 804: [0.2792274818251318, 0, 0, 0.001, 0.002, 0.16039307128580946, 0.0, 0.403, 0.0, 0.003003003003003003]\n",
            "Node 805: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.9, 0.0, 0.002002002002002002]\n",
            "Node 806: [0.31930762203800755, 0, 0, 0.001, 0.002, 0.1657228514323784, 0.0, 0.404, 0.0, 0.003003003003003003]\n",
            "Node 807: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.901, 0.0, 0.002002002002002002]\n",
            "Node 808: [1.6123096453638048, 0, 0, 0.001, 0.002, 0.33766377970242056, 0.0, 0.405, 0.0, 0.003003003003003003]\n",
            "Node 809: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.902, 0.0, 0.002002002002002002]\n",
            "Node 810: [0.621161178016229, 0, 0, 0.001, 0.002, 0.20586275816122587, 0.0, 0.406, 0.0, 0.003003003003003003]\n",
            "Node 811: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.903, 0.0, 0.002002002002002002]\n",
            "Node 812: [0.9280247515210596, 0, 0, 0.001, 0.002, 0.24666888740839438, 0.0, 0.407, 0.0, 0.003003003003003003]\n",
            "Node 813: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.904, 0.0, 0.002002002002002002]\n",
            "Node 814: [0.9397147924164817, 0, 0, 0.001, 0.002, 0.24822340661781034, 0.0, 0.408, 0.0, 0.003003003003003003]\n",
            "Node 815: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.905, 0.0, 0.002002002002002002]\n",
            "Node 816: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.409, 0.0, 0.003003003003003003]\n",
            "Node 817: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.906, 0.0, 0.002002002002002002]\n",
            "Node 818: [1.570977000769277, 0, 0, 0.001, 0.002, 0.3321674439262714, 0.0, 0.41, 0.0, 0.003003003003003003]\n",
            "Node 819: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.907, 0.0, 0.002002002002002002]\n",
            "Node 820: [1.1989831994185225, 0, 0, 0.001, 0.002, 0.28270042194092826, 0.0, 0.411, 0.0, 0.003003003003003003]\n",
            "Node 821: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.908, 0.0, 0.002002002002002002]\n",
            "Node 822: [1.1117253941634075, 0, 0, 0.001, 0.002, 0.27109704641350213, 0.0, 0.412, 0.0, 0.003003003003003003]\n",
            "Node 823: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.909, 0.0, 0.002002002002002002]\n",
            "Node 824: [0.9121596960201297, 0, 0, 0.001, 0.002, 0.2445591827670442, 0.0, 0.413, 0.0, 0.003003003003003003]\n",
            "Node 825: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.91, 0.0, 0.002002002002002002]\n",
            "Node 826: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 0.0, 0.414, 0.0, 0.003003003003003003]\n",
            "Node 827: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.911, 0.0, 0.002002002002002002]\n",
            "Node 828: [1.1985656979579717, 0, 0, 0.001, 0.002, 0.2826449033977348, 0.0, 0.415, 0.0, 0.003003003003003003]\n",
            "Node 829: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.912, 0.0, 0.002002002002002002]\n",
            "Node 830: [0.4929882296271364, 0, 0, 0.001, 0.002, 0.18881856540084388, 0.0, 0.416, 0.0, 0.003003003003003003]\n",
            "Node 831: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.913, 0.0, 0.002002002002002002]\n",
            "Node 832: [0.9626773727467753, 0, 0, 0.001, 0.002, 0.2512769264934488, 0.0, 0.417, 0.0, 0.003003003003003003]\n",
            "Node 833: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.914, 0.0, 0.002002002002002002]\n",
            "Node 834: [0.6203261750951273, 0, 0, 0.001, 0.002, 0.20575172107483897, 0.0, 0.418, 0.0, 0.003003003003003003]\n",
            "Node 835: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.915, 0.0, 0.002002002002002002]\n",
            "Node 836: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 0.0, 0.419, 0.0, 0.003003003003003003]\n",
            "Node 837: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.916, 0.0, 0.002002002002002002]\n",
            "Node 838: [0.09552683918278401, 0, 0, 0.001, 0.002, 0.13596491228070176, 0.0, 0.42, 0.0, 0.003003003003003003]\n",
            "Node 839: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.917, 0.0, 0.002002002002002002]\n",
            "Node 840: [1.2315483133414842, 0, 0, 0.001, 0.002, 0.2870308683100155, 0.0, 0.421, 0.0, 0.003003003003003003]\n",
            "Node 841: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.918, 0.0, 0.002002002002002002]\n",
            "Node 842: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.422, 0.0, 0.003003003003003003]\n",
            "Node 843: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.919, 0.0, 0.002002002002002002]\n",
            "Node 844: [0.7272065489961297, 0, 0, 0.001, 0.002, 0.2199644681323562, 0.0, 0.423, 0.0, 0.003003003003003003]\n",
            "Node 845: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.92, 0.0, 0.002002002002002002]\n",
            "Node 846: [1.1209104262955247, 0, 0, 0.001, 0.002, 0.2723184543637575, 0.0, 0.424, 0.0, 0.003003003003003003]\n",
            "Node 847: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.921, 0.0, 0.002002002002002002]\n",
            "Node 848: [1.6895474155657009, 0, 0, 0.001, 0.002, 0.3479347101932045, 0.0, 0.425, 0.0, 0.003003003003003003]\n",
            "Node 849: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.922, 0.0, 0.002002002002002002]\n",
            "Node 850: [0.5134458011941249, 0, 0, 0.001, 0.002, 0.19153897401732176, 0.0, 0.426, 0.0, 0.003003003003003003]\n",
            "Node 851: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.923, 0.0, 0.002002002002002002]\n",
            "Node 852: [0.20741723061039577, 0, 0, 0.001, 0.002, 0.15084388185654007, 0.0, 0.427, 0.0, 0.003003003003003003]\n",
            "Node 853: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.924, 0.0, 0.002002002002002002]\n",
            "Node 854: [1.2833184944497822, 0, 0, 0.001, 0.002, 0.2939151676660004, 0.0, 0.428, 0.0, 0.003003003003003003]\n",
            "Node 855: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.925, 0.0, 0.002002002002002002]\n",
            "Node 856: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 0.0, 0.429, 0.0, 0.003003003003003003]\n",
            "Node 857: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.926, 0.0, 0.002002002002002002]\n",
            "Node 858: [0.7990168002108655, 0, 0, 0.001, 0.002, 0.22951365756162556, 0.0, 0.43, 0.0, 0.003003003003003003]\n",
            "Node 859: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.927, 0.0, 0.002002002002002002]\n",
            "Node 860: [1.4941567320279312, 0, 0, 0.001, 0.002, 0.3219520319786809, 0.0, 0.431, 0.0, 0.003003003003003003]\n",
            "Node 861: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.928, 0.0, 0.002002002002002002]\n",
            "Node 862: [1.3914513727324365, 0, 0, 0.001, 0.002, 0.3082944703530979, 0.0, 0.432, 0.0, 0.003003003003003003]\n",
            "Node 863: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.929, 0.0, 0.002002002002002002]\n",
            "Node 864: [1.1676705898772133, 0, 0, 0.001, 0.002, 0.27853653120142124, 0.0, 0.433, 0.0, 0.003003003003003003]\n",
            "Node 865: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.93, 0.0, 0.002002002002002002]\n",
            "Node 866: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.434, 0.0, 0.003003003003003003]\n",
            "Node 867: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.931, 0.0, 0.002002002002002002]\n",
            "Node 868: [0.04876667560109562, 0, 0, 0.001, 0.002, 0.12974683544303797, 0.0, 0.435, 0.0, 0.003003003003003003]\n",
            "Node 869: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.932, 0.0, 0.002002002002002002]\n",
            "Node 870: [1.5041767670811501, 0, 0, 0.001, 0.002, 0.3232844770153231, 0.0, 0.436, 0.0, 0.003003003003003003]\n",
            "Node 871: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.933, 0.0, 0.002002002002002002]\n",
            "Node 872: [1.6248346891803285, 0, 0, 0.001, 0.002, 0.33932933599822335, 0.0, 0.437, 0.0, 0.003003003003003003]\n",
            "Node 873: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.934, 0.0, 0.002002002002002002]\n",
            "Node 874: [0.8537094915430191, 0, 0, 0.001, 0.002, 0.2367865867199645, 0.0, 0.438, 0.0, 0.003003003003003003]\n",
            "Node 875: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.935, 0.0, 0.002002002002002002]\n",
            "Node 876: [0.8729145587283552, 0, 0, 0.001, 0.002, 0.23934043970686206, 0.0, 0.439, 0.0, 0.003003003003003003]\n",
            "Node 877: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.936, 0.0, 0.002002002002002002]\n",
            "Node 878: [1.5772395226775384, 0, 0, 0.001, 0.002, 0.33300022207417274, 0.0, 0.44, 0.0, 0.003003003003003003]\n",
            "Node 879: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.937, 0.0, 0.002002002002002002]\n",
            "Node 880: [1.1626605723506038, 0, 0, 0.001, 0.002, 0.27787030868310014, 0.0, 0.441, 0.0, 0.003003003003003003]\n",
            "Node 881: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.938, 0.0, 0.002002002002002002]\n",
            "Node 882: [0.5443409092748834, 0, 0, 0.001, 0.002, 0.19564734621363536, 0.0, 0.442, 0.0, 0.003003003003003003]\n",
            "Node 883: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.939, 0.0, 0.002002002002002002]\n",
            "Node 884: [1.5567819511105498, 0, 0, 0.001, 0.002, 0.33027981345769486, 0.0, 0.443, 0.0, 0.003003003003003003]\n",
            "Node 885: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.94, 0.0, 0.002002002002002002]\n",
            "Node 886: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.444, 0.0, 0.003003003003003003]\n",
            "Node 887: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.941, 0.0, 0.002002002002002002]\n",
            "Node 888: [0.17693962399018806, 0, 0, 0.001, 0.002, 0.14679102820341994, 0.0, 0.445, 0.0, 0.003003003003003003]\n",
            "Node 889: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.942, 0.0, 0.002002002002002002]\n",
            "Node 890: [0.555195947249204, 0, 0, 0.001, 0.002, 0.19709082833666441, 0.0, 0.446, 0.0, 0.003003003003003003]\n",
            "Node 891: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.943, 0.0, 0.002002002002002002]\n",
            "Node 892: [0.8169693630145495, 0, 0, 0.001, 0.002, 0.23190095491894291, 0.0, 0.447, 0.0, 0.003003003003003003]\n",
            "Node 893: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.944, 0.0, 0.002002002002002002]\n",
            "Node 894: [0.15564704950209785, 0, 0, 0.001, 0.002, 0.14395958250055516, 0.0, 0.448, 0.0, 0.003003003003003003]\n",
            "Node 895: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.945, 0.0, 0.002002002002002002]\n",
            "Node 896: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.449, 0.0, 0.003003003003003003]\n",
            "Node 897: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.946, 0.0, 0.002002002002002002]\n",
            "Node 898: [0.8921196259136916, 0, 0, 0.001, 0.002, 0.24189429269375967, 0.0, 0.45, 0.0, 0.003003003003003003]\n",
            "Node 899: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.947, 0.0, 0.002002002002002002]\n",
            "Node 900: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.451, 0.0, 0.003003003003003003]\n",
            "Node 901: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.948, 0.0, 0.002002002002002002]\n",
            "Node 902: [0.05795170773321296, 0, 0, 0.001, 0.002, 0.13096824339329335, 0.0, 0.452, 0.0, 0.003003003003003003]\n",
            "Node 903: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.949, 0.0, 0.002002002002002002]\n",
            "Node 904: [1.1835356453781434, 0, 0, 0.001, 0.002, 0.2806462358427715, 0.0, 0.453, 0.0, 0.003003003003003003]\n",
            "Node 905: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.95, 0.0, 0.002002002002002002]\n",
            "Node 906: [1.3530412383617638, 0, 0, 0.001, 0.002, 0.30318676437930264, 0.0, 0.454, 0.0, 0.003003003003003003]\n",
            "Node 907: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.951, 0.0, 0.002002002002002002]\n",
            "Node 908: [-0.03306361066685929, 0, 0, 0.001, 0.002, 0.11886520097712634, 0.0, 0.455, 0.0, 0.003003003003003003]\n",
            "Node 909: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.952, 0.0, 0.002002002002002002]\n",
            "Node 910: [0.9188397193889423, 0, 0, 0.001, 0.002, 0.245447479458139, 0.0, 0.456, 0.0, 0.003003003003003003]\n",
            "Node 911: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.953, 0.0, 0.002002002002002002]\n",
            "Node 912: [1.5087692831472088, 0, 0, 0.001, 0.002, 0.32389518099045084, 0.0, 0.457, 0.0, 0.003003003003003003]\n",
            "Node 913: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.954, 0.0, 0.002002002002002002]\n",
            "Node 914: [1.7605226638593352, 0, 0, 0.001, 0.002, 0.357372862536087, 0.0, 0.458, 0.0, 0.003003003003003003]\n",
            "Node 915: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.955, 0.0, 0.002002002002002002]\n",
            "Node 916: [0.11514940782867125, 0, 0, 0.001, 0.002, 0.1385742838107928, 0.0, 0.459, 0.0, 0.003003003003003003]\n",
            "Node 917: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.956, 0.0, 0.002002002002002002]\n",
            "Node 918: [0.9726974077999941, 0, 0, 0.001, 0.002, 0.252609371530091, 0.0, 0.46, 0.0, 0.003003003003003003]\n",
            "Node 919: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.957, 0.0, 0.002002002002002002]\n",
            "Node 920: [0.3869428586472357, 0, 0, 0.001, 0.002, 0.17471685542971352, 0.0, 0.461, 0.0, 0.003003003003003003]\n",
            "Node 921: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.958, 0.0, 0.002002002002002002]\n",
            "Node 922: [0.7915017739209513, 0, 0, 0.001, 0.002, 0.22851432378414388, 0.0, 0.462, 0.0, 0.003003003003003003]\n",
            "Node 923: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.959, 0.0, 0.002002002002002002]\n",
            "Node 924: [1.0065150261046083, 0, 0, 0.001, 0.002, 0.25710637352875854, 0.0, 0.463, 0.0, 0.003003003003003003]\n",
            "Node 925: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.96, 0.0, 0.002002002002002002]\n",
            "Node 926: [1.4586691078811138, 0, 0, 0.001, 0.002, 0.3172329558072396, 0.0, 0.464, 0.0, 0.003003003003003003]\n",
            "Node 927: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.961, 0.0, 0.002002002002002002]\n",
            "Node 928: [1.7546776434116242, 0, 0, 0.001, 0.002, 0.35659560293137904, 0.0, 0.465, 0.0, 0.003003003003003003]\n",
            "Node 929: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.962, 0.0, 0.002002002002002002]\n",
            "Node 930: [0.750169129326423, 0, 0, 0.001, 0.002, 0.22301798800799466, 0.0, 0.466, 0.0, 0.003003003003003003]\n",
            "Node 931: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.963, 0.0, 0.002002002002002002]\n",
            "Node 932: [0.4842206989555698, 0, 0, 0.001, 0.002, 0.18765267599378194, 0.0, 0.467, 0.0, 0.003003003003003003]\n",
            "Node 933: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.964, 0.0, 0.002002002002002002]\n",
            "Node 934: [0.1548120465809963, 0, 0, 0.001, 0.002, 0.1438485454141683, 0.0, 0.468, 0.0, 0.003003003003003003]\n",
            "Node 935: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.965, 0.0, 0.002002002002002002]\n",
            "Node 936: [0.8854396025448791, 0, 0, 0.001, 0.002, 0.24100599600266487, 0.0, 0.469, 0.0, 0.003003003003003003]\n",
            "Node 937: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.966, 0.0, 0.002002002002002002]\n",
            "Node 938: [0.7180215168640124, 0, 0, 0.001, 0.002, 0.21874306018210082, 0.0, 0.47, 0.0, 0.003003003003003003]\n",
            "Node 939: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.967, 0.0, 0.002002002002002002]\n",
            "Node 940: [0.24165235037556057, 0, 0, 0.001, 0.002, 0.15539640239840105, 0.0, 0.471, 0.0, 0.003003003003003003]\n",
            "Node 941: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.968, 0.0, 0.002002002002002002]\n",
            "Node 942: [1.173933111785475, 0, 0, 0.001, 0.002, 0.27936930934932264, 0.0, 0.472, 0.0, 0.003003003003003003]\n",
            "Node 943: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.969, 0.0, 0.002002002002002002]\n",
            "Node 944: [0.9488998245485991, 0, 0, 0.001, 0.002, 0.24944481456806572, 0.0, 0.473, 0.0, 0.003003003003003003]\n",
            "Node 945: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.97, 0.0, 0.002002002002002002]\n",
            "Node 946: [0.8190568703173033, 0, 0, 0.001, 0.002, 0.23217854763491003, 0.0, 0.474, 0.0, 0.003003003003003003]\n",
            "Node 947: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.971, 0.0, 0.002002002002002002]\n",
            "Node 948: [0.7898317680787482, 0, 0, 0.001, 0.002, 0.22829224961137018, 0.0, 0.475, 0.0, 0.003003003003003003]\n",
            "Node 949: [-0.8910291120987331, 0, 0, 0.001, 0.001, 0.0047745947146346866, 0.0, 0.972, 0.0, 0.002002002002002002]\n",
            "Node 950: [0.8649820309778903, 0, 0, 0.001, 0.002, 0.23828558738618696, 0.0, 0.476, 0.0, 0.003003003003003003]\n",
            "Node 951: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.973, 0.0, 0.002002002002002002]\n",
            "Node 952: [0.2879950124966983, 0, 0, 0.001, 0.002, 0.16155896069287137, 0.0, 0.477, 0.0, 0.003003003003003003]\n",
            "Node 953: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.974, 0.0, 0.002002002002002002]\n",
            "Node 954: [1.6394472402996065, 0, 0, 0.001, 0.002, 0.3412724850099933, 0.0, 0.478, 0.0, 0.003003003003003003]\n",
            "Node 955: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.975, 0.0, 0.002002002002002002]\n",
            "Node 956: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.479, 0.0, 0.003003003003003003]\n",
            "Node 957: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.976, 0.0, 0.002002002002002002]\n",
            "Node 958: [0.7305465606805359, 0, 0, 0.001, 0.002, 0.2204086164779036, 0.0, 0.48, 0.0, 0.003003003003003003]\n",
            "Node 959: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.977, 0.0, 0.002002002002002002]\n",
            "Node 960: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.481, 0.0, 0.003003003003003003]\n",
            "Node 961: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.978, 0.0, 0.002002002002002002]\n",
            "Node 962: [1.4261039939581521, 0, 0, 0.001, 0.002, 0.3129025094381523, 0.0, 0.482, 0.0, 0.003003003003003003]\n",
            "Node 963: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.979, 0.0, 0.002002002002002002]\n",
            "Node 964: [1.0420026502514255, 0, 0, 0.001, 0.002, 0.26182544970019983, 0.0, 0.483, 0.0, 0.003003003003003003]\n",
            "Node 965: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.98, 0.0, 0.002002002002002002]\n",
            "Node 966: [1.4945742334884817, 0, 0, 0.001, 0.002, 0.32200755052187424, 0.0, 0.484, 0.0, 0.003003003003003003]\n",
            "Node 967: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.981, 0.0, 0.002002002002002002]\n",
            "Node 968: [1.1968956921157687, 0, 0, 0.001, 0.002, 0.2824228292249611, 0.0, 0.485, 0.0, 0.003003003003003003]\n",
            "Node 969: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.982, 0.0, 0.002002002002002002]\n",
            "Node 970: [0.6420362510437685, 0, 0, 0.001, 0.002, 0.2086386853208972, 0.0, 0.486, 0.0, 0.003003003003003003]\n",
            "Node 971: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.983, 0.0, 0.002002002002002002]\n",
            "Node 972: [1.0929378284386218, 0, 0, 0.001, 0.002, 0.2685987119697979, 0.0, 0.487, 0.0, 0.003003003003003003]\n",
            "Node 973: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.984, 0.0, 0.002002002002002002]\n",
            "Node 974: [0.5777410261189468, 0, 0, 0.001, 0.002, 0.20008882966910949, 0.0, 0.488, 0.0, 0.003003003003003003]\n",
            "Node 975: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.985, 0.0, 0.002002002002002002]\n",
            "Node 976: [0.9096546872568249, 0, 0, 0.001, 0.002, 0.2442260715078836, 0.0, 0.489, 0.0, 0.003003003003003003]\n",
            "Node 977: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.986, 0.0, 0.002002002002002002]\n",
            "Node 978: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.49, 0.0, 0.003003003003003003]\n",
            "Node 979: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.987, 0.0, 0.002002002002002002]\n",
            "Node 980: [1.5501019277417374, 0, 0, 0.001, 0.002, 0.32939151676660006, 0.0, 0.491, 0.0, 0.003003003003003003]\n",
            "Node 981: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.988, 0.0, 0.002002002002002002]\n",
            "Node 982: [1.3730813084682019, 0, 0, 0.001, 0.002, 0.30585165445258716, 0.0, 0.492, 0.0, 0.003003003003003003]\n",
            "Node 983: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.989, 0.0, 0.002002002002002002]\n",
            "Node 984: [1.1672530884166625, 0, 0, 0.001, 0.002, 0.27848101265822783, 0.0, 0.493, 0.0, 0.003003003003003003]\n",
            "Node 985: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.99, 0.0, 0.002002002002002002]\n",
            "Node 986: [0.7238665373117235, 0, 0, 0.001, 0.002, 0.2195203197868088, 0.0, 0.494, 0.0, 0.003003003003003003]\n",
            "Node 987: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.991, 0.0, 0.002002002002002002]\n",
            "Node 988: [0.6583188080052493, 0, 0, 0.001, 0.002, 0.2108039085054408, 0.0, 0.495, 0.0, 0.003003003003003003]\n",
            "Node 989: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.992, 0.0, 0.002002002002002002]\n",
            "Node 990: [1.5033417641600486, 0, 0, 0.001, 0.002, 0.32317343992893627, 0.0, 0.496, 0.0, 0.003003003003003003]\n",
            "Node 991: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.993, 0.0, 0.002002002002002002]\n",
            "Node 992: [0.7493341264053216, 0, 0, 0.001, 0.002, 0.2229069509216078, 0.0, 0.497, 0.0, 0.003003003003003003]\n",
            "Node 993: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.994, 0.0, 0.002002002002002002]\n",
            "Node 994: [0.30427756945817913, 0, 0, 0.001, 0.002, 0.16372418387741505, 0.0, 0.498, 0.0, 0.003003003003003003]\n",
            "Node 995: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.995, 0.0, 0.002002002002002002]\n",
            "Node 996: [0.9313647632054661, 0, 0, 0.001, 0.002, 0.2471130357539418, 0.0, 0.499, 0.0, 0.003003003003003003]\n",
            "Node 997: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.996, 0.0, 0.002002002002002002]\n",
            "Node 998: [1.2887460134369424, 0, 0, 0.001, 0.002, 0.29463690872751497, 0.0, 0.5, 0.0, 0.003003003003003003]\n",
            "Node 999: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.998, 0.0, 0.002002002002002002]\n",
            "Using device: cpu\n",
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7487, Time Loss: 0.9023, SLA Loss: 0.6783, Priority Loss: 0.4700\n",
            "Epoch 10, Loss: 0.7269, Time Loss: 0.9023, SLA Loss: 0.6146, Priority Loss: 0.4701\n",
            "Epoch 20, Loss: 0.6970, Time Loss: 0.9022, SLA Loss: 0.5262, Priority Loss: 0.4693\n",
            "Epoch 30, Loss: 0.6340, Time Loss: 0.9026, SLA Loss: 0.3336, Priority Loss: 0.4660\n",
            "Epoch 40, Loss: 0.5719, Time Loss: 0.9020, SLA Loss: 0.1565, Priority Loss: 0.4534\n",
            "Epoch 50, Loss: 0.5401, Time Loss: 0.9022, SLA Loss: 0.0842, Priority Loss: 0.4328\n",
            "Epoch 60, Loss: 0.5187, Time Loss: 0.9022, SLA Loss: 0.0474, Priority Loss: 0.4107\n",
            "Epoch 70, Loss: 0.5070, Time Loss: 0.9020, SLA Loss: 0.0291, Priority Loss: 0.4076\n",
            "Epoch 80, Loss: 0.4993, Time Loss: 0.9021, SLA Loss: 0.0206, Priority Loss: 0.4075\n",
            "Epoch 90, Loss: 0.4930, Time Loss: 0.9020, SLA Loss: 0.0166, Priority Loss: 0.4075\n",
            "Epoch 100, Loss: 0.4874, Time Loss: 0.9019, SLA Loss: 0.0141, Priority Loss: 0.4074\n",
            "Epoch 110, Loss: 0.4821, Time Loss: 0.9019, SLA Loss: 0.0124, Priority Loss: 0.4074\n",
            "Epoch 120, Loss: 0.4770, Time Loss: 0.9019, SLA Loss: 0.0110, Priority Loss: 0.4074\n",
            "Epoch 130, Loss: 0.4721, Time Loss: 0.9019, SLA Loss: 0.0099, Priority Loss: 0.4074\n",
            "Epoch 140, Loss: 0.4673, Time Loss: 0.9019, SLA Loss: 0.0090, Priority Loss: 0.4074\n",
            "Epoch 150, Loss: 0.4627, Time Loss: 0.9019, SLA Loss: 0.0083, Priority Loss: 0.4074\n",
            "Epoch 160, Loss: 0.4581, Time Loss: 0.9019, SLA Loss: 0.0076, Priority Loss: 0.4073\n",
            "Epoch 170, Loss: 0.4535, Time Loss: 0.9019, SLA Loss: 0.0070, Priority Loss: 0.4073\n",
            "Epoch 180, Loss: 0.4491, Time Loss: 0.9018, SLA Loss: 0.0065, Priority Loss: 0.4073\n",
            "Epoch 190, Loss: 0.4446, Time Loss: 0.9018, SLA Loss: 0.0061, Priority Loss: 0.4073\n",
            "Epoch 200, Loss: 0.4402, Time Loss: 0.9018, SLA Loss: 0.0057, Priority Loss: 0.4073\n",
            "Epoch 210, Loss: 0.4359, Time Loss: 0.9018, SLA Loss: 0.0053, Priority Loss: 0.4072\n",
            "Epoch 220, Loss: 0.4316, Time Loss: 0.9018, SLA Loss: 0.0049, Priority Loss: 0.4072\n",
            "Epoch 230, Loss: 0.4273, Time Loss: 0.9018, SLA Loss: 0.0046, Priority Loss: 0.4072\n",
            "Epoch 240, Loss: 0.4231, Time Loss: 0.9017, SLA Loss: 0.0043, Priority Loss: 0.4072\n",
            "Epoch 250, Loss: 0.4189, Time Loss: 0.9017, SLA Loss: 0.0040, Priority Loss: 0.4071\n",
            "Epoch 260, Loss: 0.4147, Time Loss: 0.9017, SLA Loss: 0.0038, Priority Loss: 0.4071\n",
            "Epoch 270, Loss: 0.4106, Time Loss: 0.9017, SLA Loss: 0.0036, Priority Loss: 0.4071\n",
            "Epoch 280, Loss: 0.4064, Time Loss: 0.9017, SLA Loss: 0.0034, Priority Loss: 0.4071\n",
            "Epoch 290, Loss: 0.4024, Time Loss: 0.9017, SLA Loss: 0.0032, Priority Loss: 0.4070\n",
            "Epoch 300, Loss: 0.3983, Time Loss: 0.9016, SLA Loss: 0.0031, Priority Loss: 0.4070\n",
            "Epoch 310, Loss: 0.3943, Time Loss: 0.9016, SLA Loss: 0.0029, Priority Loss: 0.4070\n",
            "Epoch 320, Loss: 0.3903, Time Loss: 0.9016, SLA Loss: 0.0028, Priority Loss: 0.4070\n",
            "Epoch 330, Loss: 0.3863, Time Loss: 0.9016, SLA Loss: 0.0027, Priority Loss: 0.4070\n",
            "Epoch 340, Loss: 0.3823, Time Loss: 0.9016, SLA Loss: 0.0025, Priority Loss: 0.4069\n",
            "Epoch 350, Loss: 0.3784, Time Loss: 0.9016, SLA Loss: 0.0024, Priority Loss: 0.4069\n",
            "Epoch 360, Loss: 0.3745, Time Loss: 0.9016, SLA Loss: 0.0023, Priority Loss: 0.4069\n",
            "Epoch 370, Loss: 0.3706, Time Loss: 0.9016, SLA Loss: 0.0023, Priority Loss: 0.4069\n",
            "Epoch 380, Loss: 0.3667, Time Loss: 0.9016, SLA Loss: 0.0022, Priority Loss: 0.4069\n",
            "Epoch 390, Loss: 0.3628, Time Loss: 0.9016, SLA Loss: 0.0021, Priority Loss: 0.4068\n",
            "Epoch 400, Loss: 0.3590, Time Loss: 0.9016, SLA Loss: 0.0020, Priority Loss: 0.4068\n",
            "Epoch 410, Loss: 0.3552, Time Loss: 0.9016, SLA Loss: 0.0019, Priority Loss: 0.4068\n",
            "Epoch 420, Loss: 0.3514, Time Loss: 0.9016, SLA Loss: 0.0019, Priority Loss: 0.4068\n",
            "Epoch 430, Loss: 0.3476, Time Loss: 0.9016, SLA Loss: 0.0018, Priority Loss: 0.4068\n",
            "Epoch 440, Loss: 0.3438, Time Loss: 0.9016, SLA Loss: 0.0018, Priority Loss: 0.4068\n",
            "Epoch 450, Loss: 0.3401, Time Loss: 0.9015, SLA Loss: 0.0017, Priority Loss: 0.4067\n",
            "Epoch 460, Loss: 0.3363, Time Loss: 0.9015, SLA Loss: 0.0016, Priority Loss: 0.4067\n",
            "Epoch 470, Loss: 0.3326, Time Loss: 0.9015, SLA Loss: 0.0016, Priority Loss: 0.4067\n",
            "Epoch 480, Loss: 0.3289, Time Loss: 0.9015, SLA Loss: 0.0015, Priority Loss: 0.4067\n",
            "Epoch 490, Loss: 0.3252, Time Loss: 0.9015, SLA Loss: 0.0015, Priority Loss: 0.4067\n",
            "Model, task embeddings, and graph embedding saved to ./embedding_model_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Tier-1 and Tier-2 environments\n",
        "tier1_env = Tier1SchedulerEnv(task_embeddings)\n",
        "\n",
        "\n",
        "# Wrap environments for Stable-Baselines3\n",
        "tier1_env = DummyVecEnv([lambda: tier1_env])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7yx_Jhpwgcz",
        "outputId": "c55176c7-5853-4434-a680-58e1624da4b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tier2_env = Tier2SchedulerEnv(task_embeddings, np.random.rand(5))\n",
        "tier2_env = DummyVecEnv([lambda: tier2_env])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTiEaXlb4ujh",
        "outputId": "945e7edf-0e66-4a3d-c6ef-9087015e1f21"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Tier-1 Scheduler (PPO Agent)\n",
        "print(\"Training Tier-1 Scheduler...\")\n",
        "tier1_model = PPO(\"MlpPolicy\", tier1_env, verbose=1, tensorboard_log=\"./tier1_tensorboard/\")\n",
        "tier1_callback = EvalCallback(tier1_env, eval_freq=1000, callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=100, verbose=1))\n",
        "tier1_model.learn(total_timesteps=10000, callback=tier1_callback)\n",
        "tier1_model.save(\"tier1_scheduler_new\")\n",
        "print(\"Tier-1 Scheduler trained and saved.\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Model of tier 1 trained and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMk5asGmth7T",
        "outputId": "c0e0a4f4-8fd1-4929-86e1-d8923563a0c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Tier-1 Scheduler...\n",
            "Using cpu device\n",
            "Logging to ./tier1_tensorboard/PPO_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=1000, episode_reward=-563.03 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | -563     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=2000, episode_reward=-563.03 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | -563     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 115  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 17   |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -464        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013893232 |\n",
            "|    clip_fraction        | 0.297       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.07        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    value_loss           | 20.2        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=4000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | -464     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 4000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 120  |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 33   |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -464        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007829923 |\n",
            "|    clip_fraction        | 0.00229     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.737       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00488    |\n",
            "|    value_loss           | 26.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=6000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | -464     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 116  |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 52   |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -464        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 7000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015943045 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.57        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.011      |\n",
            "|    value_loss           | 17          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=8000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | -464     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 8000     |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 120  |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 67   |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -464        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018671654 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.926      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.41        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0101     |\n",
            "|    value_loss           | 13.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-464.07 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | -464     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 120   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 85    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "Tier-1 Scheduler trained and saved.\n",
            "Model of tier 1 trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Tier-2 Scheduler (PPO Agent)\n",
        "print(\"Training Tier-2 Scheduler...\")\n",
        "tier2_model = PPO(\"MlpPolicy\", tier2_env, verbose=1, tensorboard_log=\"./tier2_tensorboard/\")\n",
        "tier2_callback = EvalCallback(tier2_env, eval_freq=1000, callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=100, verbose=1))\n",
        "tier2_model.learn(total_timesteps=10000, callback=tier2_callback)\n",
        "tier2_model.save(\"tier2_scheduler_new\")\n",
        "print(\"Tier-2 Scheduler trained and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvSpo7yHzpc-",
        "outputId": "38c213de-20ce-423b-ed2c-47a7ef29b80e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Tier-2 Scheduler...\n",
            "Using cpu device\n",
            "Logging to ./tier2_tensorboard/PPO_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=1000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 1e+03     |\n",
            "|    mean_reward     | -1.05e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1000      |\n",
            "----------------------------------\n",
            "New best mean reward!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=2000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 1e+03     |\n",
            "|    mean_reward     | -1.05e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2000      |\n",
            "----------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 137  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 14   |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=3000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -1.05e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011817899 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.7        |\n",
            "|    explained_variance   | -0.00835    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.9        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00608    |\n",
            "|    value_loss           | 101         |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=4000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 1e+03     |\n",
            "|    mean_reward     | -1.05e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 4000      |\n",
            "----------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 131  |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 31   |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=5000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -1.05e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008356707 |\n",
            "|    clip_fraction        | 0.0675      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.69       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37.3        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0038     |\n",
            "|    value_loss           | 145         |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=6000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 1e+03     |\n",
            "|    mean_reward     | -1.05e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 6000      |\n",
            "----------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 129  |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 47   |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=7000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -1.05e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 7000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013113859 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.67       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.9        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00166    |\n",
            "|    value_loss           | 124         |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=8000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 1e+03     |\n",
            "|    mean_reward     | -1.05e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 8000      |\n",
            "----------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 127  |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 64   |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=9000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -1.05e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018864375 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.66       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27          |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00572    |\n",
            "|    value_loss           | 105         |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=10000, episode_reward=-1046.38 +/- 0.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 1e+03     |\n",
            "|    mean_reward     | -1.05e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 10000     |\n",
            "----------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 126   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 80    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "Tier-2 Scheduler trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained models (if needed)\n",
        "tier1_model = PPO.load(\"tier1_scheduler_new\")\n",
        "tier2_model = PPO.load(\"tier2_scheduler_new\")\n",
        "\n",
        "# Evaluate the trained models\n",
        "print(\"Evaluating Tier-1 Scheduler...\")\n",
        "tier1_rewards = []\n",
        "tier2_rewards = []\n",
        "obs1 = tier1_env.reset()\n",
        "obs2 = tier2_env.reset()\n",
        "for _ in range(task_embeddings.shape[0]):\n",
        "    action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "    obs1, reward1, done1, info1 = tier1_env.step(action1)\n",
        "    tier1_rewards.append(reward1)\n",
        "    if done1:\n",
        "        break\n",
        "\n",
        "    action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "    obs2, reward2, done2, info2 = tier2_env.step(action2)\n",
        "    tier2_rewards.append(reward2)\n",
        "    if done2:\n",
        "        break\n",
        "\n",
        "print(f\"Tier-1 Average Reward: {np.mean(tier1_rewards)}\")\n",
        "print(f\"Tier-2 Average Reward: {np.mean(tier2_rewards)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8xoXbcyhU8X",
        "outputId": "3ae74b1b-9416-4e53-b701-82bd233db4b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Tier-1 Scheduler...\n",
            "Tier-1 Average Reward: -0.4640720784664154\n",
            "Tier-2 Average Reward: -1.0463769435882568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_full_pipeline(node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "                          task_priorities, node_features_list, device):\n",
        "    def objective(trial):\n",
        "        heads = trial.suggest_int('heads', 2, 8)\n",
        "        base_hidden_dim = trial.suggest_categorical('base_hidden_dim', [32, 64, 128])\n",
        "\n",
        "        # Compute hidden_dim dynamically\n",
        "        hidden_dim = ((base_hidden_dim + heads - 1) // heads) * heads\n",
        "\n",
        "        num_gnn_layers = trial.suggest_int('num_gnn_layers', 1, 3)\n",
        "\n",
        "        model = TaskEmbeddingModel(\n",
        "            input_dim=node_features.size(1),\n",
        "            hidden_dim=hidden_dim,\n",
        "            heads=heads,\n",
        "            num_gnn_layers=num_gnn_layers\n",
        "        ).to(device)\n",
        "\n",
        "        trained_model = train_embeddings(\n",
        "            node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "            task_priorities, node_features_list, epochs=50, save_path=\"./temp_model\"\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            task_embeddings_full, _ = model(\n",
        "                node_features.to(device), edge_index.to(device), edge_attr.to(device),\n",
        "                torch.zeros(node_features.size(0), dtype=torch.long).to(device)\n",
        "            )\n",
        "            task_embeddings = task_embeddings_full[:, :-3].cpu().numpy()\n",
        "\n",
        "        # Tier 1 PPO Hyperparameters\n",
        "        tier1_lr = trial.suggest_float('tier1_lr', 1e-5, 1e-2, log=True)\n",
        "        tier1_n_steps = trial.suggest_categorical('tier1_n_steps', [1024, 2048, 4096])\n",
        "        tier1_batch_size = trial.suggest_categorical('tier1_batch_size', [32, 64, 128])\n",
        "\n",
        "        tier1_env = DummyVecEnv([lambda: Tier1SchedulerEnv(task_embeddings)])\n",
        "        tier1_model = PPO(\n",
        "            \"MlpPolicy\", tier1_env, learning_rate=tier1_lr, n_steps=tier1_n_steps,\n",
        "            batch_size=tier1_batch_size, verbose=0\n",
        "        )\n",
        "        tier1_model.learn(total_timesteps=5000)\n",
        "\n",
        "        # Tier 2 PPO Hyperparameters\n",
        "        tier2_lr = trial.suggest_float('tier2_lr', 1e-5, 1e-2, log=True)\n",
        "        tier2_n_steps = trial.suggest_categorical('tier2_n_steps', [1024, 2048, 4096])\n",
        "        tier2_batch_size = trial.suggest_categorical('tier2_batch_size', [32, 64, 128])\n",
        "\n",
        "        tier2_env = DummyVecEnv([lambda: Tier2SchedulerEnv(task_embeddings, np.random.rand(5))])\n",
        "        tier2_model = PPO(\n",
        "            \"MlpPolicy\", tier2_env, learning_rate=tier2_lr, n_steps=tier2_n_steps,\n",
        "            batch_size=tier2_batch_size, verbose=0\n",
        "        )\n",
        "        tier2_model.learn(total_timesteps=5000)\n",
        "\n",
        "        # Evaluate Full Pipeline\n",
        "        tier1_rewards = []\n",
        "        tier2_rewards = []\n",
        "        obs1 = tier1_env.reset()\n",
        "        obs2 = tier2_env.reset()\n",
        "        for _ in range(task_embeddings.shape[0]):\n",
        "            action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "            obs1, reward1, done1, _ = tier1_env.step(action1)\n",
        "            tier1_rewards.append(reward1[0])\n",
        "            if done1:\n",
        "                break\n",
        "\n",
        "            action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "            obs2, reward2, done2, _ = tier2_env.step(action2)\n",
        "            tier2_rewards.append(reward2[0])\n",
        "            if done2:\n",
        "                break\n",
        "\n",
        "        combined_reward = 0.5 * np.mean(tier1_rewards) + 0.5 * np.mean(tier2_rewards)\n",
        "        return combined_reward\n",
        "\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=20)\n",
        "\n",
        "    # Extract best hyperparameters\n",
        "    best_params = study.best_params.copy()\n",
        "\n",
        "    # Compute hidden_dim and add it manually (AFTER optimization)\n",
        "    best_hidden_dim = ((best_params['base_hidden_dim'] + best_params['heads'] - 1) // best_params['heads']) * best_params['heads']\n",
        "    best_params['hidden_dim'] = best_hidden_dim\n",
        "\n",
        "    print(\"Best hyperparameters:\", best_params)\n",
        "    return best_params\n"
      ],
      "metadata": {
        "id": "qdq1QvAk2Zhw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- MAIN EXECUTION ---------------------- #\n",
        "# Load and prepare data\n",
        "workflow_dag = load_dag(\"cybershake_dag.json\")\n",
        "(node_features, edge_index, edge_attr, adjacency_matrix, execution_times, sla_adherences,\n",
        " task_priorities, node_features_list) = prepare_workflow_dag(workflow_dag)\n",
        "\n",
        "print(\"Initial Node Features:\")\n",
        "for i, features in enumerate(node_features_list):\n",
        "    print(f\"Node {i}: {features}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Run hyperparameter tuning\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "best_params = optimize_full_pipeline(\n",
        "    node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "    task_priorities, node_features_list, device\n",
        ")\n",
        "\n",
        "# Train the GNN-based task embedding model with best parameters\n",
        "embedding_model_save_path = \"./embedding_model_data\"\n",
        "model = TaskEmbeddingModel(\n",
        "    input_dim=node_features.size(1),\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    heads=best_params['heads'],\n",
        "    num_gnn_layers=best_params['num_gnn_layers']\n",
        ").to(device)\n",
        "model = train_embeddings(\n",
        "    node_features, edge_index, edge_attr, execution_times, sla_adherences,\n",
        "    task_priorities, node_features_list, epochs=500, save_path=embedding_model_save_path\n",
        ")\n",
        "\n",
        "# Generate task embeddings with the tuned model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    task_embeddings_full, graph_embedding = model(\n",
        "        node_features.to(device), edge_index.to(device), edge_attr.to(device),\n",
        "        torch.zeros(node_features.size(0), dtype=torch.long).to(device)\n",
        "    )\n",
        "    task_embeddings = task_embeddings_full[:, :-3].cpu().numpy()\n",
        "\n",
        "# Initialize environments with tuned embeddings\n",
        "tier1_env = DummyVecEnv([lambda: Tier1SchedulerEnv(task_embeddings)])\n",
        "tier2_env = DummyVecEnv([lambda: Tier2SchedulerEnv(task_embeddings, np.random.rand(5))])\n",
        "\n",
        "# Train Tier-1 Scheduler with best parameters\n",
        "print(\"Training Tier-1 Scheduler with tuned hyperparameters...\")\n",
        "tier1_model = PPO(\n",
        "    \"MlpPolicy\", tier1_env,\n",
        "    learning_rate=best_params['tier1_lr'],\n",
        "    n_steps=best_params['tier1_n_steps'],\n",
        "    batch_size=best_params['tier1_batch_size'],\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./tier1_tensorboard1/\"\n",
        ")\n",
        "tier1_callback = EvalCallback(tier1_env, eval_freq=1000, callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=100, verbose=1))\n",
        "tier1_model.learn(total_timesteps=10000, callback=tier1_callback)\n",
        "tier1_model.save(\"tier1_scheduler_tuned\")\n",
        "print(\"Tier-1 Scheduler trained and saved.\")\n",
        "\n",
        "# Train Tier-2 Scheduler with best parameters\n",
        "print(\"Training Tier-2 Scheduler with tuned hyperparameters...\")\n",
        "tier2_model = PPO(\n",
        "    \"MlpPolicy\", tier2_env,\n",
        "    learning_rate=best_params['tier2_lr'],\n",
        "    n_steps=best_params['tier2_n_steps'],\n",
        "    batch_size=best_params['tier2_batch_size'],\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./tier2_tensorboard1/\"\n",
        ")\n",
        "tier2_callback = EvalCallback(tier2_env, eval_freq=1000, callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=100, verbose=1))\n",
        "tier2_model.learn(total_timesteps=10000, callback=tier2_callback)\n",
        "tier2_model.save(\"tier2_scheduler_tuned\")\n",
        "print(\"Tier-2 Scheduler trained and saved.\")\n",
        "\n",
        "print(\"All models trained and saved with tuned hyperparameters.\")\n",
        "\n",
        "# Load and evaluate the tuned models\n",
        "tier1_model = PPO.load(\"tier1_scheduler_tuned\")\n",
        "tier2_model = PPO.load(\"tier2_scheduler_tuned\")\n",
        "\n",
        "print(\"Evaluating Tuned Tier-1 Scheduler...\")\n",
        "tier1_rewards = []\n",
        "tier2_rewards = []\n",
        "obs1 = tier1_env.reset()\n",
        "obs2 = tier2_env.reset()\n",
        "for _ in range(task_embeddings.shape[0]):\n",
        "    action1, _ = tier1_model.predict(obs1, deterministic=True)\n",
        "    obs1, reward1, done1, info1 = tier1_env.step(action1)\n",
        "    tier1_rewards.append(reward1[0])\n",
        "    if done1:\n",
        "        break\n",
        "\n",
        "    action2, _ = tier2_model.predict(obs2, deterministic=True)\n",
        "    obs2, reward2, done2, info2 = tier2_env.step(action2)\n",
        "    tier2_rewards.append(reward2[0])\n",
        "    if done2:\n",
        "        break\n",
        "\n",
        "print(f\"Tuned Tier-1 Average Reward: {np.mean(tier1_rewards)}\")\n",
        "print(f\"Tuned Tier-2 Average Reward: {np.mean(tier2_rewards)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zviXtyaS1CPH",
        "outputId": "832d5e1d-8a48-4f20-f34c-b2d1859e911c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-09 18:04:02,151] A new study created in memory with name: no-name-3ba56ae1-8a81-48e5-87c8-c3f484d51c3e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Node Features:\n",
            "Node 0: [-0.7908287615665436, 0, 0, 0.497, 0.0, 0.018099045081057072, 4.0, 0.999, 0.003, 0.4974974974974975]\n",
            "Node 1: [-0.5582804480397533, 0, 0, 0.497, 0.0, 0.0490228736397957, 3.0, 0.997, 0.002, 0.4974974974974975]\n",
            "Node 2: [3.1896301633246904, 0, 0, 0.0, 0.109, 0.5474128358871865, 1.0, 0.0, 0.0, 0.1091091091091091]\n",
            "Node 3: [0.8912846229925903, 0, 0, 0.001, 0.002, 0.24178325560737288, 2.0, 0.004, 0.001, 0.003003003003003003]\n",
            "Node 4: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.501, 0.002, 0.002002002002002002]\n",
            "Node 5: [0.14353950714612498, 0, 0, 0.001, 0.002, 0.1423495447479458, 2.0, 0.005, 0.001, 0.003003003003003003]\n",
            "Node 6: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.502, 0.002, 0.002002002002002002]\n",
            "Node 7: [0.4846382004161205, 0, 0, 0.001, 0.002, 0.18770819453697532, 2.0, 0.006, 0.001, 0.003003003003003003]\n",
            "Node 8: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 3.0, 0.503, 0.002, 0.002002002002002002]\n",
            "Node 9: [0.35354274180317236, 0, 0, 0.001, 0.002, 0.17027537197423936, 2.0, 0.007, 0.001, 0.003003003003003003]\n",
            "Node 10: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.504, 0.002, 0.002002002002002002]\n",
            "Node 11: [1.3893638654296827, 0, 0, 0.001, 0.002, 0.3080168776371308, 2.0, 0.008, 0.001, 0.003003003003003003]\n",
            "Node 12: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 3.0, 0.505, 0.002, 0.002002002002002002]\n",
            "Node 13: [0.15063703197548833, 0, 0, 0.001, 0.002, 0.14329335998223405, 2.0, 0.009, 0.001, 0.003003003003003003]\n",
            "Node 14: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.506, 0.002, 0.002002002002002002]\n",
            "Node 15: [1.0954428372019267, 0, 0, 0.001, 0.002, 0.2689318232289585, 2.0, 0.01, 0.001, 0.003003003003003003]\n",
            "Node 16: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.507, 0.002, 0.002002002002002002]\n",
            "Node 17: [1.1388629890992088, 0, 0, 0.001, 0.002, 0.2747057517210748, 2.0, 0.011, 0.001, 0.003003003003003003]\n",
            "Node 18: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.508, 0.002, 0.002002002002002002]\n",
            "Node 19: [0.049601678522197185, 0, 0, 0.001, 0.002, 0.12985787252942482, 2.0, 0.012, 0.001, 0.003003003003003003]\n",
            "Node 20: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 3.0, 0.509, 0.002, 0.002002002002002002]\n",
            "Node 21: [1.7534251390299718, 0, 0, 0.001, 0.002, 0.3564290473017988, 2.0, 0.013, 0.001, 0.003003003003003003]\n",
            "Node 22: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 3.0, 0.51, 0.002, 0.002002002002002002]\n",
            "Node 23: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.014, 0.001, 0.003003003003003003]\n",
            "Node 24: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 3.0, 0.511, 0.002, 0.002002002002002002]\n",
            "Node 25: [1.3960438887984952, 0, 0, 0.001, 0.002, 0.3089051743282256, 2.0, 0.015, 0.001, 0.003003003003003003]\n",
            "Node 26: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 3.0, 0.512, 0.002, 0.002002002002002002]\n",
            "Node 27: [0.3218126308013124, 0, 0, 0.001, 0.002, 0.16605596269153894, 2.0, 0.016, 0.001, 0.003003003003003003]\n",
            "Node 28: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.513, 0.002, 0.002002002002002002]\n",
            "Node 29: [0.04459166099558766, 0, 0, 0.001, 0.002, 0.12919165001110372, 2.0, 0.017, 0.001, 0.003003003003003003]\n",
            "Node 30: [-0.9114866836657218, 0, 0, 0.001, 0.001, 0.0020541860981567843, 3.0, 0.514, 0.002, 0.002002002002002002]\n",
            "Node 31: [1.4048114194700623, 0, 0, 0.001, 0.002, 0.31007106373528753, 2.0, 0.018, 0.001, 0.003003003003003003]\n",
            "Node 32: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.515, 0.002, 0.002002002002002002]\n",
            "Node 33: [0.1147319063681204, 0, 0, 0.001, 0.002, 0.13851876526759938, 2.0, 0.019, 0.001, 0.003003003003003003]\n",
            "Node 34: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.516, 0.002, 0.002002002002002002]\n",
            "Node 35: [0.8019393104347211, 0, 0, 0.001, 0.002, 0.22990228736397955, 2.0, 0.02, 0.001, 0.003003003003003003]\n",
            "Node 36: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.517, 0.002, 0.002002002002002002]\n",
            "Node 37: [1.2231982841304683, 0, 0, 0.001, 0.002, 0.28592049744614695, 2.0, 0.021, 0.001, 0.003003003003003003]\n",
            "Node 38: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.518, 0.002, 0.002002002002002002]\n",
            "Node 39: [1.3689062938626941, 0, 0, 0.001, 0.002, 0.3052964690206529, 2.0, 0.022, 0.001, 0.003003003003003003]\n",
            "Node 40: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.519, 0.002, 0.002002002002002002]\n",
            "Node 41: [0.400302905384861, 0, 0, 0.001, 0.002, 0.17649344881190318, 2.0, 0.023, 0.001, 0.003003003003003003]\n",
            "Node 42: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 3.0, 0.52, 0.002, 0.002002002002002002]\n",
            "Node 43: [0.08383679828736199, 0, 0, 0.001, 0.002, 0.1344103930712858, 2.0, 0.024, 0.001, 0.003003003003003003]\n",
            "Node 44: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.521, 0.002, 0.002002002002002002]\n",
            "Node 45: [0.125586944342441, 0, 0, 0.001, 0.002, 0.13996224739062846, 2.0, 0.025, 0.001, 0.003003003003003003]\n",
            "Node 46: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 3.0, 0.522, 0.002, 0.002002002002002002]\n",
            "Node 47: [0.9772899238660527, 0, 0, 0.001, 0.002, 0.2532200755052187, 2.0, 0.026, 0.001, 0.003003003003003003]\n",
            "Node 48: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.523, 0.002, 0.002002002002002002]\n",
            "Node 49: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 2.0, 0.027, 0.001, 0.003003003003003003]\n",
            "Node 50: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.524, 0.002, 0.002002002002002002]\n",
            "Node 51: [0.5209608274840392, 0, 0, 0.001, 0.002, 0.19253830779480344, 2.0, 0.028, 0.001, 0.003003003003003003]\n",
            "Node 52: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 3.0, 0.525, 0.002, 0.002002002002002002]\n",
            "Node 53: [1.0136125509339717, 0, 0, 0.001, 0.002, 0.25805018876304686, 2.0, 0.029, 0.001, 0.003003003003003003]\n",
            "Node 54: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.526, 0.002, 0.002002002002002002]\n",
            "Node 55: [0.155229548041547, 0, 0, 0.001, 0.002, 0.14390406395736174, 2.0, 0.03, 0.001, 0.003003003003003003]\n",
            "Node 56: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.527, 0.002, 0.002002002002002002]\n",
            "Node 57: [0.8908671215320395, 0, 0, 0.001, 0.002, 0.24172773706417944, 2.0, 0.031, 0.001, 0.003003003003003003]\n",
            "Node 58: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.528, 0.002, 0.002002002002002002]\n",
            "Node 59: [0.6219961809373304, 0, 0, 0.001, 0.002, 0.20597379524761267, 2.0, 0.032, 0.001, 0.003003003003003003]\n",
            "Node 60: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 3.0, 0.529, 0.002, 0.002002002002002002]\n",
            "Node 61: [1.7550951448721752, 0, 0, 0.001, 0.002, 0.3566511214745725, 2.0, 0.033, 0.001, 0.003003003003003003]\n",
            "Node 62: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.53, 0.002, 0.002002002002002002]\n",
            "Node 63: [0.6499687787942334, 0, 0, 0.001, 0.002, 0.20969353764157228, 2.0, 0.034, 0.001, 0.003003003003003003]\n",
            "Node 64: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 3.0, 0.531, 0.002, 0.002002002002002002]\n",
            "Node 65: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.035, 0.001, 0.003003003003003003]\n",
            "Node 66: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.532, 0.002, 0.002002002002002002]\n",
            "Node 67: [1.1150654058478138, 0, 0, 0.001, 0.002, 0.2715411947590495, 2.0, 0.036, 0.001, 0.003003003003003003]\n",
            "Node 68: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.533, 0.002, 0.002002002002002002]\n",
            "Node 69: [1.2227807826699175, 0, 0, 0.001, 0.002, 0.2858649789029536, 2.0, 0.037, 0.001, 0.003003003003003003]\n",
            "Node 70: [-0.8981266369280967, 0, 0, 0.001, 0.001, 0.0038307794803464344, 3.0, 0.534, 0.002, 0.002002002002002002]\n",
            "Node 71: [1.4110739413783238, 0, 0, 0.001, 0.002, 0.3109038418831889, 2.0, 0.038, 0.001, 0.003003003003003003]\n",
            "Node 72: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.535, 0.002, 0.002002002002002002]\n",
            "Node 73: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 2.0, 0.039, 0.001, 0.003003003003003003]\n",
            "Node 74: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 3.0, 0.536, 0.002, 0.002002002002002002]\n",
            "Node 75: [0.3255701439462695, 0, 0, 0.001, 0.002, 0.1665556295802798, 2.0, 0.04, 0.001, 0.003003003003003003]\n",
            "Node 76: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.537, 0.002, 0.002002002002002002]\n",
            "Node 77: [1.4778741750664504, 0, 0, 0.001, 0.002, 0.3197868087941372, 2.0, 0.041, 0.001, 0.003003003003003003]\n",
            "Node 78: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 3.0, 0.538, 0.002, 0.002002002002002002]\n",
            "Node 79: [1.4507365801306489, 0, 0, 0.001, 0.002, 0.3161781034865645, 2.0, 0.042, 0.001, 0.003003003003003003]\n",
            "Node 80: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 3.0, 0.539, 0.002, 0.002002002002002002]\n",
            "Node 81: [0.342270202368301, 0, 0, 0.001, 0.002, 0.16877637130801684, 2.0, 0.043, 0.001, 0.003003003003003003]\n",
            "Node 82: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.54, 0.002, 0.002002002002002002]\n",
            "Node 83: [1.2732984593965633, 0, 0, 0.001, 0.002, 0.2925827226293582, 2.0, 0.044, 0.001, 0.003003003003003003]\n",
            "Node 84: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.541, 0.002, 0.002002002002002002]\n",
            "Node 85: [0.27630497160127626, 0, 0, 0.001, 0.002, 0.16000444148345547, 2.0, 0.045, 0.001, 0.003003003003003003]\n",
            "Node 86: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 3.0, 0.542, 0.002, 0.002002002002002002]\n",
            "Node 87: [0.9877274603798225, 0, 0, 0.001, 0.002, 0.25460803908505436, 2.0, 0.046, 0.001, 0.003003003003003003]\n",
            "Node 88: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 3.0, 0.543, 0.002, 0.002002002002002002]\n",
            "Node 89: [1.1271729482037867, 0, 0, 0.001, 0.002, 0.2731512325116589, 2.0, 0.047, 0.001, 0.003003003003003003]\n",
            "Node 90: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 3.0, 0.544, 0.002, 0.002002002002002002]\n",
            "Node 91: [0.6140636531868655, 0, 0, 0.001, 0.002, 0.20491894292693758, 2.0, 0.048, 0.001, 0.003003003003003003]\n",
            "Node 92: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 3.0, 0.545, 0.002, 0.002002002002002002]\n",
            "Node 93: [0.03164911571851322, 0, 0, 0.001, 0.002, 0.12747057517210747, 2.0, 0.049, 0.001, 0.003003003003003003]\n",
            "Node 94: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 3.0, 0.546, 0.002, 0.002002002002002002]\n",
            "Node 95: [1.1547280446001387, 0, 0, 0.001, 0.002, 0.276815456362425, 2.0, 0.05, 0.001, 0.003003003003003003]\n",
            "Node 96: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 3.0, 0.547, 0.002, 0.002002002002002002]\n",
            "Node 97: [1.0754027670954884, 0, 0, 0.001, 0.002, 0.26626693315567396, 2.0, 0.051, 0.001, 0.003003003003003003]\n",
            "Node 98: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 3.0, 0.548, 0.002, 0.002002002002002002]\n",
            "Node 99: [1.3167186112938454, 0, 0, 0.001, 0.002, 0.2983566511214746, 2.0, 0.052, 0.001, 0.003003003003003003]\n",
            "Node 100: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 3.0, 0.549, 0.002, 0.002002002002002002]\n",
            "Node 101: [1.3125435966883374, 0, 0, 0.001, 0.002, 0.2978014656895403, 2.0, 0.053, 0.001, 0.003003003003003003]\n",
            "Node 102: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 3.0, 0.55, 0.002, 0.002002002002002002]\n",
            "Node 103: [1.3405161945452402, 0, 0, 0.001, 0.002, 0.30152120808349986, 2.0, 0.054, 0.001, 0.003003003003003003]\n",
            "Node 104: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.551, 0.002, 0.002002002002002002]\n",
            "Node 105: [1.1605730650478496, 0, 0, 0.001, 0.002, 0.277592715967133, 2.0, 0.055, 0.001, 0.003003003003003003]\n",
            "Node 106: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.552, 0.002, 0.002002002002002002]\n",
            "Node 107: [0.2696249482324636, 0, 0, 0.001, 0.002, 0.15911614479236064, 2.0, 0.056, 0.001, 0.003003003003003003]\n",
            "Node 108: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.553, 0.002, 0.002002002002002002]\n",
            "Node 109: [0.6424537525043192, 0, 0, 0.001, 0.002, 0.2086942038640906, 2.0, 0.057, 0.001, 0.003003003003003003]\n",
            "Node 110: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 3.0, 0.554, 0.002, 0.002002002002002002]\n",
            "Node 111: [1.7258700426336198, 0, 0, 0.001, 0.002, 0.35276482345103266, 2.0, 0.058, 0.001, 0.003003003003003003]\n",
            "Node 112: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 3.0, 0.555, 0.002, 0.002002002002002002]\n",
            "Node 113: [0.5802460348822513, 0, 0, 0.001, 0.002, 0.20042194092827, 2.0, 0.059, 0.001, 0.003003003003003003]\n",
            "Node 114: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 3.0, 0.556, 0.002, 0.002002002002002002]\n",
            "Node 115: [1.7112574915143424, 0, 0, 0.001, 0.002, 0.3508216744392627, 2.0, 0.06, 0.001, 0.003003003003003003]\n",
            "Node 116: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 3.0, 0.557, 0.002, 0.002002002002002002]\n",
            "Node 117: [0.4144979550435877, 0, 0, 0.001, 0.002, 0.17838107928047964, 2.0, 0.061, 0.001, 0.003003003003003003]\n",
            "Node 118: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.558, 0.002, 0.002002002002002002]\n",
            "Node 119: [1.3743338128498543, 0, 0, 0.001, 0.002, 0.3060182100821674, 2.0, 0.062, 0.001, 0.003003003003003003]\n",
            "Node 120: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 3.0, 0.559, 0.002, 0.002002002002002002]\n",
            "Node 121: [0.06630173694422874, 0, 0, 0.001, 0.002, 0.13207861425716186, 2.0, 0.063, 0.001, 0.003003003003003003]\n",
            "Node 122: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 3.0, 0.56, 0.002, 0.002002002002002002]\n",
            "Node 123: [1.6966449403950643, 0, 0, 0.001, 0.002, 0.3488785254274928, 2.0, 0.064, 0.001, 0.003003003003003003]\n",
            "Node 124: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 3.0, 0.561, 0.002, 0.002002002002002002]\n",
            "Node 125: [1.3831013435214212, 0, 0, 0.001, 0.002, 0.3071840994892294, 2.0, 0.065, 0.001, 0.003003003003003003]\n",
            "Node 126: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 3.0, 0.562, 0.002, 0.002002002002002002]\n",
            "Node 127: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 2.0, 0.066, 0.001, 0.003003003003003003]\n",
            "Node 128: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 3.0, 0.563, 0.002, 0.002002002002002002]\n",
            "Node 129: [0.1869596590434071, 0, 0, 0.001, 0.002, 0.14812347324006217, 2.0, 0.067, 0.001, 0.003003003003003003]\n",
            "Node 130: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.564, 0.002, 0.002002002002002002]\n",
            "Node 131: [1.1133954000056105, 0, 0, 0.001, 0.002, 0.2713191205862758, 2.0, 0.068, 0.001, 0.003003003003003003]\n",
            "Node 132: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.565, 0.002, 0.002002002002002002]\n",
            "Node 133: [0.9468123172458452, 0, 0, 0.001, 0.002, 0.24916722185209858, 2.0, 0.069, 0.001, 0.003003003003003003]\n",
            "Node 134: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 3.0, 0.566, 0.002, 0.002002002002002002]\n",
            "Node 135: [0.8507869813191636, 0, 0, 0.001, 0.002, 0.23639795691761048, 2.0, 0.07, 0.001, 0.003003003003003003]\n",
            "Node 136: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.567, 0.002, 0.002002002002002002]\n",
            "Node 137: [0.32306513518296465, 0, 0, 0.001, 0.002, 0.16622251832111923, 2.0, 0.071, 0.001, 0.003003003003003003]\n",
            "Node 138: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 3.0, 0.568, 0.002, 0.002002002002002002]\n",
            "Node 139: [0.704243968665836, 0, 0, 0.001, 0.002, 0.2169109482567177, 2.0, 0.072, 0.001, 0.003003003003003003]\n",
            "Node 140: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 3.0, 0.569, 0.002, 0.002002002002002002]\n",
            "Node 141: [0.7660341848273532, 0, 0, 0.001, 0.002, 0.22512769264934487, 2.0, 0.073, 0.001, 0.003003003003003003]\n",
            "Node 142: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 3.0, 0.57, 0.002, 0.002002002002002002]\n",
            "Node 143: [1.299601051411263, 0, 0, 0.001, 0.002, 0.2960803908505441, 2.0, 0.074, 0.001, 0.003003003003003003]\n",
            "Node 144: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.571, 0.002, 0.002002002002002002]\n",
            "Node 145: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 2.0, 0.075, 0.001, 0.003003003003003003]\n",
            "Node 146: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.572, 0.002, 0.002002002002002002]\n",
            "Node 147: [0.40907043605642734, 0, 0, 0.001, 0.002, 0.1776593382189651, 2.0, 0.076, 0.001, 0.003003003003003003]\n",
            "Node 148: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 3.0, 0.573, 0.002, 0.002002002002002002]\n",
            "Node 149: [0.9910674720642291, 0, 0, 0.001, 0.002, 0.2550521874306018, 2.0, 0.077, 0.001, 0.003003003003003003]\n",
            "Node 150: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 3.0, 0.574, 0.002, 0.002002002002002002]\n",
            "Node 151: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 2.0, 0.078, 0.001, 0.003003003003003003]\n",
            "Node 152: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.575, 0.002, 0.002002002002002002]\n",
            "Node 153: [1.6640798264721026, 0, 0, 0.001, 0.002, 0.34454807905840545, 2.0, 0.079, 0.001, 0.003003003003003003]\n",
            "Node 154: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 3.0, 0.576, 0.002, 0.002002002002002002]\n",
            "Node 155: [1.2975135441085088, 0, 0, 0.001, 0.002, 0.29580279813457694, 2.0, 0.08, 0.001, 0.003003003003003003]\n",
            "Node 156: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 3.0, 0.577, 0.002, 0.002002002002002002]\n",
            "Node 157: [0.9960774895908384, 0, 0, 0.001, 0.002, 0.2557184099489229, 2.0, 0.081, 0.001, 0.003003003003003003]\n",
            "Node 158: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.578, 0.002, 0.002002002002002002]\n",
            "Node 159: [0.14938452759383591, 0, 0, 0.001, 0.002, 0.14312680435265376, 2.0, 0.082, 0.001, 0.003003003003003003]\n",
            "Node 160: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 3.0, 0.579, 0.002, 0.002002002002002002]\n",
            "Node 161: [0.6157336590290686, 0, 0, 0.001, 0.002, 0.20514101709971128, 2.0, 0.083, 0.001, 0.003003003003003003]\n",
            "Node 162: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 3.0, 0.58, 0.002, 0.002002002002002002]\n",
            "Node 163: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 2.0, 0.084, 0.001, 0.003003003003003003]\n",
            "Node 164: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 3.0, 0.581, 0.002, 0.002002002002002002]\n",
            "Node 165: [-0.012606039099870637, 0, 0, 0.001, 0.002, 0.12158560959360425, 2.0, 0.085, 0.001, 0.003003003003003003]\n",
            "Node 166: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.582, 0.002, 0.002002002002002002]\n",
            "Node 167: [0.5714785042106848, 0, 0, 0.001, 0.002, 0.19925605152120807, 2.0, 0.086, 0.001, 0.003003003003003003]\n",
            "Node 168: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 3.0, 0.583, 0.002, 0.002002002002002002]\n",
            "Node 169: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 2.0, 0.087, 0.001, 0.003003003003003003]\n",
            "Node 170: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 3.0, 0.584, 0.002, 0.002002002002002002]\n",
            "Node 171: [0.020794077744192608, 0, 0, 0.001, 0.002, 0.1260270930490784, 2.0, 0.088, 0.001, 0.003003003003003003]\n",
            "Node 172: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.585, 0.002, 0.002002002002002002]\n",
            "Node 173: [0.6971464438364728, 0, 0, 0.001, 0.002, 0.21596713302242948, 2.0, 0.089, 0.001, 0.003003003003003003]\n",
            "Node 174: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 3.0, 0.586, 0.002, 0.002002002002002002]\n",
            "Node 175: [1.3810138362186668, 0, 0, 0.001, 0.002, 0.30690650677326226, 2.0, 0.09, 0.001, 0.003003003003003003]\n",
            "Node 176: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 3.0, 0.587, 0.002, 0.002002002002002002]\n",
            "Node 177: [0.5840035480272087, 0, 0, 0.001, 0.002, 0.20092160781701088, 2.0, 0.091, 0.001, 0.003003003003003003]\n",
            "Node 178: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 3.0, 0.588, 0.002, 0.002002002002002002]\n",
            "Node 179: [1.1935556804313623, 0, 0, 0.001, 0.002, 0.28197868087941375, 2.0, 0.092, 0.001, 0.003003003003003003]\n",
            "Node 180: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 3.0, 0.589, 0.002, 0.002002002002002002]\n",
            "Node 181: [0.2550123971131859, 0, 0, 0.001, 0.002, 0.1571729957805907, 2.0, 0.093, 0.001, 0.003003003003003003]\n",
            "Node 182: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 3.0, 0.59, 0.002, 0.002002002002002002]\n",
            "Node 183: [1.3956263873379449, 0, 0, 0.001, 0.002, 0.30884965578503215, 2.0, 0.094, 0.001, 0.003003003003003003]\n",
            "Node 184: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 3.0, 0.591, 0.002, 0.002002002002002002]\n",
            "Node 185: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 2.0, 0.095, 0.001, 0.003003003003003003]\n",
            "Node 186: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 3.0, 0.592, 0.002, 0.002002002002002002]\n",
            "Node 187: [1.7145975031987486, 0, 0, 0.001, 0.002, 0.3512658227848101, 2.0, 0.096, 0.001, 0.003003003003003003]\n",
            "Node 188: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 3.0, 0.593, 0.002, 0.002002002002002002]\n",
            "Node 189: [1.6198246716537188, 0, 0, 0.001, 0.002, 0.33866311347990224, 2.0, 0.097, 0.001, 0.003003003003003003]\n",
            "Node 190: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 3.0, 0.594, 0.002, 0.002002002002002002]\n",
            "Node 191: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 2.0, 0.098, 0.001, 0.003003003003003003]\n",
            "Node 192: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.595, 0.002, 0.002002002002002002]\n",
            "Node 193: [1.4916517232646265, 0, 0, 0.001, 0.002, 0.3216189207195203, 2.0, 0.099, 0.001, 0.003003003003003003]\n",
            "Node 194: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 3.0, 0.596, 0.002, 0.002002002002002002]\n",
            "Node 195: [0.8850221010843284, 0, 0, 0.001, 0.002, 0.24095047745947148, 2.0, 0.1, 0.001, 0.003003003003003003]\n",
            "Node 196: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 3.0, 0.597, 0.002, 0.002002002002002002]\n",
            "Node 197: [0.24707986936272097, 0, 0, 0.001, 0.002, 0.15611814345991562, 2.0, 0.101, 0.001, 0.003003003003003003]\n",
            "Node 198: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 3.0, 0.598, 0.002, 0.002002002002002002]\n",
            "Node 199: [0.2917525256416554, 0, 0, 0.001, 0.002, 0.16205862758161224, 2.0, 0.102, 0.001, 0.003003003003003003]\n",
            "Node 200: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 3.0, 0.599, 0.002, 0.002002002002002002]\n",
            "Node 201: [0.557283454551958, 0, 0, 0.001, 0.002, 0.19736842105263158, 2.0, 0.103, 0.001, 0.003003003003003003]\n",
            "Node 202: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 3.0, 0.6, 0.002, 0.002002002002002002]\n",
            "Node 203: [0.6925539277704141, 0, 0, 0.001, 0.002, 0.2153564290473018, 2.0, 0.104, 0.001, 0.003003003003003003]\n",
            "Node 204: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 3.0, 0.601, 0.002, 0.002002002002002002]\n",
            "Node 205: [0.8637295265962379, 0, 0, 0.001, 0.002, 0.23811903175660667, 2.0, 0.105, 0.001, 0.003003003003003003]\n",
            "Node 206: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 3.0, 0.602, 0.002, 0.002002002002002002]\n",
            "Node 207: [0.02496909234970057, 0, 0, 0.001, 0.002, 0.12658227848101267, 2.0, 0.106, 0.001, 0.003003003003003003]\n",
            "Node 208: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 3.0, 0.603, 0.002, 0.002002002002002002]\n",
            "Node 209: [0.5510209326436962, 0, 0, 0.001, 0.002, 0.1965356429047302, 2.0, 0.107, 0.001, 0.003003003003003003]\n",
            "Node 210: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 3.0, 0.604, 0.002, 0.002002002002002002]\n",
            "Node 211: [0.6837863970988476, 0, 0, 0.001, 0.002, 0.21419053964023985, 2.0, 0.108, 0.001, 0.003003003003003003]\n",
            "Node 212: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 3.0, 0.605, 0.002, 0.002002002002002002]\n",
            "Node 213: [0.3456102140527074, 0, 0, 0.001, 0.002, 0.16922051965356427, 2.0, 0.109, 0.001, 0.003003003003003003]\n",
            "Node 214: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 3.0, 0.606, 0.002, 0.002002002002002002]\n",
            "Node 215: [0.8424369521081477, 0, 0, 0.001, 0.002, 0.23528758605374192, 2.0, 0.11, 0.001, 0.003003003003003003]\n",
            "Node 216: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 3.0, 0.607, 0.002, 0.002002002002002002]\n",
            "Node 217: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 2.0, 0.111, 0.001, 0.003003003003003003]\n",
            "Node 218: [-0.9060591646785616, 0, 0, 0.001, 0.001, 0.0027759271596713305, 3.0, 0.608, 0.002, 0.002002002002002002]\n",
            "Node 219: [1.673682360064771, 0, 0, 0.001, 0.002, 0.3458250055518543, 2.0, 0.112, 0.001, 0.003003003003003003]\n",
            "Node 220: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 3.0, 0.609, 0.002, 0.002002002002002002]\n",
            "Node 221: [6.593102069734732, 0, 0, 0.0, 0.125, 1.0, 0.0, 0.001, 0.0, 0.12512512512512514]\n",
            "Node 222: [0.9217622296127977, 0, 0, 0.001, 0.002, 0.245836109260493, 0.0, 0.113, 0.0, 0.003003003003003003]\n",
            "Node 223: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.61, 0.0, 0.002002002002002002]\n",
            "Node 224: [1.682032389275787, 0, 0, 0.001, 0.002, 0.34693537641572286, 0.0, 0.114, 0.0, 0.003003003003003003]\n",
            "Node 225: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.611, 0.0, 0.002002002002002002]\n",
            "Node 226: [0.6533087904786397, 0, 0, 0.001, 0.002, 0.21013768598711965, 0.0, 0.115, 0.0, 0.003003003003003003]\n",
            "Node 227: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.612, 0.0, 0.002002002002002002]\n",
            "Node 228: [1.2344708235653397, 0, 0, 0.001, 0.002, 0.28741949811236955, 0.0, 0.116, 0.0, 0.003003003003003003]\n",
            "Node 229: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.613, 0.0, 0.002002002002002002]\n",
            "Node 230: [0.8023568118952717, 0, 0, 0.001, 0.002, 0.22995780590717296, 0.0, 0.117, 0.0, 0.003003003003003003]\n",
            "Node 231: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.614, 0.0, 0.002002002002002002]\n",
            "Node 232: [1.7672026872281477, 0, 0, 0.001, 0.002, 0.3582611592271819, 0.0, 0.118, 0.0, 0.003003003003003003]\n",
            "Node 233: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.615, 0.0, 0.002002002002002002]\n",
            "Node 234: [0.9305297602843644, 0, 0, 0.001, 0.002, 0.24700199866755496, 0.0, 0.119, 0.0, 0.003003003003003003]\n",
            "Node 235: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.616, 0.0, 0.002002002002002002]\n",
            "Node 236: [0.6683388430584681, 0, 0, 0.001, 0.002, 0.21213635354208304, 0.0, 0.12, 0.0, 0.003003003003003003]\n",
            "Node 237: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.617, 0.0, 0.002002002002002002]\n",
            "Node 238: [1.5830845431252494, 0, 0, 0.001, 0.002, 0.3337774816788807, 0.0, 0.121, 0.0, 0.003003003003003003]\n",
            "Node 239: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.618, 0.0, 0.002002002002002002]\n",
            "Node 240: [0.9209272266916964, 0, 0, 0.001, 0.002, 0.24572507217410614, 0.0, 0.122, 0.0, 0.003003003003003003]\n",
            "Node 241: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.619, 0.0, 0.002002002002002002]\n",
            "Node 242: [1.1584855577450959, 0, 0, 0.001, 0.002, 0.27731512325116586, 0.0, 0.123, 0.0, 0.003003003003003003]\n",
            "Node 243: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.62, 0.0, 0.002002002002002002]\n",
            "Node 244: [0.3431052052894026, 0, 0, 0.001, 0.002, 0.16888740839440372, 0.0, 0.124, 0.0, 0.003003003003003003]\n",
            "Node 245: [-0.8851840916510221, 0, 0, 0.001, 0.001, 0.00555185431934266, 0.0, 0.621, 0.0, 0.002002002002002002]\n",
            "Node 246: [1.0006700056568971, 0, 0, 0.001, 0.002, 0.2563291139240506, 0.0, 0.125, 0.0, 0.003003003003003003]\n",
            "Node 247: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.622, 0.0, 0.002002002002002002]\n",
            "Node 248: [0.9923199764458815, 0, 0, 0.001, 0.002, 0.2552187430601821, 0.0, 0.126, 0.0, 0.003003003003003003]\n",
            "Node 249: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.623, 0.0, 0.002002002002002002]\n",
            "Node 250: [0.5393308917482741, 0, 0, 0.001, 0.002, 0.19498112369531423, 0.0, 0.127, 0.0, 0.003003003003003003]\n",
            "Node 251: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.624, 0.0, 0.002002002002002002]\n",
            "Node 252: [0.157317055344301, 0, 0, 0.001, 0.002, 0.14418165667332888, 0.0, 0.128, 0.0, 0.003003003003003003]\n",
            "Node 253: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.625, 0.0, 0.002002002002002002]\n",
            "Node 254: [0.8679045412017459, 0, 0, 0.001, 0.002, 0.23867421718854095, 0.0, 0.129, 0.0, 0.003003003003003003]\n",
            "Node 255: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.626, 0.0, 0.002002002002002002]\n",
            "Node 256: [0.781899240328283, 0, 0, 0.001, 0.002, 0.22723739729069506, 0.0, 0.13, 0.0, 0.003003003003003003]\n",
            "Node 257: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.627, 0.0, 0.002002002002002002]\n",
            "Node 258: [0.3940403834765989, 0, 0, 0.001, 0.002, 0.17566067066400176, 0.0, 0.131, 0.0, 0.003003003003003003]\n",
            "Node 259: [-0.9110691822051711, 0, 0, 0.001, 0.001, 0.002109704641350211, 0.0, 0.628, 0.0, 0.002002002002002002]\n",
            "Node 260: [1.2553458965928792, 0, 0, 0.001, 0.002, 0.29019542527204084, 0.0, 0.132, 0.0, 0.003003003003003003]\n",
            "Node 261: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.629, 0.0, 0.002002002002002002]\n",
            "Node 262: [0.10972188884151088, 0, 0, 0.001, 0.002, 0.13785254274927825, 0.0, 0.133, 0.0, 0.003003003003003003]\n",
            "Node 263: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.63, 0.0, 0.002002002002002002]\n",
            "Node 264: [0.08007928514240488, 0, 0, 0.001, 0.002, 0.13391072618254496, 0.0, 0.134, 0.0, 0.003003003003003003]\n",
            "Node 265: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.631, 0.0, 0.002002002002002002]\n",
            "Node 266: [-0.041413639877875066, 0, 0, 0.001, 0.002, 0.11775483011325782, 0.0, 0.135, 0.0, 0.003003003003003003]\n",
            "Node 267: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.632, 0.0, 0.002002002002002002]\n",
            "Node 268: [1.4795441809086534, 0, 0, 0.001, 0.002, 0.32000888296691093, 0.0, 0.136, 0.0, 0.003003003003003003]\n",
            "Node 269: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.633, 0.0, 0.002002002002002002]\n",
            "Node 270: [1.0716452539505317, 0, 0, 0.001, 0.002, 0.26576726626693314, 0.0, 0.137, 0.0, 0.003003003003003003]\n",
            "Node 271: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.634, 0.0, 0.002002002002002002]\n",
            "Node 272: [0.06170922087817007, 0, 0, 0.001, 0.002, 0.1314679102820342, 0.0, 0.138, 0.0, 0.003003003003003003]\n",
            "Node 273: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.635, 0.0, 0.002002002002002002]\n",
            "Node 274: [1.15013552853408, 0, 0, 0.001, 0.002, 0.2762047523872973, 0.0, 0.139, 0.0, 0.003003003003003003]\n",
            "Node 275: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.636, 0.0, 0.002002002002002002]\n",
            "Node 276: [1.637777234457403, 0, 0, 0.001, 0.002, 0.3410504108372196, 0.0, 0.14, 0.0, 0.003003003003003003]\n",
            "Node 277: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.637, 0.0, 0.002002002002002002]\n",
            "Node 278: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.141, 0.0, 0.003003003003003003]\n",
            "Node 279: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.638, 0.0, 0.002002002002002002]\n",
            "Node 280: [1.2524233863690237, 0, 0, 0.001, 0.002, 0.28980679546968685, 0.0, 0.142, 0.0, 0.003003003003003003]\n",
            "Node 281: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.639, 0.0, 0.002002002002002002]\n",
            "Node 282: [0.7906667709998496, 0, 0, 0.001, 0.002, 0.22840328669775703, 0.0, 0.143, 0.0, 0.003003003003003003]\n",
            "Node 283: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.64, 0.0, 0.002002002002002002]\n",
            "Node 284: [0.9013046580458093, 0, 0, 0.001, 0.002, 0.2431157006440151, 0.0, 0.144, 0.0, 0.003003003003003003]\n",
            "Node 285: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.641, 0.0, 0.002002002002002002]\n",
            "Node 286: [0.30761758114258553, 0, 0, 0.001, 0.002, 0.16416833222296245, 0.0, 0.145, 0.0, 0.003003003003003003]\n",
            "Node 287: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.642, 0.0, 0.002002002002002002]\n",
            "Node 288: [0.1685895947791723, 0, 0, 0.001, 0.002, 0.1456806573395514, 0.0, 0.146, 0.0, 0.003003003003003003]\n",
            "Node 289: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.643, 0.0, 0.002002002002002002]\n",
            "Node 290: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.147, 0.0, 0.003003003003003003]\n",
            "Node 291: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.644, 0.0, 0.002002002002002002]\n",
            "Node 292: [1.3501187281379086, 0, 0, 0.001, 0.002, 0.3027981345769487, 0.0, 0.148, 0.0, 0.003003003003003003]\n",
            "Node 293: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.645, 0.0, 0.002002002002002002]\n",
            "Node 294: [0.5172033143390822, 0, 0, 0.001, 0.002, 0.19203864090606262, 0.0, 0.149, 0.0, 0.003003003003003003]\n",
            "Node 295: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.646, 0.0, 0.002002002002002002]\n",
            "Node 296: [1.3325836667947755, 0, 0, 0.001, 0.002, 0.30046635576282477, 0.0, 0.15, 0.0, 0.003003003003003003]\n",
            "Node 297: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.647, 0.0, 0.002002002002002002]\n",
            "Node 298: [1.6720123542225676, 0, 0, 0.001, 0.002, 0.34560293137908055, 0.0, 0.151, 0.0, 0.003003003003003003]\n",
            "Node 299: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.648, 0.0, 0.002002002002002002]\n",
            "Node 300: [0.9326172675871185, 0, 0, 0.001, 0.002, 0.2472795913835221, 0.0, 0.152, 0.0, 0.003003003003003003]\n",
            "Node 301: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.649, 0.0, 0.002002002002002002]\n",
            "Node 302: [0.4128279492013846, 0, 0, 0.001, 0.002, 0.17815900510770596, 0.0, 0.153, 0.0, 0.003003003003003003]\n",
            "Node 303: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.65, 0.0, 0.002002002002002002]\n",
            "Node 304: [0.953492340614658, 0, 0, 0.001, 0.002, 0.2500555185431934, 0.0, 0.154, 0.0, 0.003003003003003003]\n",
            "Node 305: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.651, 0.0, 0.002002002002002002]\n",
            "Node 306: [0.3209776278802108, 0, 0, 0.001, 0.002, 0.16594492560515212, 0.0, 0.155, 0.0, 0.003003003003003003]\n",
            "Node 307: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.652, 0.0, 0.002002002002002002]\n",
            "Node 308: [1.1831181439175926, 0, 0, 0.001, 0.002, 0.2805907172995781, 0.0, 0.156, 0.0, 0.003003003003003003]\n",
            "Node 309: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.653, 0.0, 0.002002002002002002]\n",
            "Node 310: [0.3201426249591092, 0, 0, 0.001, 0.002, 0.16583388851876527, 0.0, 0.157, 0.0, 0.003003003003003003]\n",
            "Node 311: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.654, 0.0, 0.002002002002002002]\n",
            "Node 312: [1.0374101341853668, 0, 0, 0.001, 0.002, 0.2612147457250722, 0.0, 0.158, 0.0, 0.003003003003003003]\n",
            "Node 313: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.655, 0.0, 0.002002002002002002]\n",
            "Node 314: [1.7388125879106944, 0, 0, 0.001, 0.002, 0.35448589829002886, 0.0, 0.159, 0.0, 0.003003003003003003]\n",
            "Node 315: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.656, 0.0, 0.002002002002002002]\n",
            "Node 316: [0.11222689760481572, 0, 0, 0.001, 0.002, 0.13818565400843882, 0.0, 0.16, 0.0, 0.003003003003003003]\n",
            "Node 317: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.657, 0.0, 0.002002002002002002]\n",
            "Node 318: [0.7514216337080755, 0, 0, 0.001, 0.002, 0.22318454363757492, 0.0, 0.161, 0.0, 0.003003003003003003]\n",
            "Node 319: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.658, 0.0, 0.002002002002002002]\n",
            "Node 320: [0.5915185743171228, 0, 0, 0.001, 0.002, 0.20192094159449256, 0.0, 0.162, 0.0, 0.003003003003003003]\n",
            "Node 321: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.659, 0.0, 0.002002002002002002]\n",
            "Node 322: [0.8942071332164457, 0, 0, 0.001, 0.002, 0.2421718854097268, 0.0, 0.163, 0.0, 0.003003003003003003]\n",
            "Node 323: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.66, 0.0, 0.002002002002002002]\n",
            "Node 324: [0.4032254156087163, 0, 0, 0.001, 0.002, 0.17688207861425712, 0.0, 0.164, 0.0, 0.003003003003003003]\n",
            "Node 325: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.661, 0.0, 0.002002002002002002]\n",
            "Node 326: [1.1438730066258183, 0, 0, 0.001, 0.002, 0.2753719742393959, 0.0, 0.165, 0.0, 0.003003003003003003]\n",
            "Node 327: [-0.8960391296253427, 0, 0, 0.001, 0.001, 0.004108372196313569, 0.0, 0.662, 0.0, 0.002002002002002002]\n",
            "Node 328: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.166, 0.0, 0.003003003003003003]\n",
            "Node 329: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.663, 0.0, 0.002002002002002002]\n",
            "Node 330: [1.4720291546187394, 0, 0, 0.001, 0.002, 0.31900954918942925, 0.0, 0.167, 0.0, 0.003003003003003003]\n",
            "Node 331: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.664, 0.0, 0.002002002002002002]\n",
            "Node 332: [1.5192068196609785, 0, 0, 0.001, 0.002, 0.3252831445702865, 0.0, 0.168, 0.0, 0.003003003003003003]\n",
            "Node 333: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.665, 0.0, 0.002002002002002002]\n",
            "Node 334: [0.0608742179570685, 0, 0, 0.001, 0.002, 0.13135687319564732, 0.0, 0.169, 0.0, 0.003003003003003003]\n",
            "Node 335: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.666, 0.0, 0.002002002002002002]\n",
            "Node 336: [0.34185270090775033, 0, 0, 0.001, 0.002, 0.16872085276482346, 0.0, 0.17, 0.0, 0.003003003003003003]\n",
            "Node 337: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.667, 0.0, 0.002002002002002002]\n",
            "Node 338: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.171, 0.0, 0.003003003003003003]\n",
            "Node 339: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.668, 0.0, 0.002002002002002002]\n",
            "Node 340: [0.5280583523134026, 0, 0, 0.001, 0.002, 0.19348212302909168, 0.0, 0.172, 0.0, 0.003003003003003003]\n",
            "Node 341: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.669, 0.0, 0.002002002002002002]\n",
            "Node 342: [0.4332855207683734, 0, 0, 0.001, 0.002, 0.1808794137241839, 0.0, 0.173, 0.0, 0.003003003003003003]\n",
            "Node 343: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.67, 0.0, 0.002002002002002002]\n",
            "Node 344: [1.698732447697818, 0, 0, 0.001, 0.002, 0.34915611814345987, 0.0, 0.174, 0.0, 0.003003003003003003]\n",
            "Node 345: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.671, 0.0, 0.002002002002002002]\n",
            "Node 346: [0.5577009560125088, 0, 0, 0.001, 0.002, 0.197423939595825, 0.0, 0.175, 0.0, 0.003003003003003003]\n",
            "Node 347: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.672, 0.0, 0.002002002002002002]\n",
            "Node 348: [1.54634441459678, 0, 0, 0.001, 0.002, 0.3288918498778592, 0.0, 0.176, 0.0, 0.003003003003003003]\n",
            "Node 349: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.673, 0.0, 0.002002002002002002]\n",
            "Node 350: [1.6256696921014298, 0, 0, 0.001, 0.002, 0.3394403730846102, 0.0, 0.177, 0.0, 0.003003003003003003]\n",
            "Node 351: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.674, 0.0, 0.002002002002002002]\n",
            "Node 352: [0.883352095242125, 0, 0, 0.001, 0.002, 0.24072840328669773, 0.0, 0.178, 0.0, 0.003003003003003003]\n",
            "Node 353: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.675, 0.0, 0.002002002002002002]\n",
            "Node 354: [1.5212943269637322, 0, 0, 0.001, 0.002, 0.32556073728625357, 0.0, 0.179, 0.0, 0.003003003003003003]\n",
            "Node 355: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.676, 0.0, 0.002002002002002002]\n",
            "Node 356: [0.8040268177374749, 0, 0, 0.001, 0.002, 0.2301798800799467, 0.0, 0.18, 0.0, 0.003003003003003003]\n",
            "Node 357: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.677, 0.0, 0.002002002002002002]\n",
            "Node 358: [-0.025131082916394373, 0, 0, 0.001, 0.002, 0.11992005329780143, 0.0, 0.181, 0.0, 0.003003003003003003]\n",
            "Node 359: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.678, 0.0, 0.002002002002002002]\n",
            "Node 360: [1.122580432137728, 0, 0, 0.001, 0.002, 0.2725405285365312, 0.0, 0.182, 0.0, 0.003003003003003003]\n",
            "Node 361: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.679, 0.0, 0.002002002002002002]\n",
            "Node 362: [1.7617751682409877, 0, 0, 0.001, 0.002, 0.35753941816566737, 0.0, 0.183, 0.0, 0.003003003003003003]\n",
            "Node 363: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.68, 0.0, 0.002002002002002002]\n",
            "Node 364: [0.5606234662363643, 0, 0, 0.001, 0.002, 0.19781256939817896, 0.0, 0.184, 0.0, 0.003003003003003003]\n",
            "Node 365: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.681, 0.0, 0.002002002002002002]\n",
            "Node 366: [0.2516723854287796, 0, 0, 0.001, 0.002, 0.15672884743504328, 0.0, 0.185, 0.0, 0.003003003003003003]\n",
            "Node 367: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.682, 0.0, 0.002002002002002002]\n",
            "Node 368: [0.3977978966215562, 0, 0, 0.001, 0.002, 0.1761603375527426, 0.0, 0.186, 0.0, 0.003003003003003003]\n",
            "Node 369: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.683, 0.0, 0.002002002002002002]\n",
            "Node 370: [1.7162675090409514, 0, 0, 0.001, 0.002, 0.35148789695758376, 0.0, 0.187, 0.0, 0.003003003003003003]\n",
            "Node 371: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.684, 0.0, 0.002002002002002002]\n",
            "Node 372: [0.16733709039752004, 0, 0, 0.001, 0.002, 0.14551410170997112, 0.0, 0.188, 0.0, 0.003003003003003003]\n",
            "Node 373: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.685, 0.0, 0.002002002002002002]\n",
            "Node 374: [0.5873435597116149, 0, 0, 0.001, 0.002, 0.2013657561625583, 0.0, 0.189, 0.0, 0.003003003003003003]\n",
            "Node 375: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.686, 0.0, 0.002002002002002002]\n",
            "Node 376: [0.44288805436104145, 0, 0, 0.001, 0.002, 0.18215634021763266, 0.0, 0.19, 0.0, 0.003003003003003003]\n",
            "Node 377: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.687, 0.0, 0.002002002002002002]\n",
            "Node 378: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.191, 0.0, 0.003003003003003003]\n",
            "Node 379: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.688, 0.0, 0.002002002002002002]\n",
            "Node 380: [0.5426709034326803, 0, 0, 0.001, 0.002, 0.19542527204086163, 0.0, 0.192, 0.0, 0.003003003003003003]\n",
            "Node 381: [-0.9227592231005933, 0, 0, 0.001, 0.001, 0.0005551854319342662, 0.0, 0.689, 0.0, 0.002002002002002002]\n",
            "Node 382: [0.016201561678133938, 0, 0, 0.001, 0.002, 0.1254163890739507, 0.0, 0.193, 0.0, 0.003003003003003003]\n",
            "Node 383: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.69, 0.0, 0.002002002002002002]\n",
            "Node 384: [0.3973803951610055, 0, 0, 0.001, 0.002, 0.1761048190095492, 0.0, 0.194, 0.0, 0.003003003003003003]\n",
            "Node 385: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.691, 0.0, 0.002002002002002002]\n",
            "Node 386: [1.6945574330923105, 0, 0, 0.001, 0.002, 0.34860093271152565, 0.0, 0.195, 0.0, 0.003003003003003003]\n",
            "Node 387: [-0.88935910625653, 0, 0, 0.001, 0.001, 0.0049966688874083925, 0.0, 0.692, 0.0, 0.002002002002002002]\n",
            "Node 388: [1.3346711740975292, 0, 0, 0.001, 0.002, 0.3007439484787919, 0.0, 0.196, 0.0, 0.003003003003003003]\n",
            "Node 389: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.693, 0.0, 0.002002002002002002]\n",
            "Node 390: [0.5506034311831453, 0, 0, 0.001, 0.002, 0.19648012436153672, 0.0, 0.197, 0.0, 0.003003003003003003]\n",
            "Node 391: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.694, 0.0, 0.002002002002002002]\n",
            "Node 392: [0.13143196479015196, 0, 0, 0.001, 0.002, 0.1407395069953364, 0.0, 0.198, 0.0, 0.003003003003003003]\n",
            "Node 393: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.695, 0.0, 0.002002002002002002]\n",
            "Node 394: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.199, 0.0, 0.003003003003003003]\n",
            "Node 395: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.696, 0.0, 0.002002002002002002]\n",
            "Node 396: [1.6766048702886263, 0, 0, 0.001, 0.002, 0.3462136353542083, 0.0, 0.2, 0.0, 0.003003003003003003]\n",
            "Node 397: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.697, 0.0, 0.002002002002002002]\n",
            "Node 398: [0.8453594623320032, 0, 0, 0.001, 0.002, 0.2356762158560959, 0.0, 0.201, 0.0, 0.003003003003003003]\n",
            "Node 399: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.698, 0.0, 0.002002002002002002]\n",
            "Node 400: [1.5835020445858004, 0, 0, 0.001, 0.002, 0.3338330002220741, 0.0, 0.202, 0.0, 0.003003003003003003]\n",
            "Node 401: [-0.8826790828877173, 0, 0, 0.001, 0.001, 0.005884965578503219, 0.0, 0.699, 0.0, 0.002002002002002002]\n",
            "Node 402: [0.8603895149118317, 0, 0, 0.001, 0.002, 0.23767488341105925, 0.0, 0.203, 0.0, 0.003003003003003003]\n",
            "Node 403: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.7, 0.0, 0.002002002002002002]\n",
            "Node 404: [1.540499394149069, 0, 0, 0.001, 0.002, 0.3281145902731512, 0.0, 0.204, 0.0, 0.003003003003003003]\n",
            "Node 405: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.701, 0.0, 0.002002002002002002]\n",
            "Node 406: [1.7229475324097638, 0, 0, 0.001, 0.002, 0.35237619364867867, 0.0, 0.205, 0.0, 0.003003003003003003]\n",
            "Node 407: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.702, 0.0, 0.002002002002002002]\n",
            "Node 408: [0.5188733201812853, 0, 0, 0.001, 0.002, 0.1922607150788363, 0.0, 0.206, 0.0, 0.003003003003003003]\n",
            "Node 409: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.703, 0.0, 0.002002002002002002]\n",
            "Node 410: [0.4245179900968068, 0, 0, 0.001, 0.002, 0.17971352431712193, 0.0, 0.207, 0.0, 0.003003003003003003]\n",
            "Node 411: [-0.9235942260216948, 0, 0, 0.001, 0.001, 0.0004441483455474128, 0.0, 0.704, 0.0, 0.002002002002002002]\n",
            "Node 412: [-0.015111047863175325, 0, 0, 0.001, 0.002, 0.1212524983344437, 0.0, 0.208, 0.0, 0.003003003003003003]\n",
            "Node 413: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.705, 0.0, 0.002002002002002002]\n",
            "Node 414: [-0.007178520112710406, 0, 0, 0.001, 0.002, 0.12230735065511879, 0.0, 0.209, 0.0, 0.003003003003003003]\n",
            "Node 415: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.706, 0.0, 0.002002002002002002]\n",
            "Node 416: [0.38777786156833716, 0, 0, 0.001, 0.002, 0.17482789251610037, 0.0, 0.21, 0.0, 0.003003003003003003]\n",
            "Node 417: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.707, 0.0, 0.002002002002002002]\n",
            "Node 418: [-0.03556861943016413, 0, 0, 0.001, 0.002, 0.11853208971796576, 0.0, 0.211, 0.0, 0.003003003003003003]\n",
            "Node 419: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.708, 0.0, 0.002002002002002002]\n",
            "Node 420: [1.7279575499363735, 0, 0, 0.001, 0.002, 0.3530424161669998, 0.0, 0.212, 0.0, 0.003003003003003003]\n",
            "Node 421: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.709, 0.0, 0.002002002002002002]\n",
            "Node 422: [0.2600224146397954, 0, 0, 0.001, 0.002, 0.15783921829891182, 0.0, 0.213, 0.0, 0.003003003003003003]\n",
            "Node 423: [-0.907311669060214, 0, 0, 0.001, 0.001, 0.00260937153009105, 0.0, 0.71, 0.0, 0.002002002002002002]\n",
            "Node 424: [0.7764717213411229, 0, 0, 0.001, 0.002, 0.22651565622918055, 0.0, 0.214, 0.0, 0.003003003003003003]\n",
            "Node 425: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.711, 0.0, 0.002002002002002002]\n",
            "Node 426: [1.5914345723362653, 0, 0, 0.001, 0.002, 0.3348878525427492, 0.0, 0.215, 0.0, 0.003003003003003003]\n",
            "Node 427: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.712, 0.0, 0.002002002002002002]\n",
            "Node 428: [0.2537598927315335, 0, 0, 0.001, 0.002, 0.15700644015101042, 0.0, 0.216, 0.0, 0.003003003003003003]\n",
            "Node 429: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.713, 0.0, 0.002002002002002002]\n",
            "Node 430: [0.6144811546474163, 0, 0, 0.001, 0.002, 0.20497446147013101, 0.0, 0.217, 0.0, 0.003003003003003003]\n",
            "Node 431: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.714, 0.0, 0.002002002002002002]\n",
            "Node 432: [1.386858856666378, 0, 0, 0.001, 0.002, 0.30768376637797024, 0.0, 0.218, 0.0, 0.003003003003003003]\n",
            "Node 433: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.715, 0.0, 0.002002002002002002]\n",
            "Node 434: [0.9196747223100439, 0, 0, 0.001, 0.002, 0.24555851654452587, 0.0, 0.219, 0.0, 0.003003003003003003]\n",
            "Node 435: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.716, 0.0, 0.002002002002002002]\n",
            "Node 436: [0.45833560840142057, 0, 0, 0.001, 0.002, 0.18421052631578946, 0.0, 0.22, 0.0, 0.003003003003003003]\n",
            "Node 437: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.717, 0.0, 0.002002002002002002]\n",
            "Node 438: [1.4695241458554344, 0, 0, 0.001, 0.002, 0.31867643793026873, 0.0, 0.221, 0.0, 0.003003003003003003]\n",
            "Node 439: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.718, 0.0, 0.002002002002002002]\n",
            "Node 440: [0.8829345937815742, 0, 0, 0.001, 0.002, 0.2406728847435043, 0.0, 0.222, 0.0, 0.003003003003003003]\n",
            "Node 441: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.719, 0.0, 0.002002002002002002]\n",
            "Node 442: [0.21910727150581794, 0, 0, 0.001, 0.002, 0.152398401065956, 0.0, 0.223, 0.0, 0.003003003003003003]\n",
            "Node 443: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.72, 0.0, 0.002002002002002002]\n",
            "Node 444: [0.9701923990366895, 0, 0, 0.001, 0.002, 0.2522762602709305, 0.0, 0.224, 0.0, 0.003003003003003003]\n",
            "Node 445: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.721, 0.0, 0.002002002002002002]\n",
            "Node 446: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.225, 0.0, 0.003003003003003003]\n",
            "Node 447: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.722, 0.0, 0.002002002002002002]\n",
            "Node 448: [0.7672866892090056, 0, 0, 0.001, 0.002, 0.22529424827892516, 0.0, 0.226, 0.0, 0.003003003003003003]\n",
            "Node 449: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.723, 0.0, 0.002002002002002002]\n",
            "Node 450: [1.6386122373785044, 0, 0, 0.001, 0.002, 0.3411614479236065, 0.0, 0.227, 0.0, 0.003003003003003003]\n",
            "Node 451: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.724, 0.0, 0.002002002002002002]\n",
            "Node 452: [1.4937392305673802, 0, 0, 0.001, 0.002, 0.3218965134354874, 0.0, 0.228, 0.0, 0.003003003003003003]\n",
            "Node 453: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.725, 0.0, 0.002002002002002002]\n",
            "Node 454: [1.09210282551752, 0, 0, 0.001, 0.002, 0.268487674883411, 0.0, 0.229, 0.0, 0.003003003003003003]\n",
            "Node 455: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.726, 0.0, 0.002002002002002002]\n",
            "Node 456: [0.4165854623463416, 0, 0, 0.001, 0.002, 0.1786586719964468, 0.0, 0.23, 0.0, 0.003003003003003003]\n",
            "Node 457: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.727, 0.0, 0.002002002002002002]\n",
            "Node 458: [0.43412052368947485, 0, 0, 0.001, 0.002, 0.1809904508105707, 0.0, 0.231, 0.0, 0.003003003003003003]\n",
            "Node 459: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.728, 0.0, 0.002002002002002002]\n",
            "Node 460: [0.9518223347724546, 0, 0, 0.001, 0.002, 0.24983344437041966, 0.0, 0.232, 0.0, 0.003003003003003003]\n",
            "Node 461: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.729, 0.0, 0.002002002002002002]\n",
            "Node 462: [0.44622806604544774, 0, 0, 0.001, 0.002, 0.18260048856318006, 0.0, 0.233, 0.0, 0.003003003003003003]\n",
            "Node 463: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.73, 0.0, 0.002002002002002002]\n",
            "Node 464: [1.6949749345528615, 0, 0, 0.001, 0.002, 0.34865645125471906, 0.0, 0.234, 0.0, 0.003003003003003003]\n",
            "Node 465: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.731, 0.0, 0.002002002002002002]\n",
            "Node 466: [1.610222138061051, 0, 0, 0.001, 0.002, 0.33738618698645345, 0.0, 0.235, 0.0, 0.003003003003003003]\n",
            "Node 467: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.732, 0.0, 0.002002002002002002]\n",
            "Node 468: [1.0040100173413034, 0, 0, 0.001, 0.002, 0.256773262269598, 0.0, 0.236, 0.0, 0.003003003003003003]\n",
            "Node 469: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.733, 0.0, 0.002002002002002002]\n",
            "Node 470: [0.3080350826031362, 0, 0, 0.001, 0.002, 0.1642238507661559, 0.0, 0.237, 0.0, 0.003003003003003003]\n",
            "Node 471: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.734, 0.0, 0.002002002002002002]\n",
            "Node 472: [3.5207088215414664, 0, 0, 0.0, 0.131, 0.5914390406395736, 0.0, 0.002, 0.0, 0.13113113113113112]\n",
            "Node 473: [0.3898653688710913, 0, 0, 0.001, 0.002, 0.1751054852320675, 0.0, 0.238, 0.0, 0.003003003003003003]\n",
            "Node 474: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.735, 0.0, 0.002002002002002002]\n",
            "Node 475: [1.5317318634775021, 0, 0, 0.001, 0.002, 0.32694870086608924, 0.0, 0.239, 0.0, 0.003003003003003003]\n",
            "Node 476: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.736, 0.0, 0.002002002002002002]\n",
            "Node 477: [0.7397315928126532, 0, 0, 0.001, 0.002, 0.221630024428159, 0.0, 0.24, 0.0, 0.003003003003003003]\n",
            "Node 478: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.737, 0.0, 0.002002002002002002]\n",
            "Node 479: [0.17025960062137543, 0, 0, 0.001, 0.002, 0.1459027315123251, 0.0, 0.241, 0.0, 0.003003003003003003]\n",
            "Node 480: [-0.9035541559152569, 0, 0, 0.001, 0.001, 0.0031090384188318895, 0.0, 0.738, 0.0, 0.002002002002002002]\n",
            "Node 481: [0.5627109735391181, 0, 0, 0.001, 0.002, 0.1980901621141461, 0.0, 0.242, 0.0, 0.003003003003003003]\n",
            "Node 482: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.739, 0.0, 0.002002002002002002]\n",
            "Node 483: [-0.008848525954913531, 0, 0, 0.001, 0.002, 0.1220852764823451, 0.0, 0.243, 0.0, 0.003003003003003003]\n",
            "Node 484: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.74, 0.0, 0.002002002002002002]\n",
            "Node 485: [0.8061143250402291, 0, 0, 0.001, 0.002, 0.23045747279591383, 0.0, 0.244, 0.0, 0.003003003003003003]\n",
            "Node 486: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.741, 0.0, 0.002002002002002002]\n",
            "Node 487: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.245, 0.0, 0.003003003003003003]\n",
            "Node 488: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.742, 0.0, 0.002002002002002002]\n",
            "Node 489: [1.615649657048211, 0, 0, 0.001, 0.002, 0.338107928047968, 0.0, 0.246, 0.0, 0.003003003003003003]\n",
            "Node 490: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.743, 0.0, 0.002002002002002002]\n",
            "Node 491: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.247, 0.0, 0.003003003003003003]\n",
            "Node 492: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.744, 0.0, 0.002002002002002002]\n",
            "Node 493: [0.36940779730410245, 0, 0, 0.001, 0.002, 0.1723850766155896, 0.0, 0.248, 0.0, 0.003003003003003003]\n",
            "Node 494: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.745, 0.0, 0.002002002002002002]\n",
            "Node 495: [0.22536979341407973, 0, 0, 0.001, 0.002, 0.1532311792138574, 0.0, 0.249, 0.0, 0.003003003003003003]\n",
            "Node 496: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.746, 0.0, 0.002002002002002002]\n",
            "Node 497: [1.5713945022298272, 0, 0, 0.001, 0.002, 0.3322229624694648, 0.0, 0.25, 0.0, 0.003003003003003003]\n",
            "Node 498: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.747, 0.0, 0.002002002002002002]\n",
            "Node 499: [1.1434555051652675, 0, 0, 0.001, 0.002, 0.27531645569620256, 0.0, 0.251, 0.0, 0.003003003003003003]\n",
            "Node 500: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.748, 0.0, 0.002002002002002002]\n",
            "Node 501: [1.659487310406044, 0, 0, 0.001, 0.002, 0.3439373750832778, 0.0, 0.252, 0.0, 0.003003003003003003]\n",
            "Node 502: [-0.9139916924290267, 0, 0, 0.001, 0.001, 0.0017210748389962247, 0.0, 0.749, 0.0, 0.002002002002002002]\n",
            "Node 503: [0.8211443776200574, 0, 0, 0.001, 0.002, 0.2324561403508772, 0.0, 0.253, 0.0, 0.003003003003003003]\n",
            "Node 504: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.75, 0.0, 0.002002002002002002]\n",
            "Node 505: [1.7358900776868385, 0, 0, 0.001, 0.002, 0.35409726848767487, 0.0, 0.254, 0.0, 0.003003003003003003]\n",
            "Node 506: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.751, 0.0, 0.002002002002002002]\n",
            "Node 507: [1.161825569429502, 0, 0, 0.001, 0.002, 0.2777592715967133, 0.0, 0.255, 0.0, 0.003003003003003003]\n",
            "Node 508: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.752, 0.0, 0.002002002002002002]\n",
            "Node 509: [1.6290097037858366, 0, 0, 0.001, 0.002, 0.3398845214301577, 0.0, 0.256, 0.0, 0.003003003003003003]\n",
            "Node 510: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.753, 0.0, 0.002002002002002002]\n",
            "Node 511: [1.7642801770042924, 0, 0, 0.001, 0.002, 0.35787252942482795, 0.0, 0.257, 0.0, 0.003003003003003003]\n",
            "Node 512: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.754, 0.0, 0.002002002002002002]\n",
            "Node 513: [0.13226696771125365, 0, 0, 0.001, 0.002, 0.1408505440817233, 0.0, 0.258, 0.0, 0.003003003003003003]\n",
            "Node 514: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.755, 0.0, 0.002002002002002002]\n",
            "Node 515: [0.32056012641966, 0, 0, 0.001, 0.002, 0.16588940706195868, 0.0, 0.259, 0.0, 0.003003003003003003]\n",
            "Node 516: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.756, 0.0, 0.002002002002002002]\n",
            "Node 517: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.26, 0.0, 0.003003003003003003]\n",
            "Node 518: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.757, 0.0, 0.002002002002002002]\n",
            "Node 519: [0.028726605494657675, 0, 0, 0.001, 0.002, 0.1270819453697535, 0.0, 0.261, 0.0, 0.003003003003003003]\n",
            "Node 520: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.758, 0.0, 0.002002002002002002]\n",
            "Node 521: [1.3363411799397324, 0, 0, 0.001, 0.002, 0.30096602265156563, 0.0, 0.262, 0.0, 0.003003003003003003]\n",
            "Node 522: [-0.897291634006995, 0, 0, 0.001, 0.001, 0.003941816566733289, 0.0, 0.759, 0.0, 0.002002002002002002]\n",
            "Node 523: [0.10930438738096017, 0, 0, 0.001, 0.002, 0.1377970242060848, 0.0, 0.263, 0.0, 0.003003003003003003]\n",
            "Node 524: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.76, 0.0, 0.002002002002002002]\n",
            "Node 525: [1.0683052422661252, 0, 0, 0.001, 0.002, 0.26532311792138574, 0.0, 0.264, 0.0, 0.003003003003003003]\n",
            "Node 526: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.761, 0.0, 0.002002002002002002]\n",
            "Node 527: [1.5388293883068656, 0, 0, 0.001, 0.002, 0.32789251610037745, 0.0, 0.265, 0.0, 0.003003003003003003]\n",
            "Node 528: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.762, 0.0, 0.002002002002002002]\n",
            "Node 529: [0.547263419498739, 0, 0, 0.001, 0.002, 0.19603597601598932, 0.0, 0.266, 0.0, 0.003003003003003003]\n",
            "Node 530: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.763, 0.0, 0.002002002002002002]\n",
            "Node 531: [0.7756367184200212, 0, 0, 0.001, 0.002, 0.22640461914279367, 0.0, 0.267, 0.0, 0.003003003003003003]\n",
            "Node 532: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.764, 0.0, 0.002002002002002002]\n",
            "Node 533: [0.3769228235940167, 0, 0, 0.001, 0.002, 0.1733844103930713, 0.0, 0.268, 0.0, 0.003003003003003003]\n",
            "Node 534: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.765, 0.0, 0.002002002002002002]\n",
            "Node 535: [1.378926328915913, 0, 0, 0.001, 0.002, 0.30662891405729514, 0.0, 0.269, 0.0, 0.003003003003003003]\n",
            "Node 536: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.766, 0.0, 0.002002002002002002]\n",
            "Node 537: [0.8219793805411589, 0, 0, 0.001, 0.002, 0.23256717743726402, 0.0, 0.27, 0.0, 0.003003003003003003]\n",
            "Node 538: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.767, 0.0, 0.002002002002002002]\n",
            "Node 539: [0.578993530500599, 0, 0, 0.001, 0.002, 0.20025538529868972, 0.0, 0.271, 0.0, 0.003003003003003003]\n",
            "Node 540: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.768, 0.0, 0.002002002002002002]\n",
            "Node 541: [1.0916853240569693, 0, 0, 0.001, 0.002, 0.2684321563402176, 0.0, 0.272, 0.0, 0.003003003003003003]\n",
            "Node 542: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.769, 0.0, 0.002002002002002002]\n",
            "Node 543: [0.684621400019949, 0, 0, 0.001, 0.002, 0.21430157672662667, 0.0, 0.273, 0.0, 0.003003003003003003]\n",
            "Node 544: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.77, 0.0, 0.002002002002002002]\n",
            "Node 545: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.274, 0.0, 0.003003003003003003]\n",
            "Node 546: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.771, 0.0, 0.002002002002002002]\n",
            "Node 547: [0.5067657778253124, 0, 0, 0.001, 0.002, 0.19065067732622695, 0.0, 0.275, 0.0, 0.003003003003003003]\n",
            "Node 548: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.772, 0.0, 0.002002002002002002]\n",
            "Node 549: [0.3088700855242378, 0, 0, 0.001, 0.002, 0.16433488785254272, 0.0, 0.276, 0.0, 0.003003003003003003]\n",
            "Node 550: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.773, 0.0, 0.002002002002002002]\n",
            "Node 551: [0.9125771974806804, 0, 0, 0.001, 0.002, 0.24461470131023758, 0.0, 0.277, 0.0, 0.003003003003003003]\n",
            "Node 552: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.774, 0.0, 0.002002002002002002]\n",
            "Node 553: [0.599033600607037, 0, 0, 0.001, 0.002, 0.20292027537197424, 0.0, 0.278, 0.0, 0.003003003003003003]\n",
            "Node 554: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.775, 0.0, 0.002002002002002002]\n",
            "Node 555: [1.0340701225009605, 0, 0, 0.001, 0.002, 0.26077059737952474, 0.0, 0.279, 0.0, 0.003003003003003003]\n",
            "Node 556: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.776, 0.0, 0.002002002002002002]\n",
            "Node 557: [0.8662345353595428, 0, 0, 0.001, 0.002, 0.23845214301576725, 0.0, 0.28, 0.0, 0.003003003003003003]\n",
            "Node 558: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.777, 0.0, 0.002002002002002002]\n",
            "Node 559: [1.6912174214079043, 0, 0, 0.001, 0.002, 0.34815678436597824, 0.0, 0.281, 0.0, 0.003003003003003003]\n",
            "Node 560: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.778, 0.0, 0.002002002002002002]\n",
            "Node 561: [0.4516555850326081, 0, 0, 0.001, 0.002, 0.18332222962469466, 0.0, 0.282, 0.0, 0.003003003003003003]\n",
            "Node 562: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.779, 0.0, 0.002002002002002002]\n",
            "Node 563: [1.512109294831615, 0, 0, 0.001, 0.002, 0.3243393293359982, 0.0, 0.283, 0.0, 0.003003003003003003]\n",
            "Node 564: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.78, 0.0, 0.002002002002002002]\n",
            "Node 565: [0.9902324691431273, 0, 0, 0.001, 0.002, 0.25494115034421494, 0.0, 0.284, 0.0, 0.003003003003003003]\n",
            "Node 566: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.781, 0.0, 0.002002002002002002]\n",
            "Node 567: [-0.036821123811816396, 0, 0, 0.001, 0.002, 0.11836553408838552, 0.0, 0.285, 0.0, 0.003003003003003003]\n",
            "Node 568: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.782, 0.0, 0.002002002002002002]\n",
            "Node 569: [0.9021396609669107, 0, 0, 0.001, 0.002, 0.2432267377304019, 0.0, 0.286, 0.0, 0.003003003003003003]\n",
            "Node 570: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.783, 0.0, 0.002002002002002002]\n",
            "Node 571: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.287, 0.0, 0.003003003003003003]\n",
            "Node 572: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.784, 0.0, 0.002002002002002002]\n",
            "Node 573: [1.164330578192807, 0, 0, 0.001, 0.002, 0.2780923828558739, 0.0, 0.288, 0.0, 0.003003003003003003]\n",
            "Node 574: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.785, 0.0, 0.002002002002002002]\n",
            "Node 575: [0.07256425885249053, 0, 0, 0.001, 0.002, 0.13291139240506328, 0.0, 0.289, 0.0, 0.003003003003003003]\n",
            "Node 576: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.786, 0.0, 0.002002002002002002]\n",
            "Node 577: [1.6219121789564732, 0, 0, 0.001, 0.002, 0.3389407061958694, 0.0, 0.29, 0.0, 0.003003003003003003]\n",
            "Node 578: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.787, 0.0, 0.002002002002002002]\n",
            "Node 579: [1.6469622665895203, 0, 0, 0.001, 0.002, 0.34227181878747504, 0.0, 0.291, 0.0, 0.003003003003003003]\n",
            "Node 580: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.788, 0.0, 0.002002002002002002]\n",
            "Node 581: [1.3083685820828297, 0, 0, 0.001, 0.002, 0.297246280257606, 0.0, 0.292, 0.0, 0.003003003003003003]\n",
            "Node 582: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.789, 0.0, 0.002002002002002002]\n",
            "Node 583: [0.989397466222026, 0, 0, 0.001, 0.002, 0.2548301132578281, 0.0, 0.293, 0.0, 0.003003003003003003]\n",
            "Node 584: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.79, 0.0, 0.002002002002002002]\n",
            "Node 585: [0.12266443411858546, 0, 0, 0.001, 0.002, 0.1395736175882745, 0.0, 0.294, 0.0, 0.003003003003003003]\n",
            "Node 586: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.791, 0.0, 0.002002002002002002]\n",
            "Node 587: [1.1776906249304322, 0, 0, 0.001, 0.002, 0.2798689762380635, 0.0, 0.295, 0.0, 0.003003003003003003]\n",
            "Node 588: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.792, 0.0, 0.002002002002002002]\n",
            "Node 589: [-0.020121065389784847, 0, 0, 0.001, 0.002, 0.12058627581612258, 0.0, 0.296, 0.0, 0.003003003003003003]\n",
            "Node 590: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.793, 0.0, 0.002002002002002002]\n",
            "Node 591: [1.0503526794624412, 0, 0, 0.001, 0.002, 0.2629358205640684, 0.0, 0.297, 0.0, 0.003003003003003003]\n",
            "Node 592: [-0.8947866252436902, 0, 0, 0.001, 0.001, 0.004274927825893848, 0.0, 0.794, 0.0, 0.002002002002002002]\n",
            "Node 593: [1.394791384416843, 0, 0, 0.001, 0.002, 0.30873861869864533, 0.0, 0.298, 0.0, 0.003003003003003003]\n",
            "Node 594: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.795, 0.0, 0.002002002002002002]\n",
            "Node 595: [0.3113750942875426, 0, 0, 0.001, 0.002, 0.1646679991117033, 0.0, 0.299, 0.0, 0.003003003003003003]\n",
            "Node 596: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.796, 0.0, 0.002002002002002002]\n",
            "Node 597: [0.9831349443137639, 0, 0, 0.001, 0.002, 0.25399733510992667, 0.0, 0.3, 0.0, 0.003003003003003003]\n",
            "Node 598: [-0.9085641734418665, 0, 0, 0.001, 0.001, 0.0024428159005107698, 0.0, 0.797, 0.0, 0.002002002002002002]\n",
            "Node 599: [0.8591370105301792, 0, 0, 0.001, 0.002, 0.237508327781479, 0.0, 0.301, 0.0, 0.003003003003003003]\n",
            "Node 600: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.798, 0.0, 0.002002002002002002]\n",
            "Node 601: [0.6645813299135112, 0, 0, 0.001, 0.002, 0.2116366866533422, 0.0, 0.302, 0.0, 0.003003003003003003]\n",
            "Node 602: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.799, 0.0, 0.002002002002002002]\n",
            "Node 603: [1.3204761244388026, 0, 0, 0.001, 0.002, 0.2988563180102154, 0.0, 0.303, 0.0, 0.003003003003003003]\n",
            "Node 604: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.8, 0.0, 0.002002002002002002]\n",
            "Node 605: [0.8996346522036058, 0, 0, 0.001, 0.002, 0.24289362647124133, 0.0, 0.304, 0.0, 0.003003003003003003]\n",
            "Node 606: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.801, 0.0, 0.002002002002002002]\n",
            "Node 607: [1.1108903912423058, 0, 0, 0.001, 0.002, 0.2709860093271152, 0.0, 0.305, 0.0, 0.003003003003003003]\n",
            "Node 608: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.802, 0.0, 0.002002002002002002]\n",
            "Node 609: [0.47670567266565556, 0, 0, 0.001, 0.002, 0.18665334221630023, 0.0, 0.306, 0.0, 0.003003003003003003]\n",
            "Node 610: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.803, 0.0, 0.002002002002002002]\n",
            "Node 611: [0.5698084983684817, 0, 0, 0.001, 0.002, 0.19903397734843434, 0.0, 0.307, 0.0, 0.003003003003003003]\n",
            "Node 612: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.804, 0.0, 0.002002002002002002]\n",
            "Node 613: [1.5580344554922023, 0, 0, 0.001, 0.002, 0.33044636908727515, 0.0, 0.308, 0.0, 0.003003003003003003]\n",
            "Node 614: [-0.9260992347849996, 0, 0, 0.001, 0.001, 0.0001110370863868529, 0.0, 0.805, 0.0, 0.002002002002002002]\n",
            "Node 615: [0.740149094273204, 0, 0, 0.001, 0.002, 0.2216855429713524, 0.0, 0.309, 0.0, 0.003003003003003003]\n",
            "Node 616: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.806, 0.0, 0.002002002002002002]\n",
            "Node 617: [0.8077843308824322, 0, 0, 0.001, 0.002, 0.23067954696868756, 0.0, 0.31, 0.0, 0.003003003003003003]\n",
            "Node 618: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.807, 0.0, 0.002002002002002002]\n",
            "Node 619: [0.3886128644894389, 0, 0, 0.001, 0.002, 0.17493892960248722, 0.0, 0.311, 0.0, 0.003003003003003003]\n",
            "Node 620: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.808, 0.0, 0.002002002002002002]\n",
            "Node 621: [0.5664684866840753, 0, 0, 0.001, 0.002, 0.19858982900288696, 0.0, 0.312, 0.0, 0.003003003003003003]\n",
            "Node 622: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.809, 0.0, 0.002002002002002002]\n",
            "Node 623: [0.5718960056712358, 0, 0, 0.001, 0.002, 0.1993115700644015, 0.0, 0.313, 0.0, 0.003003003003003003]\n",
            "Node 624: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.81, 0.0, 0.002002002002002002]\n",
            "Node 625: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.314, 0.0, 0.003003003003003003]\n",
            "Node 626: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.811, 0.0, 0.002002002002002002]\n",
            "Node 627: [1.100452854728536, 0, 0, 0.001, 0.002, 0.2695980457472795, 0.0, 0.315, 0.0, 0.003003003003003003]\n",
            "Node 628: [-0.8822615814271665, 0, 0, 0.001, 0.001, 0.005940484121696646, 0.0, 0.812, 0.0, 0.002002002002002002]\n",
            "Node 629: [1.0336526210404096, 0, 0, 0.001, 0.002, 0.2607150788363313, 0.0, 0.316, 0.0, 0.003003003003003003]\n",
            "Node 630: [-0.915244196810679, 0, 0, 0.001, 0.001, 0.0015545192094159443, 0.0, 0.813, 0.0, 0.002002002002002002]\n",
            "Node 631: [1.573899510993132, 0, 0, 0.001, 0.002, 0.3325560737286254, 0.0, 0.317, 0.0, 0.003003003003003003]\n",
            "Node 632: [-0.9202542143372885, 0, 0, 0.001, 0.001, 0.0008882966910948253, 0.0, 0.814, 0.0, 0.002002002002002002]\n",
            "Node 633: [0.3652327826985945, 0, 0, 0.001, 0.002, 0.17182989118365533, 0.0, 0.318, 0.0, 0.003003003003003003]\n",
            "Node 634: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.815, 0.0, 0.002002002002002002]\n",
            "Node 635: [1.5872595577307578, 0, 0, 0.001, 0.002, 0.334332667110815, 0.0, 0.319, 0.0, 0.003003003003003003]\n",
            "Node 636: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.816, 0.0, 0.002002002002002002]\n",
            "Node 637: [0.34394020821050414, 0, 0, 0.001, 0.002, 0.16899844548079057, 0.0, 0.32, 0.0, 0.003003003003003003]\n",
            "Node 638: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.817, 0.0, 0.002002002002002002]\n",
            "Node 639: [0.4925707281665854, 0, 0, 0.001, 0.002, 0.1887630468576504, 0.0, 0.321, 0.0, 0.003003003003003003]\n",
            "Node 640: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.818, 0.0, 0.002002002002002002]\n",
            "Node 641: [1.1029578634918409, 0, 0, 0.001, 0.002, 0.2699311570064401, 0.0, 0.322, 0.0, 0.003003003003003003]\n",
            "Node 642: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.819, 0.0, 0.002002002002002002]\n",
            "Node 643: [0.5050957719831093, 0, 0, 0.001, 0.002, 0.19042860315345325, 0.0, 0.323, 0.0, 0.003003003003003003]\n",
            "Node 644: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.82, 0.0, 0.002002002002002002]\n",
            "Node 645: [0.039581643468978134, 0, 0, 0.001, 0.002, 0.12852542749278256, 0.0, 0.324, 0.0, 0.003003003003003003]\n",
            "Node 646: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.821, 0.0, 0.002002002002002002]\n",
            "Node 647: [1.221945779748816, 0, 0, 0.001, 0.002, 0.2857539418165667, 0.0, 0.325, 0.0, 0.003003003003003003]\n",
            "Node 648: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.822, 0.0, 0.002002002002002002]\n",
            "Node 649: [0.12391693850023773, 0, 0, 0.001, 0.002, 0.13974017321785473, 0.0, 0.326, 0.0, 0.003003003003003003]\n",
            "Node 650: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.823, 0.0, 0.002002002002002002]\n",
            "Node 651: [1.0111075421706668, 0, 0, 0.001, 0.002, 0.2577170775038863, 0.0, 0.327, 0.0, 0.003003003003003003]\n",
            "Node 652: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.824, 0.0, 0.002002002002002002]\n",
            "Node 653: [0.11974192389472993, 0, 0, 0.001, 0.002, 0.13918498778592048, 0.0, 0.328, 0.0, 0.003003003003003003]\n",
            "Node 654: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.825, 0.0, 0.002002002002002002]\n",
            "Node 655: [1.357633754427823, 0, 0, 0.001, 0.002, 0.3037974683544304, 0.0, 0.329, 0.0, 0.003003003003003003]\n",
            "Node 656: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.826, 0.0, 0.002002002002002002]\n",
            "Node 657: [0.35521274764537564, 0, 0, 0.001, 0.002, 0.1704974461470131, 0.0, 0.33, 0.0, 0.003003003003003003]\n",
            "Node 658: [-0.8839315872693696, 0, 0, 0.001, 0.001, 0.00571840994892294, 0.0, 0.827, 0.0, 0.002002002002002002]\n",
            "Node 659: [0.9785424282477052, 0, 0, 0.001, 0.002, 0.253386631134799, 0.0, 0.331, 0.0, 0.003003003003003003]\n",
            "Node 660: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.828, 0.0, 0.002002002002002002]\n",
            "Node 661: [1.219858272446062, 0, 0, 0.001, 0.002, 0.2854763491005996, 0.0, 0.332, 0.0, 0.003003003003003003]\n",
            "Node 662: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.829, 0.0, 0.002002002002002002]\n",
            "Node 663: [0.9372097836531772, 0, 0, 0.001, 0.002, 0.24789029535864981, 0.0, 0.333, 0.0, 0.003003003003003003]\n",
            "Node 664: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.83, 0.0, 0.002002002002002002]\n",
            "Node 665: [0.45499559671701434, 0, 0, 0.001, 0.002, 0.18376637797024203, 0.0, 0.334, 0.0, 0.003003003003003003]\n",
            "Node 666: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.831, 0.0, 0.002002002002002002]\n",
            "Node 667: [0.23789483723060348, 0, 0, 0.001, 0.002, 0.1548967355096602, 0.0, 0.335, 0.0, 0.003003003003003003]\n",
            "Node 668: [-0.8856015931115729, 0, 0, 0.001, 0.001, 0.005496335776149233, 0.0, 0.832, 0.0, 0.002002002002002002]\n",
            "Node 669: [1.6548947943399852, 0, 0, 0.001, 0.002, 0.3433266711081501, 0.0, 0.336, 0.0, 0.003003003003003003]\n",
            "Node 670: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.833, 0.0, 0.002002002002002002]\n",
            "Node 671: [0.6245011897006353, 0, 0, 0.001, 0.002, 0.20630690650677325, 0.0, 0.337, 0.0, 0.003003003003003003]\n",
            "Node 672: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.834, 0.0, 0.002002002002002002]\n",
            "Node 673: [-0.03264610920630858, 0, 0, 0.001, 0.002, 0.11892071952031977, 0.0, 0.338, 0.0, 0.003003003003003003]\n",
            "Node 674: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.835, 0.0, 0.002002002002002002]\n",
            "Node 675: [1.0098550377890145, 0, 0, 0.001, 0.002, 0.257550521874306, 0.0, 0.339, 0.0, 0.003003003003003003]\n",
            "Node 676: [-0.8830965843482681, 0, 0, 0.001, 0.001, 0.005829447035309794, 0.0, 0.836, 0.0, 0.002002002002002002]\n",
            "Node 677: [1.6528072870372315, 0, 0, 0.001, 0.002, 0.343049078392183, 0.0, 0.34, 0.0, 0.003003003003003003]\n",
            "Node 678: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.837, 0.0, 0.002002002002002002]\n",
            "Node 679: [1.5000017524756424, 0, 0, 0.001, 0.002, 0.3227292915833888, 0.0, 0.341, 0.0, 0.003003003003003003]\n",
            "Node 680: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.838, 0.0, 0.002002002002002002]\n",
            "Node 681: [0.44163554997938903, 0, 0, 0.001, 0.002, 0.18198978458805237, 0.0, 0.342, 0.0, 0.003003003003003003]\n",
            "Node 682: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.839, 0.0, 0.002002002002002002]\n",
            "Node 683: [0.4733656609812493, 0, 0, 0.001, 0.002, 0.18620919387075283, 0.0, 0.343, 0.0, 0.003003003003003003]\n",
            "Node 684: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.84, 0.0, 0.002002002002002002]\n",
            "Node 685: [0.7969292929081118, 0, 0, 0.001, 0.002, 0.22923606484565845, 0.0, 0.344, 0.0, 0.003003003003003003]\n",
            "Node 686: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.841, 0.0, 0.002002002002002002]\n",
            "Node 687: [0.39612789077935306, 0, 0, 0.001, 0.002, 0.1759382633799689, 0.0, 0.345, 0.0, 0.003003003003003003]\n",
            "Node 688: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.842, 0.0, 0.002002002002002002]\n",
            "Node 689: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.346, 0.0, 0.003003003003003003]\n",
            "Node 690: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.843, 0.0, 0.002002002002002002]\n",
            "Node 691: [0.9029746638880124, 0, 0, 0.001, 0.002, 0.2433377748167888, 0.0, 0.347, 0.0, 0.003003003003003003]\n",
            "Node 692: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.844, 0.0, 0.002002002002002002]\n",
            "Node 693: [0.36565028415914536, 0, 0, 0.001, 0.002, 0.17188540972684876, 0.0, 0.348, 0.0, 0.003003003003003003]\n",
            "Node 694: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.845, 0.0, 0.002002002002002002]\n",
            "Node 695: [1.5396643912279675, 0, 0, 0.001, 0.002, 0.3280035531867644, 0.0, 0.349, 0.0, 0.003003003003003003]\n",
            "Node 696: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.846, 0.0, 0.002002002002002002]\n",
            "Node 697: [0.8745845645705587, 0, 0, 0.001, 0.002, 0.2395625138796358, 0.0, 0.35, 0.0, 0.003003003003003003]\n",
            "Node 698: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.847, 0.0, 0.002002002002002002]\n",
            "Node 699: [0.7209440270878679, 0, 0, 0.001, 0.002, 0.21913168998445479, 0.0, 0.351, 0.0, 0.003003003003003003]\n",
            "Node 700: [-0.9190017099556361, 0, 0, 0.001, 0.001, 0.0010548523206751047, 0.0, 0.848, 0.0, 0.002002002002002002]\n",
            "Node 701: [0.007851532467118165, 0, 0, 0.001, 0.002, 0.12430601821008216, 0.0, 0.352, 0.0, 0.003003003003003003]\n",
            "Node 702: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.849, 0.0, 0.002002002002002002]\n",
            "Node 703: [1.3755863172315068, 0, 0, 0.001, 0.002, 0.30618476571174774, 0.0, 0.353, 0.0, 0.003003003003003003]\n",
            "Node 704: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.85, 0.0, 0.002002002002002002]\n",
            "Node 705: [0.45290808941426053, 0, 0, 0.001, 0.002, 0.18348878525427492, 0.0, 0.354, 0.0, 0.003003003003003003]\n",
            "Node 706: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.851, 0.0, 0.002002002002002002]\n",
            "Node 707: [0.7518391351686261, 0, 0, 0.001, 0.002, 0.22324006218076836, 0.0, 0.355, 0.0, 0.003003003003003003]\n",
            "Node 708: [-0.8993791413097489, 0, 0, 0.001, 0.001, 0.0036642238507661553, 0.0, 0.852, 0.0, 0.002002002002002002]\n",
            "Node 709: [1.6369422315363016, 0, 0, 0.001, 0.002, 0.3409393737508328, 0.0, 0.356, 0.0, 0.003003003003003003]\n",
            "Node 710: [-0.9169142026528821, 0, 0, 0.001, 0.001, 0.0013324450366422385, 0.0, 0.853, 0.0, 0.002002002002002002]\n",
            "Node 711: [0.36189277101418826, 0, 0, 0.001, 0.002, 0.17138574283810792, 0.0, 0.357, 0.0, 0.003003003003003003]\n",
            "Node 712: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.854, 0.0, 0.002002002002002002]\n",
            "Node 713: [1.6056296219949924, 0, 0, 0.001, 0.002, 0.33677548301132576, 0.0, 0.358, 0.0, 0.003003003003003003]\n",
            "Node 714: [-0.9206717157978392, 0, 0, 0.001, 0.001, 0.0008327781479013981, 0.0, 0.855, 0.0, 0.002002002002002002]\n",
            "Node 715: [0.9935724808275336, 0, 0, 0.001, 0.002, 0.25538529868976234, 0.0, 0.359, 0.0, 0.003003003003003003]\n",
            "Node 716: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.856, 0.0, 0.002002002002002002]\n",
            "Node 717: [1.4027239121673083, 0, 0, 0.001, 0.002, 0.3097934710193205, 0.0, 0.36, 0.0, 0.003003003003003003]\n",
            "Node 718: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.857, 0.0, 0.002002002002002002]\n",
            "Node 719: [1.4603391137233173, 0, 0, 0.001, 0.002, 0.3174550299800133, 0.0, 0.361, 0.0, 0.003003003003003003]\n",
            "Node 720: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.858, 0.0, 0.002002002002002002]\n",
            "Node 721: [0.7280415519172311, 0, 0, 0.001, 0.002, 0.22007550521874303, 0.0, 0.362, 0.0, 0.003003003003003003]\n",
            "Node 722: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.859, 0.0, 0.002002002002002002]\n",
            "Node 723: [0.2282923036379353, 0, 0, 0.001, 0.002, 0.1536198090162114, 0.0, 0.363, 0.0, 0.003003003003003003]\n",
            "Node 724: [-0.8985441383886473, 0, 0, 0.001, 0.001, 0.003775260937153009, 0.0, 0.86, 0.0, 0.002002002002002002]\n",
            "Node 725: [1.7037424652244277, 0, 0, 0.001, 0.002, 0.34982234066178103, 0.0, 0.364, 0.0, 0.003003003003003003]\n",
            "Node 726: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.861, 0.0, 0.002002002002002002]\n",
            "Node 727: [0.9777074253266038, 0, 0, 0.001, 0.002, 0.25327559404841216, 0.0, 0.365, 0.0, 0.003003003003003003]\n",
            "Node 728: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.862, 0.0, 0.002002002002002002]\n",
            "Node 729: [0.5046782705225585, 0, 0, 0.001, 0.002, 0.19037308461025984, 0.0, 0.366, 0.0, 0.003003003003003003]\n",
            "Node 730: [-0.9198367128767377, 0, 0, 0.001, 0.001, 0.0009438152342882523, 0.0, 0.863, 0.0, 0.002002002002002002]\n",
            "Node 731: [0.925102241297204, 0, 0, 0.001, 0.002, 0.2462802576060404, 0.0, 0.367, 0.0, 0.003003003003003003]\n",
            "Node 732: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.864, 0.0, 0.002002002002002002]\n",
            "Node 733: [1.5751520153747844, 0, 0, 0.001, 0.002, 0.3327226293582056, 0.0, 0.368, 0.0, 0.003003003003003003]\n",
            "Node 734: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.865, 0.0, 0.002002002002002002]\n",
            "Node 735: [3.959085355119796, 0, 0, 0.0, 0.132, 0.6497335109926716, 0.0, 0.003, 0.0, 0.13213213213213212]\n",
            "Node 736: [1.0428376531725267, 0, 0, 0.001, 0.002, 0.2619364867865867, 0.0, 0.369, 0.0, 0.003003003003003003]\n",
            "Node 737: [-0.9123216865868236, 0, 0, 0.001, 0.001, 0.001943149011769931, 0.0, 0.866, 0.0, 0.002002002002002002]\n",
            "Node 738: [0.6457937641887255, 0, 0, 0.001, 0.002, 0.209138352209638, 0.0, 0.37, 0.0, 0.003003003003003003]\n",
            "Node 739: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.867, 0.0, 0.002002002002002002]\n",
            "Node 740: [1.0361576298037143, 0, 0, 0.001, 0.002, 0.2610481900954919, 0.0, 0.371, 0.0, 0.003003003003003003]\n",
            "Node 741: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.868, 0.0, 0.002002002002002002]\n",
            "Node 742: [0.32682264832792174, 0, 0, 0.001, 0.002, 0.16672218520986007, 0.0, 0.372, 0.0, 0.003003003003003003]\n",
            "Node 743: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.869, 0.0, 0.002002002002002002]\n",
            "Node 744: [0.6182386677923735, 0, 0, 0.001, 0.002, 0.20547412835887185, 0.0, 0.373, 0.0, 0.003003003003003003]\n",
            "Node 745: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.87, 0.0, 0.002002002002002002]\n",
            "Node 746: [0.24791487228382253, 0, 0, 0.001, 0.002, 0.15622918054630247, 0.0, 0.374, 0.0, 0.003003003003003003]\n",
            "Node 747: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.871, 0.0, 0.002002002002002002]\n",
            "Node 748: [1.7116749929748927, 0, 0, 0.001, 0.002, 0.3508771929824561, 0.0, 0.375, 0.0, 0.003003003003003003]\n",
            "Node 749: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.872, 0.0, 0.002002002002002002]\n",
            "Node 750: [0.10888688592040931, 0, 0, 0.001, 0.002, 0.1377415056628914, 0.0, 0.376, 0.0, 0.003003003003003003]\n",
            "Node 751: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.873, 0.0, 0.002002002002002002]\n",
            "Node 752: [-0.012188537639319782, 0, 0, 0.001, 0.002, 0.12164112813679767, 0.0, 0.377, 0.0, 0.003003003003003003]\n",
            "Node 753: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.874, 0.0, 0.002002002002002002]\n",
            "Node 754: [0.49507573692989026, 0, 0, 0.001, 0.002, 0.189096158116811, 0.0, 0.378, 0.0, 0.003003003003003003]\n",
            "Node 755: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.875, 0.0, 0.002002002002002002]\n",
            "Node 756: [1.5250518401086897, 0, 0, 0.001, 0.002, 0.32606040417499443, 0.0, 0.379, 0.0, 0.003003003003003003]\n",
            "Node 757: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.876, 0.0, 0.002002002002002002]\n",
            "Node 758: [1.0378276356459175, 0, 0, 0.001, 0.002, 0.26127026426826555, 0.0, 0.38, 0.0, 0.003003003003003003]\n",
            "Node 759: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.877, 0.0, 0.002002002002002002]\n",
            "Node 760: [0.22453479049297817, 0, 0, 0.001, 0.002, 0.15312014212747055, 0.0, 0.381, 0.0, 0.003003003003003003]\n",
            "Node 761: [-0.8922816164803856, 0, 0, 0.001, 0.001, 0.004608039085054407, 0.0, 0.878, 0.0, 0.002002002002002002]\n",
            "Node 762: [0.30260756361597596, 0, 0, 0.001, 0.002, 0.16350210970464132, 0.0, 0.382, 0.0, 0.003003003003003003]\n",
            "Node 763: [-0.9164967011923313, 0, 0, 0.001, 0.001, 0.0013879635798356655, 0.0, 0.879, 0.0, 0.002002002002002002]\n",
            "Node 764: [0.7985992987503149, 0, 0, 0.001, 0.002, 0.22945813901843218, 0.0, 0.383, 0.0, 0.003003003003003003]\n",
            "Node 765: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.88, 0.0, 0.002002002002002002]\n",
            "Node 766: [1.576822021216988, 0, 0, 0.001, 0.002, 0.3329447035309793, 0.0, 0.384, 0.0, 0.003003003003003003]\n",
            "Node 767: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.881, 0.0, 0.002002002002002002]\n",
            "Node 768: [1.7254525411730688, 0, 0, 0.001, 0.002, 0.3527093049078392, 0.0, 0.385, 0.0, 0.003003003003003003]\n",
            "Node 769: [-0.8989616398491982, 0, 0, 0.001, 0.001, 0.003719742393959582, 0.0, 0.882, 0.0, 0.002002002002002002]\n",
            "Node 770: [0.8541269930035699, 0, 0, 0.001, 0.002, 0.23684210526315788, 0.0, 0.386, 0.0, 0.003003003003003003]\n",
            "Node 771: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.883, 0.0, 0.002002002002002002]\n",
            "Node 772: [0.6675038401373667, 0, 0, 0.001, 0.002, 0.2120253164556962, 0.0, 0.387, 0.0, 0.003003003003003003]\n",
            "Node 773: [-0.9068941675996631, 0, 0, 0.001, 0.001, 0.0026648900732844766, 0.0, 0.884, 0.0, 0.002002002002002002]\n",
            "Node 774: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.388, 0.0, 0.003003003003003003]\n",
            "Node 775: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.885, 0.0, 0.002002002002002002]\n",
            "Node 776: [1.281230987147028, 0, 0, 0.001, 0.002, 0.2936375749500333, 0.0, 0.389, 0.0, 0.003003003003003003]\n",
            "Node 777: [-0.9177492055739838, 0, 0, 0.001, 0.001, 0.001221407950255385, 0.0, 0.886, 0.0, 0.002002002002002002]\n",
            "Node 778: [0.7334690709043915, 0, 0, 0.001, 0.002, 0.2207972462802576, 0.0, 0.39, 0.0, 0.003003003003003003]\n",
            "Node 779: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.887, 0.0, 0.002002002002002002]\n",
            "Node 780: [0.8816820893999219, 0, 0, 0.001, 0.002, 0.240506329113924, 0.0, 0.391, 0.0, 0.003003003003003003]\n",
            "Node 781: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.888, 0.0, 0.002002002002002002]\n",
            "Node 782: [1.0812477875431996, 0, 0, 0.001, 0.002, 0.26704419276038194, 0.0, 0.392, 0.0, 0.003003003003003003]\n",
            "Node 783: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.889, 0.0, 0.002002002002002002]\n",
            "Node 784: [0.6829513941777459, 0, 0, 0.001, 0.002, 0.21407950255385297, 0.0, 0.393, 0.0, 0.003003003003003003]\n",
            "Node 785: [-0.9194192114161869, 0, 0, 0.001, 0.001, 0.0009993337774816785, 0.0, 0.89, 0.0, 0.002002002002002002]\n",
            "Node 786: [-0.0034210069677531522, 0, 0, 0.001, 0.002, 0.12280701754385964, 0.0, 0.394, 0.0, 0.003003003003003003]\n",
            "Node 787: [-0.9160791997317806, 0, 0, 0.001, 0.001, 0.0014434821230290917, 0.0, 0.891, 0.0, 0.002002002002002002]\n",
            "Node 788: [1.3709938011654481, 0, 0, 0.001, 0.002, 0.30557406173662005, 0.0, 0.395, 0.0, 0.003003003003003003]\n",
            "Node 789: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.892, 0.0, 0.002002002002002002]\n",
            "Node 790: [1.60437711761334, 0, 0, 0.001, 0.002, 0.33660892738174547, 0.0, 0.396, 0.0, 0.003003003003003003]\n",
            "Node 791: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.893, 0.0, 0.002002002002002002]\n",
            "Node 792: [0.23079731240124013, 0, 0, 0.001, 0.002, 0.15395292027537197, 0.0, 0.397, 0.0, 0.003003003003003003]\n",
            "Node 793: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.894, 0.0, 0.002002002002002002]\n",
            "Node 794: [0.3639802783169421, 0, 0, 0.001, 0.002, 0.17166333555407504, 0.0, 0.398, 0.0, 0.003003003003003003]\n",
            "Node 795: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.895, 0.0, 0.002002002002002002]\n",
            "Node 796: [1.6857899024207441, 0, 0, 0.001, 0.002, 0.3474350433044637, 0.0, 0.399, 0.0, 0.003003003003003003]\n",
            "Node 797: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.896, 0.0, 0.002002002002002002]\n",
            "Node 798: [0.6487162744125811, 0, 0, 0.001, 0.002, 0.209526982011992, 0.0, 0.4, 0.0, 0.003003003003003003]\n",
            "Node 799: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.897, 0.0, 0.002002002002002002]\n",
            "Node 800: [0.015784060217583083, 0, 0, 0.001, 0.002, 0.12536087053075726, 0.0, 0.401, 0.0, 0.003003003003003003]\n",
            "Node 801: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.898, 0.0, 0.002002002002002002]\n",
            "Node 802: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.402, 0.0, 0.003003003003003003]\n",
            "Node 803: [-0.90522416175746, 0, 0, 0.001, 0.001, 0.002886964246058183, 0.0, 0.899, 0.0, 0.002002002002002002]\n",
            "Node 804: [0.2792274818251318, 0, 0, 0.001, 0.002, 0.16039307128580946, 0.0, 0.403, 0.0, 0.003003003003003003]\n",
            "Node 805: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.9, 0.0, 0.002002002002002002]\n",
            "Node 806: [0.31930762203800755, 0, 0, 0.001, 0.002, 0.1657228514323784, 0.0, 0.404, 0.0, 0.003003003003003003]\n",
            "Node 807: [-0.9043891588363585, 0, 0, 0.001, 0.001, 0.0029980013324450373, 0.0, 0.901, 0.0, 0.002002002002002002]\n",
            "Node 808: [1.6123096453638048, 0, 0, 0.001, 0.002, 0.33766377970242056, 0.0, 0.405, 0.0, 0.003003003003003003]\n",
            "Node 809: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.902, 0.0, 0.002002002002002002]\n",
            "Node 810: [0.621161178016229, 0, 0, 0.001, 0.002, 0.20586275816122587, 0.0, 0.406, 0.0, 0.003003003003003003]\n",
            "Node 811: [-0.909399176362968, 0, 0, 0.001, 0.001, 0.002331778814123917, 0.0, 0.903, 0.0, 0.002002002002002002]\n",
            "Node 812: [0.9280247515210596, 0, 0, 0.001, 0.002, 0.24666888740839438, 0.0, 0.407, 0.0, 0.003003003003003003]\n",
            "Node 813: [-0.9081466719813156, 0, 0, 0.001, 0.001, 0.0024983344437041967, 0.0, 0.904, 0.0, 0.002002002002002002]\n",
            "Node 814: [0.9397147924164817, 0, 0, 0.001, 0.002, 0.24822340661781034, 0.0, 0.408, 0.0, 0.003003003003003003]\n",
            "Node 815: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.905, 0.0, 0.002002002002002002]\n",
            "Node 816: [1.2110907417744954, 0, 0, 0.001, 0.002, 0.28431045969353763, 0.0, 0.409, 0.0, 0.003003003003003003]\n",
            "Node 817: [-0.8968741325464442, 0, 0, 0.001, 0.001, 0.003997335109926716, 0.0, 0.906, 0.0, 0.002002002002002002]\n",
            "Node 818: [1.570977000769277, 0, 0, 0.001, 0.002, 0.3321674439262714, 0.0, 0.41, 0.0, 0.003003003003003003]\n",
            "Node 819: [-0.9027191529941553, 0, 0, 0.001, 0.001, 0.003220075505218742, 0.0, 0.907, 0.0, 0.002002002002002002]\n",
            "Node 820: [1.1989831994185225, 0, 0, 0.001, 0.002, 0.28270042194092826, 0.0, 0.411, 0.0, 0.003003003003003003]\n",
            "Node 821: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.908, 0.0, 0.002002002002002002]\n",
            "Node 822: [1.1117253941634075, 0, 0, 0.001, 0.002, 0.27109704641350213, 0.0, 0.412, 0.0, 0.003003003003003003]\n",
            "Node 823: [-0.8935341208620379, 0, 0, 0.001, 0.001, 0.004441483455474129, 0.0, 0.909, 0.0, 0.002002002002002002]\n",
            "Node 824: [0.9121596960201297, 0, 0, 0.001, 0.002, 0.2445591827670442, 0.0, 0.413, 0.0, 0.003003003003003003]\n",
            "Node 825: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.91, 0.0, 0.002002002002002002]\n",
            "Node 826: [1.3104560893855834, 0, 0, 0.001, 0.002, 0.2975238729735732, 0.0, 0.414, 0.0, 0.003003003003003003]\n",
            "Node 827: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.911, 0.0, 0.002002002002002002]\n",
            "Node 828: [1.1985656979579717, 0, 0, 0.001, 0.002, 0.2826449033977348, 0.0, 0.415, 0.0, 0.003003003003003003]\n",
            "Node 829: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.912, 0.0, 0.002002002002002002]\n",
            "Node 830: [0.4929882296271364, 0, 0, 0.001, 0.002, 0.18881856540084388, 0.0, 0.416, 0.0, 0.003003003003003003]\n",
            "Node 831: [-0.8997966427702998, 0, 0, 0.001, 0.001, 0.0036087053075727284, 0.0, 0.913, 0.0, 0.002002002002002002]\n",
            "Node 832: [0.9626773727467753, 0, 0, 0.001, 0.002, 0.2512769264934488, 0.0, 0.417, 0.0, 0.003003003003003003]\n",
            "Node 833: [-0.9135741909684758, 0, 0, 0.001, 0.001, 0.0017765933821896507, 0.0, 0.914, 0.0, 0.002002002002002002]\n",
            "Node 834: [0.6203261750951273, 0, 0, 0.001, 0.002, 0.20575172107483897, 0.0, 0.418, 0.0, 0.003003003003003003]\n",
            "Node 835: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.915, 0.0, 0.002002002002002002]\n",
            "Node 836: [1.364731279257186, 0, 0, 0.001, 0.002, 0.3047412835887186, 0.0, 0.419, 0.0, 0.003003003003003003]\n",
            "Node 837: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.916, 0.0, 0.002002002002002002]\n",
            "Node 838: [0.09552683918278401, 0, 0, 0.001, 0.002, 0.13596491228070176, 0.0, 0.42, 0.0, 0.003003003003003003]\n",
            "Node 839: [-0.9223417216400425, 0, 0, 0.001, 0.001, 0.0006107039751276923, 0.0, 0.917, 0.0, 0.002002002002002002]\n",
            "Node 840: [1.2315483133414842, 0, 0, 0.001, 0.002, 0.2870308683100155, 0.0, 0.421, 0.0, 0.003003003003003003]\n",
            "Node 841: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.918, 0.0, 0.002002002002002002]\n",
            "Node 842: [0.07298176031304138, 0, 0, 0.001, 0.002, 0.13296691094825672, 0.0, 0.422, 0.0, 0.003003003003003003]\n",
            "Node 843: [-0.9102341792840696, 0, 0, 0.001, 0.001, 0.0022207417277370634, 0.0, 0.919, 0.0, 0.002002002002002002]\n",
            "Node 844: [0.7272065489961297, 0, 0, 0.001, 0.002, 0.2199644681323562, 0.0, 0.423, 0.0, 0.003003003003003003]\n",
            "Node 845: [-0.8860190945721236, 0, 0, 0.001, 0.001, 0.005440817232955806, 0.0, 0.92, 0.0, 0.002002002002002002]\n",
            "Node 846: [1.1209104262955247, 0, 0, 0.001, 0.002, 0.2723184543637575, 0.0, 0.424, 0.0, 0.003003003003003003]\n",
            "Node 847: [-0.8885241033354284, 0, 0, 0.001, 0.001, 0.005107705973795247, 0.0, 0.921, 0.0, 0.002002002002002002]\n",
            "Node 848: [1.6895474155657009, 0, 0, 0.001, 0.002, 0.3479347101932045, 0.0, 0.425, 0.0, 0.003003003003003003]\n",
            "Node 849: [-0.8843490887299205, 0, 0, 0.001, 0.001, 0.005662891405729513, 0.0, 0.922, 0.0, 0.002002002002002002]\n",
            "Node 850: [0.5134458011941249, 0, 0, 0.001, 0.002, 0.19153897401732176, 0.0, 0.426, 0.0, 0.003003003003003003]\n",
            "Node 851: [-0.8964566310858934, 0, 0, 0.001, 0.001, 0.004052853653120141, 0.0, 0.923, 0.0, 0.002002002002002002]\n",
            "Node 852: [0.20741723061039577, 0, 0, 0.001, 0.002, 0.15084388185654007, 0.0, 0.427, 0.0, 0.003003003003003003]\n",
            "Node 853: [-0.8847665901904713, 0, 0, 0.001, 0.001, 0.005607372862536085, 0.0, 0.924, 0.0, 0.002002002002002002]\n",
            "Node 854: [1.2833184944497822, 0, 0, 0.001, 0.002, 0.2939151676660004, 0.0, 0.428, 0.0, 0.003003003003003003]\n",
            "Node 855: [-0.9089816749024171, 0, 0, 0.001, 0.001, 0.0023872973573173437, 0.0, 0.925, 0.0, 0.002002002002002002]\n",
            "Node 856: [0.4587531098619716, 0, 0, 0.001, 0.002, 0.18426604485898287, 0.0, 0.429, 0.0, 0.003003003003003003]\n",
            "Node 857: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.926, 0.0, 0.002002002002002002]\n",
            "Node 858: [0.7990168002108655, 0, 0, 0.001, 0.002, 0.22951365756162556, 0.0, 0.43, 0.0, 0.003003003003003003]\n",
            "Node 859: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.927, 0.0, 0.002002002002002002]\n",
            "Node 860: [1.4941567320279312, 0, 0, 0.001, 0.002, 0.3219520319786809, 0.0, 0.431, 0.0, 0.003003003003003003]\n",
            "Node 861: [-0.925264231863898, 0, 0, 0.001, 0.001, 0.0002220741727737062, 0.0, 0.928, 0.0, 0.002002002002002002]\n",
            "Node 862: [1.3914513727324365, 0, 0, 0.001, 0.002, 0.3082944703530979, 0.0, 0.432, 0.0, 0.003003003003003003]\n",
            "Node 863: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.929, 0.0, 0.002002002002002002]\n",
            "Node 864: [1.1676705898772133, 0, 0, 0.001, 0.002, 0.27853653120142124, 0.0, 0.433, 0.0, 0.003003003003003003]\n",
            "Node 865: [-0.8818440799666158, 0, 0, 0.001, 0.001, 0.005996002664890072, 0.0, 0.93, 0.0, 0.002002002002002002]\n",
            "Node 866: [1.2140132519983509, 0, 0, 0.001, 0.002, 0.2846990894958916, 0.0, 0.434, 0.0, 0.003003003003003003]\n",
            "Node 867: [-0.9265167362455504, 0, 0, 0.001, 0.001, 5.551854319342665e-05, 0.0, 0.931, 0.0, 0.002002002002002002]\n",
            "Node 868: [0.04876667560109562, 0, 0, 0.001, 0.002, 0.12974683544303797, 0.0, 0.435, 0.0, 0.003003003003003003]\n",
            "Node 869: [-0.8868540974932252, 0, 0, 0.001, 0.001, 0.005329780146568954, 0.0, 0.932, 0.0, 0.002002002002002002]\n",
            "Node 870: [1.5041767670811501, 0, 0, 0.001, 0.002, 0.3232844770153231, 0.0, 0.436, 0.0, 0.003003003003003003]\n",
            "Node 871: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.933, 0.0, 0.002002002002002002]\n",
            "Node 872: [1.6248346891803285, 0, 0, 0.001, 0.002, 0.33932933599822335, 0.0, 0.437, 0.0, 0.003003003003003003]\n",
            "Node 873: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.934, 0.0, 0.002002002002002002]\n",
            "Node 874: [0.8537094915430191, 0, 0, 0.001, 0.002, 0.2367865867199645, 0.0, 0.438, 0.0, 0.003003003003003003]\n",
            "Node 875: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.935, 0.0, 0.002002002002002002]\n",
            "Node 876: [0.8729145587283552, 0, 0, 0.001, 0.002, 0.23934043970686206, 0.0, 0.439, 0.0, 0.003003003003003003]\n",
            "Node 877: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.936, 0.0, 0.002002002002002002]\n",
            "Node 878: [1.5772395226775384, 0, 0, 0.001, 0.002, 0.33300022207417274, 0.0, 0.44, 0.0, 0.003003003003003003]\n",
            "Node 879: [-0.9039716573758076, 0, 0, 0.001, 0.001, 0.0030535198756384634, 0.0, 0.937, 0.0, 0.002002002002002002]\n",
            "Node 880: [1.1626605723506038, 0, 0, 0.001, 0.002, 0.27787030868310014, 0.0, 0.441, 0.0, 0.003003003003003003]\n",
            "Node 881: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.938, 0.0, 0.002002002002002002]\n",
            "Node 882: [0.5443409092748834, 0, 0, 0.001, 0.002, 0.19564734621363536, 0.0, 0.442, 0.0, 0.003003003003003003]\n",
            "Node 883: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.939, 0.0, 0.002002002002002002]\n",
            "Node 884: [1.5567819511105498, 0, 0, 0.001, 0.002, 0.33027981345769486, 0.0, 0.443, 0.0, 0.003003003003003003]\n",
            "Node 885: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.94, 0.0, 0.002002002002002002]\n",
            "Node 886: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.444, 0.0, 0.003003003003003003]\n",
            "Node 887: [-0.8956216281647918, 0, 0, 0.001, 0.001, 0.0041638907395069955, 0.0, 0.941, 0.0, 0.002002002002002002]\n",
            "Node 888: [0.17693962399018806, 0, 0, 0.001, 0.002, 0.14679102820341994, 0.0, 0.445, 0.0, 0.003003003003003003]\n",
            "Node 889: [-0.9256817333244488, 0, 0, 0.001, 0.001, 0.00016655562958027914, 0.0, 0.942, 0.0, 0.002002002002002002]\n",
            "Node 890: [0.555195947249204, 0, 0, 0.001, 0.002, 0.19709082833666441, 0.0, 0.446, 0.0, 0.003003003003003003]\n",
            "Node 891: [-0.9185842084950853, 0, 0, 0.001, 0.001, 0.001110370863868532, 0.0, 0.943, 0.0, 0.002002002002002002]\n",
            "Node 892: [0.8169693630145495, 0, 0, 0.001, 0.002, 0.23190095491894291, 0.0, 0.447, 0.0, 0.003003003003003003]\n",
            "Node 893: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.944, 0.0, 0.002002002002002002]\n",
            "Node 894: [0.15564704950209785, 0, 0, 0.001, 0.002, 0.14395958250055516, 0.0, 0.448, 0.0, 0.003003003003003003]\n",
            "Node 895: [-0.9098166778235187, 0, 0, 0.001, 0.001, 0.0022762602709304903, 0.0, 0.945, 0.0, 0.002002002002002002]\n",
            "Node 896: [1.034905125422062, 0, 0, 0.001, 0.002, 0.2608816344659116, 0.0, 0.449, 0.0, 0.003003003003003003]\n",
            "Node 897: [-0.8906116106381825, 0, 0, 0.001, 0.001, 0.0048301132578281135, 0.0, 0.946, 0.0, 0.002002002002002002]\n",
            "Node 898: [0.8921196259136916, 0, 0, 0.001, 0.002, 0.24189429269375967, 0.0, 0.45, 0.0, 0.003003003003003003]\n",
            "Node 899: [-0.9156616982712298, 0, 0, 0.001, 0.001, 0.001499000666222518, 0.0, 0.947, 0.0, 0.002002002002002002]\n",
            "Node 900: [1.0319826151982063, 0, 0, 0.001, 0.002, 0.2604930046635576, 0.0, 0.451, 0.0, 0.003003003003003003]\n",
            "Node 901: [-0.9077291705207647, 0, 0, 0.001, 0.001, 0.002553852986897624, 0.0, 0.948, 0.0, 0.002002002002002002]\n",
            "Node 902: [0.05795170773321296, 0, 0, 0.001, 0.002, 0.13096824339329335, 0.0, 0.452, 0.0, 0.003003003003003003]\n",
            "Node 903: [-0.9023016515336044, 0, 0, 0.001, 0.001, 0.0032755940484121694, 0.0, 0.949, 0.0, 0.002002002002002002]\n",
            "Node 904: [1.1835356453781434, 0, 0, 0.001, 0.002, 0.2806462358427715, 0.0, 0.453, 0.0, 0.003003003003003003]\n",
            "Node 905: [-0.8876891004143269, 0, 0, 0.001, 0.001, 0.005218743060182099, 0.0, 0.95, 0.0, 0.002002002002002002]\n",
            "Node 906: [1.3530412383617638, 0, 0, 0.001, 0.002, 0.30318676437930264, 0.0, 0.454, 0.0, 0.003003003003003003]\n",
            "Node 907: [-0.9006316456914013, 0, 0, 0.001, 0.001, 0.003497668221185876, 0.0, 0.951, 0.0, 0.002002002002002002]\n",
            "Node 908: [-0.03306361066685929, 0, 0, 0.001, 0.002, 0.11886520097712634, 0.0, 0.455, 0.0, 0.003003003003003003]\n",
            "Node 909: [-0.8926991179409363, 0, 0, 0.001, 0.001, 0.0045525205418609814, 0.0, 0.952, 0.0, 0.002002002002002002]\n",
            "Node 910: [0.9188397193889423, 0, 0, 0.001, 0.002, 0.245447479458139, 0.0, 0.456, 0.0, 0.003003003003003003]\n",
            "Node 911: [-0.92108921725839, 0, 0, 0.001, 0.001, 0.0007772596047079719, 0.0, 0.953, 0.0, 0.002002002002002002]\n",
            "Node 912: [1.5087692831472088, 0, 0, 0.001, 0.002, 0.32389518099045084, 0.0, 0.457, 0.0, 0.003003003003003003]\n",
            "Node 913: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.954, 0.0, 0.002002002002002002]\n",
            "Node 914: [1.7605226638593352, 0, 0, 0.001, 0.002, 0.357372862536087, 0.0, 0.458, 0.0, 0.003003003003003003]\n",
            "Node 915: [-0.9014666486125029, 0, 0, 0.001, 0.001, 0.0033866311347990215, 0.0, 0.955, 0.0, 0.002002002002002002]\n",
            "Node 916: [0.11514940782867125, 0, 0, 0.001, 0.002, 0.1385742838107928, 0.0, 0.459, 0.0, 0.003003003003003003]\n",
            "Node 917: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.956, 0.0, 0.002002002002002002]\n",
            "Node 918: [0.9726974077999941, 0, 0, 0.001, 0.002, 0.252609371530091, 0.0, 0.46, 0.0, 0.003003003003003003]\n",
            "Node 919: [-0.9244292289427964, 0, 0, 0.001, 0.001, 0.0003331112591605595, 0.0, 0.957, 0.0, 0.002002002002002002]\n",
            "Node 920: [0.3869428586472357, 0, 0, 0.001, 0.002, 0.17471685542971352, 0.0, 0.461, 0.0, 0.003003003003003003]\n",
            "Node 921: [-0.923176724561144, 0, 0, 0.001, 0.001, 0.000499666888740839, 0.0, 0.958, 0.0, 0.002002002002002002]\n",
            "Node 922: [0.7915017739209513, 0, 0, 0.001, 0.002, 0.22851432378414388, 0.0, 0.462, 0.0, 0.003003003003003003]\n",
            "Node 923: [-0.8864365960326744, 0, 0, 0.001, 0.001, 0.005385298689762381, 0.0, 0.959, 0.0, 0.002002002002002002]\n",
            "Node 924: [1.0065150261046083, 0, 0, 0.001, 0.002, 0.25710637352875854, 0.0, 0.463, 0.0, 0.003003003003003003]\n",
            "Node 925: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.96, 0.0, 0.002002002002002002]\n",
            "Node 926: [1.4586691078811138, 0, 0, 0.001, 0.002, 0.3172329558072396, 0.0, 0.464, 0.0, 0.003003003003003003]\n",
            "Node 927: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.961, 0.0, 0.002002002002002002]\n",
            "Node 928: [1.7546776434116242, 0, 0, 0.001, 0.002, 0.35659560293137904, 0.0, 0.465, 0.0, 0.003003003003003003]\n",
            "Node 929: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.962, 0.0, 0.002002002002002002]\n",
            "Node 930: [0.750169129326423, 0, 0, 0.001, 0.002, 0.22301798800799466, 0.0, 0.466, 0.0, 0.003003003003003003]\n",
            "Node 931: [-0.9148266953501282, 0, 0, 0.001, 0.001, 0.0016100377526093712, 0.0, 0.963, 0.0, 0.002002002002002002]\n",
            "Node 932: [0.4842206989555698, 0, 0, 0.001, 0.002, 0.18765267599378194, 0.0, 0.467, 0.0, 0.003003003003003003]\n",
            "Node 933: [-0.903136654454706, 0, 0, 0.001, 0.001, 0.003164556962025317, 0.0, 0.964, 0.0, 0.002002002002002002]\n",
            "Node 934: [0.1548120465809963, 0, 0, 0.001, 0.002, 0.1438485454141683, 0.0, 0.468, 0.0, 0.003003003003003003]\n",
            "Node 935: [-0.883514085808819, 0, 0, 0.001, 0.001, 0.005773928492116367, 0.0, 0.965, 0.0, 0.002002002002002002]\n",
            "Node 936: [0.8854396025448791, 0, 0, 0.001, 0.002, 0.24100599600266487, 0.0, 0.469, 0.0, 0.003003003003003003]\n",
            "Node 937: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.966, 0.0, 0.002002002002002002]\n",
            "Node 938: [0.7180215168640124, 0, 0, 0.001, 0.002, 0.21874306018210082, 0.0, 0.47, 0.0, 0.003003003003003003]\n",
            "Node 939: [-0.9119041851262727, 0, 0, 0.001, 0.001, 0.0019986675549633574, 0.0, 0.967, 0.0, 0.002002002002002002]\n",
            "Node 940: [0.24165235037556057, 0, 0, 0.001, 0.002, 0.15539640239840105, 0.0, 0.471, 0.0, 0.003003003003003003]\n",
            "Node 941: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.968, 0.0, 0.002002002002002002]\n",
            "Node 942: [1.173933111785475, 0, 0, 0.001, 0.002, 0.27936930934932264, 0.0, 0.472, 0.0, 0.003003003003003003]\n",
            "Node 943: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.969, 0.0, 0.002002002002002002]\n",
            "Node 944: [0.9488998245485991, 0, 0, 0.001, 0.002, 0.24944481456806572, 0.0, 0.473, 0.0, 0.003003003003003003]\n",
            "Node 945: [-0.9215067187189409, 0, 0, 0.001, 0.001, 0.0007217410615145457, 0.0, 0.97, 0.0, 0.002002002002002002]\n",
            "Node 946: [0.8190568703173033, 0, 0, 0.001, 0.002, 0.23217854763491003, 0.0, 0.474, 0.0, 0.003003003003003003]\n",
            "Node 947: [-0.9248467304033471, 0, 0, 0.001, 0.001, 0.00027759271596713243, 0.0, 0.971, 0.0, 0.002002002002002002]\n",
            "Node 948: [0.7898317680787482, 0, 0, 0.001, 0.002, 0.22829224961137018, 0.0, 0.475, 0.0, 0.003003003003003003]\n",
            "Node 949: [-0.8910291120987331, 0, 0, 0.001, 0.001, 0.0047745947146346866, 0.0, 0.972, 0.0, 0.002002002002002002]\n",
            "Node 950: [0.8649820309778903, 0, 0, 0.001, 0.002, 0.23828558738618696, 0.0, 0.476, 0.0, 0.003003003003003003]\n",
            "Node 951: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.973, 0.0, 0.002002002002002002]\n",
            "Node 952: [0.2879950124966983, 0, 0, 0.001, 0.002, 0.16155896069287137, 0.0, 0.477, 0.0, 0.003003003003003003]\n",
            "Node 953: [-0.9064766661391125, 0, 0, 0.001, 0.001, 0.0027204086164779036, 0.0, 0.974, 0.0, 0.002002002002002002]\n",
            "Node 954: [1.6394472402996065, 0, 0, 0.001, 0.002, 0.3412724850099933, 0.0, 0.478, 0.0, 0.003003003003003003]\n",
            "Node 955: [-0.9269342377061011, 0, 0, 0.001, 0.001, 0.0, 0.0, 0.975, 0.0, 0.002002002002002002]\n",
            "Node 956: [1.2791434798442742, 0, 0, 0.001, 0.002, 0.2933599822340662, 0.0, 0.479, 0.0, 0.003003003003003003]\n",
            "Node 957: [-0.9048066602969091, 0, 0, 0.001, 0.001, 0.00294248278925161, 0.0, 0.976, 0.0, 0.002002002002002002]\n",
            "Node 958: [0.7305465606805359, 0, 0, 0.001, 0.002, 0.2204086164779036, 0.0, 0.48, 0.0, 0.003003003003003003]\n",
            "Node 959: [-0.9018841500730538, 0, 0, 0.001, 0.001, 0.0033311125916055955, 0.0, 0.977, 0.0, 0.002002002002002002]\n",
            "Node 960: [1.3417686989268927, 0, 0, 0.001, 0.002, 0.3016877637130802, 0.0, 0.481, 0.0, 0.003003003003003003]\n",
            "Node 961: [-0.8931166194014871, 0, 0, 0.001, 0.001, 0.0044970019986675545, 0.0, 0.978, 0.0, 0.002002002002002002]\n",
            "Node 962: [1.4261039939581521, 0, 0, 0.001, 0.002, 0.3129025094381523, 0.0, 0.482, 0.0, 0.003003003003003003]\n",
            "Node 963: [-0.8977091354675458, 0, 0, 0.001, 0.001, 0.0038862980235398617, 0.0, 0.979, 0.0, 0.002002002002002002]\n",
            "Node 964: [1.0420026502514255, 0, 0, 0.001, 0.002, 0.26182544970019983, 0.0, 0.483, 0.0, 0.003003003003003003]\n",
            "Node 965: [-0.8881066018748777, 0, 0, 0.001, 0.001, 0.0051632245169886725, 0.0, 0.98, 0.0, 0.002002002002002002]\n",
            "Node 966: [1.4945742334884817, 0, 0, 0.001, 0.002, 0.32200755052187424, 0.0, 0.484, 0.0, 0.003003003003003003]\n",
            "Node 967: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.981, 0.0, 0.002002002002002002]\n",
            "Node 968: [1.1968956921157687, 0, 0, 0.001, 0.002, 0.2824228292249611, 0.0, 0.485, 0.0, 0.003003003003003003]\n",
            "Node 969: [-0.9181667070345345, 0, 0, 0.001, 0.001, 0.0011658894070619588, 0.0, 0.982, 0.0, 0.002002002002002002]\n",
            "Node 970: [0.6420362510437685, 0, 0, 0.001, 0.002, 0.2086386853208972, 0.0, 0.486, 0.0, 0.003003003003003003]\n",
            "Node 971: [-0.891446613559284, 0, 0, 0.001, 0.001, 0.00471907617144126, 0.0, 0.983, 0.0, 0.002002002002002002]\n",
            "Node 972: [1.0929378284386218, 0, 0, 0.001, 0.002, 0.2685987119697979, 0.0, 0.487, 0.0, 0.003003003003003003]\n",
            "Node 973: [-0.8901941091776316, 0, 0, 0.001, 0.001, 0.00488563180102154, 0.0, 0.984, 0.0, 0.002002002002002002]\n",
            "Node 974: [0.5777410261189468, 0, 0, 0.001, 0.002, 0.20008882966910949, 0.0, 0.488, 0.0, 0.003003003003003003]\n",
            "Node 975: [-0.9240117274822456, 0, 0, 0.001, 0.001, 0.00038862980235398575, 0.0, 0.985, 0.0, 0.002002002002002002]\n",
            "Node 976: [0.9096546872568249, 0, 0, 0.001, 0.002, 0.2442260715078836, 0.0, 0.489, 0.0, 0.003003003003003003]\n",
            "Node 977: [-0.9219242201794916, 0, 0, 0.001, 0.001, 0.0006662225183211194, 0.0, 0.986, 0.0, 0.002002002002002002]\n",
            "Node 978: [1.2570159024350824, 0, 0, 0.001, 0.002, 0.29041749944481454, 0.0, 0.49, 0.0, 0.003003003003003003]\n",
            "Node 979: [-0.9144091938895773, 0, 0, 0.001, 0.001, 0.0016655562958027975, 0.0, 0.987, 0.0, 0.002002002002002002]\n",
            "Node 980: [1.5501019277417374, 0, 0, 0.001, 0.002, 0.32939151676660006, 0.0, 0.491, 0.0, 0.003003003003003003]\n",
            "Node 981: [-0.9002141442308504, 0, 0, 0.001, 0.001, 0.003553186764379302, 0.0, 0.988, 0.0, 0.002002002002002002]\n",
            "Node 982: [1.3730813084682019, 0, 0, 0.001, 0.002, 0.30585165445258716, 0.0, 0.492, 0.0, 0.003003003003003003]\n",
            "Node 983: [-0.9056416632180109, 0, 0, 0.001, 0.001, 0.002831445702864757, 0.0, 0.989, 0.0, 0.002002002002002002]\n",
            "Node 984: [1.1672530884166625, 0, 0, 0.001, 0.002, 0.27848101265822783, 0.0, 0.493, 0.0, 0.003003003003003003]\n",
            "Node 985: [-0.8952041267042411, 0, 0, 0.001, 0.001, 0.0042194092827004225, 0.0, 0.99, 0.0, 0.002002002002002002]\n",
            "Node 986: [0.7238665373117235, 0, 0, 0.001, 0.002, 0.2195203197868088, 0.0, 0.494, 0.0, 0.003003003003003003]\n",
            "Node 987: [-0.8943691237831394, 0, 0, 0.001, 0.001, 0.004330446369087275, 0.0, 0.991, 0.0, 0.002002002002002002]\n",
            "Node 988: [0.6583188080052493, 0, 0, 0.001, 0.002, 0.2108039085054408, 0.0, 0.495, 0.0, 0.003003003003003003]\n",
            "Node 989: [-0.9131566895079251, 0, 0, 0.001, 0.001, 0.0018321119253830779, 0.0, 0.992, 0.0, 0.002002002002002002]\n",
            "Node 990: [1.5033417641600486, 0, 0, 0.001, 0.002, 0.32317343992893627, 0.0, 0.496, 0.0, 0.003003003003003003]\n",
            "Node 991: [-0.8918641150198348, 0, 0, 0.001, 0.001, 0.0046635576282478336, 0.0, 0.993, 0.0, 0.002002002002002002]\n",
            "Node 992: [0.7493341264053216, 0, 0, 0.001, 0.002, 0.2229069509216078, 0.0, 0.497, 0.0, 0.003003003003003003]\n",
            "Node 993: [-0.8897766077170808, 0, 0, 0.001, 0.001, 0.004941150344214967, 0.0, 0.994, 0.0, 0.002002002002002002]\n",
            "Node 994: [0.30427756945817913, 0, 0, 0.001, 0.002, 0.16372418387741505, 0.0, 0.498, 0.0, 0.003003003003003003]\n",
            "Node 995: [-0.9106516807446202, 0, 0, 0.001, 0.001, 0.002165223184543637, 0.0, 0.995, 0.0, 0.002002002002002002]\n",
            "Node 996: [0.9313647632054661, 0, 0, 0.001, 0.002, 0.2471130357539418, 0.0, 0.499, 0.0, 0.003003003003003003]\n",
            "Node 997: [-0.8889416047959792, 0, 0, 0.001, 0.001, 0.00505218743060182, 0.0, 0.996, 0.0, 0.002002002002002002]\n",
            "Node 998: [1.2887460134369424, 0, 0, 0.001, 0.002, 0.29463690872751497, 0.0, 0.5, 0.0, 0.003003003003003003]\n",
            "Node 999: [-0.9010491471519522, 0, 0, 0.001, 0.001, 0.003442149677992449, 0.0, 0.998, 0.0, 0.002002002002002002]\n",
            "Using device: cpu\n",
            "Starting hyperparameter tuning...\n",
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7797, Time Loss: 0.9020, SLA Loss: 0.7862, Priority Loss: 0.4639\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7514, Time Loss: 0.9020, SLA Loss: 0.7014, Priority Loss: 0.4621\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6987, Time Loss: 0.9020, SLA Loss: 0.5396, Priority Loss: 0.4587\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6037, Time Loss: 0.9020, SLA Loss: 0.2490, Priority Loss: 0.4487\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5479, Time Loss: 0.9020, SLA Loss: 0.1004, Priority Loss: 0.4252\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:04:31,871] Trial 0 finished with value: -0.8891171216964722 and parameters: {'heads': 4, 'base_hidden_dim': 64, 'num_gnn_layers': 2, 'tier1_lr': 0.00018168315158648466, 'tier1_n_steps': 2048, 'tier1_batch_size': 64, 'tier2_lr': 0.00011892543057679326, 'tier2_n_steps': 2048, 'tier2_batch_size': 128}. Best is trial 0 with value: -0.8891171216964722.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7385, Time Loss: 0.9021, SLA Loss: 0.6418, Priority Loss: 0.4746\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7134, Time Loss: 0.9020, SLA Loss: 0.5691, Priority Loss: 0.4724\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6759, Time Loss: 0.9021, SLA Loss: 0.4570, Priority Loss: 0.4699\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6010, Time Loss: 0.9020, SLA Loss: 0.2325, Priority Loss: 0.4597\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5489, Time Loss: 0.9024, SLA Loss: 0.0983, Priority Loss: 0.4301\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 35])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 35])\n",
            "Q shape: torch.Size([1000, 5, 7])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 35])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 35])\n",
            "Q shape: torch.Size([1000, 5, 7])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 35])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:05:16,059] Trial 1 finished with value: -0.7999642193317413 and parameters: {'heads': 5, 'base_hidden_dim': 32, 'num_gnn_layers': 1, 'tier1_lr': 1.9214154495671464e-05, 'tier1_n_steps': 4096, 'tier1_batch_size': 32, 'tier2_lr': 6.252175503200479e-05, 'tier2_n_steps': 2048, 'tier2_batch_size': 32}. Best is trial 1 with value: -0.7999642193317413.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7629, Time Loss: 0.9036, SLA Loss: 0.7277, Priority Loss: 0.4642\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7374, Time Loss: 0.9020, SLA Loss: 0.6555, Priority Loss: 0.4618\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.7024, Time Loss: 0.9021, SLA Loss: 0.5531, Priority Loss: 0.4557\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6190, Time Loss: 0.9024, SLA Loss: 0.3093, Priority Loss: 0.4307\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5528, Time Loss: 0.9023, SLA Loss: 0.1264, Priority Loss: 0.4076\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 66])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 66])\n",
            "Q shape: torch.Size([1000, 6, 11])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 66])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 66])\n",
            "Q shape: torch.Size([1000, 6, 11])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 66])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "GNN layer 2 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:05:45,474] Trial 2 finished with value: -0.8210613131523132 and parameters: {'heads': 6, 'base_hidden_dim': 64, 'num_gnn_layers': 3, 'tier1_lr': 0.003275046069866695, 'tier1_n_steps': 1024, 'tier1_batch_size': 128, 'tier2_lr': 0.0003519887891890739, 'tier2_n_steps': 2048, 'tier2_batch_size': 64}. Best is trial 1 with value: -0.7999642193317413.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7736, Time Loss: 0.9021, SLA Loss: 0.7700, Priority Loss: 0.4578\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7485, Time Loss: 0.9021, SLA Loss: 0.6960, Priority Loss: 0.4557\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.7062, Time Loss: 0.9020, SLA Loss: 0.5686, Priority Loss: 0.4516\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6147, Time Loss: 0.9020, SLA Loss: 0.2904, Priority Loss: 0.4396\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5526, Time Loss: 0.9020, SLA Loss: 0.1189, Priority Loss: 0.4191\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 35])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 35])\n",
            "Q shape: torch.Size([1000, 5, 7])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 35])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 35])\n",
            "Q shape: torch.Size([1000, 5, 7])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 35])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:06:22,297] Trial 3 finished with value: -0.7954559326171875 and parameters: {'heads': 5, 'base_hidden_dim': 32, 'num_gnn_layers': 1, 'tier1_lr': 0.00012319429214200574, 'tier1_n_steps': 4096, 'tier1_batch_size': 64, 'tier2_lr': 0.00026511565656415164, 'tier2_n_steps': 1024, 'tier2_batch_size': 32}. Best is trial 3 with value: -0.7954559326171875.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7595, Time Loss: 0.9023, SLA Loss: 0.7240, Priority Loss: 0.4557\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7295, Time Loss: 0.9022, SLA Loss: 0.6331, Priority Loss: 0.4557\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6837, Time Loss: 0.9020, SLA Loss: 0.4923, Priority Loss: 0.4558\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6002, Time Loss: 0.9059, SLA Loss: 0.2276, Priority Loss: 0.4536\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5492, Time Loss: 0.9021, SLA Loss: 0.0933, Priority Loss: 0.4407\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 2, 32])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 2, 32])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:06:53,512] Trial 4 finished with value: -0.9173134863376617 and parameters: {'heads': 2, 'base_hidden_dim': 64, 'num_gnn_layers': 1, 'tier1_lr': 0.00015916324634801106, 'tier1_n_steps': 2048, 'tier1_batch_size': 64, 'tier2_lr': 8.66041443521428e-05, 'tier2_n_steps': 2048, 'tier2_batch_size': 64}. Best is trial 3 with value: -0.7954559326171875.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7391, Time Loss: 0.9056, SLA Loss: 0.6477, Priority Loss: 0.4602\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7116, Time Loss: 0.9026, SLA Loss: 0.5728, Priority Loss: 0.4564\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6677, Time Loss: 0.9023, SLA Loss: 0.4443, Priority Loss: 0.4488\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.5689, Time Loss: 0.9031, SLA Loss: 0.1529, Priority Loss: 0.4208\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5312, Time Loss: 0.9034, SLA Loss: 0.0554, Priority Loss: 0.4075\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 133])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 133])\n",
            "Q shape: torch.Size([1000, 7, 19])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 133])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 133])\n",
            "Q shape: torch.Size([1000, 7, 19])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 133])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:07:29,049] Trial 5 finished with value: -0.7889570593833923 and parameters: {'heads': 7, 'base_hidden_dim': 128, 'num_gnn_layers': 2, 'tier1_lr': 0.0003348371228133698, 'tier1_n_steps': 4096, 'tier1_batch_size': 64, 'tier2_lr': 0.005493529735980974, 'tier2_n_steps': 2048, 'tier2_batch_size': 64}. Best is trial 5 with value: -0.7889570593833923.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7348, Time Loss: 0.9020, SLA Loss: 0.6403, Priority Loss: 0.4586\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7055, Time Loss: 0.9019, SLA Loss: 0.5528, Priority Loss: 0.4576\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6501, Time Loss: 0.9020, SLA Loss: 0.3846, Priority Loss: 0.4524\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.5714, Time Loss: 0.9020, SLA Loss: 0.1563, Priority Loss: 0.4306\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5355, Time Loss: 0.9020, SLA Loss: 0.0692, Priority Loss: 0.4111\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 128])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 128])\n",
            "Q shape: torch.Size([1000, 8, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 128])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 128])\n",
            "Q shape: torch.Size([1000, 8, 16])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 128])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:08:05,573] Trial 6 finished with value: -0.4974881708621979 and parameters: {'heads': 8, 'base_hidden_dim': 128, 'num_gnn_layers': 2, 'tier1_lr': 0.00012228765641450365, 'tier1_n_steps': 2048, 'tier1_batch_size': 32, 'tier2_lr': 0.003994196513518774, 'tier2_n_steps': 1024, 'tier2_batch_size': 32}. Best is trial 6 with value: -0.4974881708621979.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7696, Time Loss: 0.9022, SLA Loss: 0.7494, Priority Loss: 0.4686\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7447, Time Loss: 0.9021, SLA Loss: 0.6764, Priority Loss: 0.4660\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6994, Time Loss: 0.9020, SLA Loss: 0.5397, Priority Loss: 0.4615\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6041, Time Loss: 0.9024, SLA Loss: 0.2517, Priority Loss: 0.4454\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5474, Time Loss: 0.9021, SLA Loss: 0.1014, Priority Loss: 0.4204\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 130])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 130])\n",
            "Q shape: torch.Size([1000, 5, 26])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 130])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 130])\n",
            "Q shape: torch.Size([1000, 5, 26])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 130])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "GNN layer 2 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:08:30,740] Trial 7 finished with value: -0.9951191842556 and parameters: {'heads': 5, 'base_hidden_dim': 128, 'num_gnn_layers': 3, 'tier1_lr': 0.002909743205303136, 'tier1_n_steps': 2048, 'tier1_batch_size': 128, 'tier2_lr': 0.007304104238686721, 'tier2_n_steps': 1024, 'tier2_batch_size': 128}. Best is trial 6 with value: -0.4974881708621979.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7482, Time Loss: 0.9033, SLA Loss: 0.6839, Priority Loss: 0.4569\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7160, Time Loss: 0.9021, SLA Loss: 0.5906, Priority Loss: 0.4528\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6547, Time Loss: 0.9022, SLA Loss: 0.4053, Priority Loss: 0.4437\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.5640, Time Loss: 0.9026, SLA Loss: 0.1413, Priority Loss: 0.4164\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5331, Time Loss: 0.9021, SLA Loss: 0.0643, Priority Loss: 0.4075\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 32])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 32])\n",
            "Q shape: torch.Size([1000, 8, 4])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 32])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 32])\n",
            "Q shape: torch.Size([1000, 8, 4])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 32])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "GNN layer 2 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:09:04,150] Trial 8 finished with value: -0.9333812892436981 and parameters: {'heads': 8, 'base_hidden_dim': 32, 'num_gnn_layers': 3, 'tier1_lr': 0.004543462980544856, 'tier1_n_steps': 1024, 'tier1_batch_size': 64, 'tier2_lr': 0.0005231897150972212, 'tier2_n_steps': 2048, 'tier2_batch_size': 32}. Best is trial 6 with value: -0.4974881708621979.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7124, Time Loss: 0.9022, SLA Loss: 0.5661, Priority Loss: 0.4573\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.6833, Time Loss: 0.9022, SLA Loss: 0.4824, Priority Loss: 0.4528\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6270, Time Loss: 0.9020, SLA Loss: 0.3142, Priority Loss: 0.4448\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.5500, Time Loss: 0.9020, SLA Loss: 0.0950, Priority Loss: 0.4187\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5269, Time Loss: 0.9019, SLA Loss: 0.0437, Priority Loss: 0.4074\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 33])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 33])\n",
            "Q shape: torch.Size([1000, 3, 11])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 33])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 33])\n",
            "Q shape: torch.Size([1000, 3, 11])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 33])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "GNN layer 2 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:09:51,549] Trial 9 finished with value: -0.5179372876882553 and parameters: {'heads': 3, 'base_hidden_dim': 32, 'num_gnn_layers': 3, 'tier1_lr': 0.002690802078217633, 'tier1_n_steps': 2048, 'tier1_batch_size': 32, 'tier2_lr': 0.00010517053926530751, 'tier2_n_steps': 4096, 'tier2_batch_size': 32}. Best is trial 6 with value: -0.4974881708621979.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7448, Time Loss: 0.9039, SLA Loss: 0.6650, Priority Loss: 0.4667\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7158, Time Loss: 0.9021, SLA Loss: 0.5818, Priority Loss: 0.4649\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.6702, Time Loss: 0.9024, SLA Loss: 0.4437, Priority Loss: 0.4614\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.5841, Time Loss: 0.9030, SLA Loss: 0.1869, Priority Loss: 0.4440\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5391, Time Loss: 0.9031, SLA Loss: 0.0784, Priority Loss: 0.4113\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 128])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 128])\n",
            "Q shape: torch.Size([1000, 8, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 128])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 128])\n",
            "Q shape: torch.Size([1000, 8, 16])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 128])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[I 2025-03-09 18:10:27,713] Trial 10 finished with value: -0.8104212880134583 and parameters: {'heads': 8, 'base_hidden_dim': 128, 'num_gnn_layers': 2, 'tier1_lr': 1.306452654067201e-05, 'tier1_n_steps': 2048, 'tier1_batch_size': 32, 'tier2_lr': 1.203047958869564e-05, 'tier2_n_steps': 1024, 'tier2_batch_size': 32}. Best is trial 6 with value: -0.4974881708621979.\n",
            "<ipython-input-13-0b84f27b1722>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 0, Loss: 0.7814, Time Loss: 0.9037, SLA Loss: 0.7857, Priority Loss: 0.4690\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 10, Loss: 0.7562, Time Loss: 0.9020, SLA Loss: 0.7143, Priority Loss: 0.4664\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 20, Loss: 0.7185, Time Loss: 0.9022, SLA Loss: 0.6006, Priority Loss: 0.4632\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 30, Loss: 0.6336, Time Loss: 0.9026, SLA Loss: 0.3419, Priority Loss: 0.4526\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Epoch 40, Loss: 0.5674, Time Loss: 0.9026, SLA Loss: 0.1525, Priority Loss: 0.4383\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Initial embedding output shape: torch.Size([1000, 64])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 64])\n",
            "Q shape: torch.Size([1000, 4, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 64])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n",
            "Model, task embeddings, and graph embedding saved to ./temp_model\n",
            "Initial embedding output shape: torch.Size([1000, 32])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 32])\n",
            "Q shape: torch.Size([1000, 2, 16])\n",
            "Transformer layer 0 output shape: torch.Size([1000, 32])\n",
            "GraphTransformerLayer input x shape: torch.Size([1000, 32])\n",
            "Q shape: torch.Size([1000, 2, 16])\n",
            "Transformer layer 1 output shape: torch.Size([1000, 32])\n",
            "Feature projection output shape: torch.Size([1000, 32])\n",
            "GNN layer 0 output shape: torch.Size([1000, 32])\n",
            "GNN layer 1 output shape: torch.Size([1000, 32])\n",
            "Global mean pool output shape: torch.Size([1, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "[W 2025-03-09 18:10:34,799] Trial 11 failed with parameters: {'heads': 2, 'base_hidden_dim': 32, 'num_gnn_layers': 2, 'tier1_lr': 0.0009889072891345147, 'tier1_n_steps': 2048, 'tier1_batch_size': 32} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-57-04fd75a54d37>\", line 41, in objective\n",
            "    tier1_model.learn(total_timesteps=5000)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\", line 311, in learn\n",
            "    return super().learn(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 323, in learn\n",
            "    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 218, in collect_rollouts\n",
            "    new_obs, rewards, dones, infos = env.step(clipped_actions)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\", line 207, in step\n",
            "    return self.step_wait()\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 59, in step_wait\n",
            "    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n",
            "                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/shimmy/openai_gym_compatibility.py\", line 250, in step\n",
            "    obs, reward, done, info = self.gym_env.step(action)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-14-6d4a248c233d>\", line 58, in step\n",
            "    self.energy_sim.input['sla_adherence'] = np.clip(sla_adherence, 0, 1)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skfuzzy/control/controlsystem.py\", line 216, in __setitem__\n",
            "    self._update_to_current()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skfuzzy/control/controlsystem.py\", line 239, in _update_to_current\n",
            "    antecedent.input[self.sim] = antecedent.input['current']\n",
            "    ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skfuzzy/control/state.py\", line 18, in __get__\n",
            "    def __get__(self, instance, owner):\n",
            "    \n",
            "KeyboardInterrupt\n",
            "[W 2025-03-09 18:10:34,802] Trial 11 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-a3556e42c719>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Run hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting hyperparameter tuning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m best_params = optimize_full_pipeline(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msla_adherences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtask_priorities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-04fd75a54d37>\u001b[0m in \u001b[0;36moptimize_full_pipeline\u001b[0;34m(node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities, node_features_list, device)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Extract best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-04fd75a54d37>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtier1_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         )\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtier1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Tier 2 PPO Hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \"\"\"\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shimmy/openai_gym_compatibility.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6d4a248c233d>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Apply fuzzy logic for energy estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sla_adherence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msla_adherence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skfuzzy/control/controlsystem.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_unique_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_to_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skfuzzy/control/controlsystem.py\u001b[0m in \u001b[0;36m_update_to_current\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mantecedent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mantecedent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mantecedent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skfuzzy/control/state.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'current'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitial_condition\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper parameter tuning\n",
        "# Define the hyperparameter search space\n",
        "hyperparameter_ranges = {\n",
        "    \"lr\": [0.0001, 0.001, 0.01],\n",
        "    \"num_gnn_layers\": [1, 2, 3],\n",
        "    \"num_transformer_layers\": [1, 2, 3],\n",
        "    \"hidden_dim\": [32, 64, 128],\n",
        "    \"heads\": [2, 4, 8],\n",
        "    \"dropout\": [0.1, 0.2, 0.3]\n",
        "}"
      ],
      "metadata": {
        "id": "rXTjriJUu5q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(hyperparameters, node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities, epochs=100):\n",
        "    \"\"\"\n",
        "    Train the model with the given hyperparameters and return the validation loss.\n",
        "    \"\"\"\n",
        "    # Extract hyperparameters\n",
        "    lr = hyperparameters[\"lr\"]\n",
        "    num_gnn_layers = hyperparameters[\"num_gnn_layers\"]\n",
        "    num_transformer_layers = hyperparameters[\"num_transformer_layers\"]\n",
        "    hidden_dim = hyperparameters[\"hidden_dim\"]\n",
        "    heads = hyperparameters[\"heads\"]\n",
        "    #dropout = hyperparameters[\"dropout\"]\n",
        "\n",
        "    # Initialize the model with the given hyperparameters\n",
        "    model = TaskEmbeddingModel(\n",
        "        input_dim=node_features.shape[1],\n",
        "        hidden_dim=hidden_dim,\n",
        "        heads=heads,\n",
        "        num_gnn_layers=num_gnn_layers,\n",
        "        num_transformer_layers=num_transformer_layers,\n",
        "        #dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Initialize the optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training loop\n",
        "    criterion_time = nn.L1Loss()\n",
        "    criterion_sla = nn.BCELoss()\n",
        "    criterion_priority = nn.L1Loss()\n",
        "\n",
        "    # Create a batch vector for graph-level pooling (assuming single graph)\n",
        "    batch = torch.zeros(node_features.size(0), dtype=torch.long).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        embeddings, _ = model(node_features, edge_index, edge_attr, batch)\n",
        "        exec_time_pred = embeddings[:, -3].unsqueeze(1)\n",
        "        sla_pred = embeddings[:, -2].unsqueeze(1)\n",
        "        priority_pred = embeddings[:, -1].unsqueeze(1)\n",
        "\n",
        "        loss_time = criterion_time(exec_time_pred, execution_times)\n",
        "        loss_sla = criterion_sla(sla_pred, sla_adherences)\n",
        "        loss_priority = criterion_priority(priority_pred, task_priorities)\n",
        "\n",
        "        # Dynamic loss weighting\n",
        "        sigma_time = torch.exp(-model.log_sigma_time)\n",
        "        sigma_sla = torch.exp(-model.log_sigma_sla)\n",
        "        sigma_priority = torch.exp(-model.log_sigma_priority)\n",
        "\n",
        "        loss_time_weighted = 0.5 * sigma_time * loss_time + 0.5 * model.log_sigma_time\n",
        "        loss_sla_weighted = 0.3 * sigma_sla * loss_sla + 0.3 * model.log_sigma_sla\n",
        "        loss_priority_weighted = 0.2 * sigma_priority * loss_priority + 0.2 * model.log_sigma_priority\n",
        "\n",
        "        loss = loss_time_weighted + loss_sla_weighted + loss_priority_weighted\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Return the validation loss (or any other metric)\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "JAxjctLG5AWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_function(hyperparameters):\n",
        "    \"\"\"\n",
        "    Objective function for hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    # Train the model and return the validation loss\n",
        "    validation_loss = train_model(hyperparameters, node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities)\n",
        "    return validation_loss,"
      ],
      "metadata": {
        "id": "Zs8xa1UX5Cz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deap import creator\n",
        "\n",
        "if \"FitnessMin\" not in creator.__dict__:\n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # ✅ Only create if not exists\n",
        "if \"Individual\" not in creator.__dict__:\n",
        "    creator.create(\"Individual\", dict, fitness=creator.FitnessMin)\n"
      ],
      "metadata": {
        "id": "42o0Q_R86092"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input Dim: {node_features.shape[1]}, Hidden Dim: {hyperparameter_ranges['hidden_dim']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsztHkoJ9TKi",
        "outputId": "1f8d3d93-b847-4205-cbeb-eca558bfadb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Dim: 10, Hidden Dim: [32, 64, 128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare data\n",
        "workflow_dag = load_dag(\"cybershake_dag.json\")\n",
        "(node_features, edge_index, edge_attr, adjacency_matrix, execution_times, sla_adherences, task_priorities, node_features_list) = prepare_workflow_dag(workflow_dag)\n",
        "\n",
        "# Genetic Algorithm Setup\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # Minimize the objective function\n",
        "creator.create(\"Individual\", dict, fitness=creator.FitnessMin)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# Define how to generate hyperparameters\n",
        "def generate_hyperparameters():\n",
        "    return {\n",
        "        \"lr\": random.choice(hyperparameter_ranges[\"lr\"]),\n",
        "        \"num_gnn_layers\": random.choice(hyperparameter_ranges[\"num_gnn_layers\"]),\n",
        "        \"num_transformer_layers\": random.choice(hyperparameter_ranges[\"num_transformer_layers\"]),\n",
        "        \"hidden_dim\": random.choice([64]),  # ✅ PICK ONE VALUE, NOT A LIST\n",
        "        \"heads\": random.choice(hyperparameter_ranges[\"heads\"]),\n",
        "        \"dropout\": random.choice(hyperparameter_ranges[\"dropout\"])\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# Register functions in DEAP\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual, generate_hyperparameters)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"evaluate\", objective_function)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=len(hyperparameter_ranges) - 1, indpb=0.1)  # Mutation\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Selection\n",
        "\n",
        "# Run the Genetic Algorithm\n",
        "population = toolbox.population(n=10)  # Population size\n",
        "ngen = 5  # Number of generations\n",
        "cxpb = 0.5  # Crossover probability\n",
        "mutpb = 0.2  # Mutation probability\n",
        "\n",
        "# Run the algorithm\n",
        "algorithms.eaSimple(population, toolbox, cxpb, mutpb, ngen, verbose=True)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hyperparameters = tools.selBest(population, k=1)[0]\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "tylhc99X6OXy",
        "outputId": "5c53d360-dc51-4f0d-b444-03f78b5681bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x32 and 64x64)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-5c3432334bf7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Run the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meaSimple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Get the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-1c8eb69cbb0c>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Train the model and return the validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msla_adherences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_priorities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-757f8e8f3ccb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(hyperparameters, node_features, edge_index, edge_attr, execution_times, sla_adherences, task_priorities, epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mexec_time_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msla_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-e8fc70df691b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_transformer_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gnn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_transformer_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gnn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass edge_index to GATConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-e8fc70df691b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1000x32 and 64x64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# List of files and folders to download\n",
        "files_to_download = [\n",
        "    \"embedding_model_data\",\n",
        "    \"tier1_tensorboard\",\n",
        "    \"tier2_tensorboard\",\n",
        "    \"cybershake_dag.json\",\n",
        "    \"tier1_scheduler_new.zip\",\n",
        "    \"tier2_scheduler_new.zip\"\n",
        "]\n",
        "\n",
        "# Create a temporary directory to organize files\n",
        "temp_dir = \"temp_download\"\n",
        "os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "# Copy files and folders to the temporary directory\n",
        "for item in files_to_download:\n",
        "    if os.path.exists(item):\n",
        "        if os.path.isdir(item):\n",
        "            shutil.copytree(item, os.path.join(temp_dir, item))\n",
        "        else:\n",
        "            shutil.copy(item, os.path.join(temp_dir, item))\n",
        "    else:\n",
        "        print(f\"Warning: {item} does not exist and will be skipped.\")\n",
        "\n",
        "# Compress the temporary directory into a zip file\n",
        "output_zip = \"colab_files.zip\"\n",
        "shutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', temp_dir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(output_zip)\n",
        "\n",
        "# Clean up the temporary directory\n",
        "shutil.rmtree(temp_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FRUdQKUk6QfK",
        "outputId": "0b5e6d65-8317-4a6a-de6b-fe6c123e18ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f708f57c-37d2-4ccb-bc97-b214c6497eaf\", \"colab_files.zip\", 486572)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8UmVxkVBYxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}